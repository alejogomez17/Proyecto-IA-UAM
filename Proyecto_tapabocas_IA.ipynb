{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto-tapabocas-IA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+mViFJn/fBIbD+kkK3W3A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alejogomez17/Proyecto-IA-UAM/blob/main/Proyecto_tapabocas_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJRP-c2gHMHG",
        "outputId": "dcf57a6d-6d99-4ccc-fa64-ae2a6ee3a38b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg-V3VfSFmfB"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import scipy\n",
        "import os\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from io import StringIO\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils.vis_utils import plot_model #Pintar el modelo"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EphjjcnpHbjC"
      },
      "source": [
        "## ruta base de las del dataset de las imágenes\n",
        "BASE_DIR = '/content/drive/MyDrive/inteligencia artificial/Inteligencia Artificial - EspecializaciónSW/trabajos/proyecto/dataset-mask2/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVfkztlbHfzZ"
      },
      "source": [
        "# cargar las imagenes en X,y con los tres canales de las imágenes\n",
        "def get_data_multi_channel(folder):\n",
        "    \"\"\"\n",
        "    Cargar los datos y las etiquetas desde una carpeta dada.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for mask_type in os.listdir(folder):\n",
        "        if not mask_type.startswith('.'):\n",
        "            if mask_type in ['correcto']:\n",
        "                ## tapabocas bien puesto\n",
        "                label = '0'\n",
        "            else:\n",
        "                ## tapabocas mal puesto\n",
        "                label = '1'\n",
        "            for image_filename in os.listdir(folder + mask_type):\n",
        "                img_file = cv2.imread(folder + mask_type + '/' + image_filename)\n",
        "                if img_file is not None:\n",
        "                    image = cv2.cvtColor(img_file, cv2.COLOR_BGR2RGB)\n",
        "                    #redimensionar para que todas queden con el mismo tamaño\n",
        "                    image = cv2.resize(image, (224, 224))\n",
        "                    img_arr = np.asarray(image)\n",
        "                    X.append(img_arr)\n",
        "                    y.append(label)\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    return X,y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "688RTkDSI6ek"
      },
      "source": [
        "X_train_multi_channel, y_train_multi_channel = get_data_multi_channel(BASE_DIR + 'train/')\n",
        "X_test_multi_channel, y_test_multi_channel = get_data_multi_channel(BASE_DIR + 'test/')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayFm8DO2N-mu"
      },
      "source": [
        "Verificamos el tamaño de las imágenes cargadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BjL_fAPYgX9",
        "outputId": "6b41ff31-8538-4f5f-9ca9-e9d92a3561bf"
      },
      "source": [
        "X_train_multi_channel.shape, y_train_multi_channel.shape, X_test_multi_channel.shape, y_test_multi_channel.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1251, 224, 224, 3), (1251,), (339, 224, 224, 3), (339,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utFfvHbgcMUf"
      },
      "source": [
        "Vamos a trabajar con un set de imágenes de 1590 imágenes, divididas en:\n",
        "- 1251 para entrenar\n",
        "- 339 para test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0aqNPtAGPKw"
      },
      "source": [
        "# **Super Vector Machine**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MdQs1IldGXY"
      },
      "source": [
        "**Trabajaremos con otras variables para no tocar lo datos iniciales por si se quiere dar otro uso.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJmgyTAxZXwu"
      },
      "source": [
        "X_train = X_train_multi_channel\n",
        "y_train = y_train_multi_channel\n",
        "X_test = X_test_multi_channel\n",
        "y_test = y_test_multi_channel\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qYtNsI8dZBA",
        "outputId": "8ac3c7f6-d797-4aed-a14a-d64b5859bd14"
      },
      "source": [
        "#verificamos integridad\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1251, 224, 224, 3), (1251,), (339, 224, 224, 3), (339,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztyl5Au1dmZF"
      },
      "source": [
        "## transformar X_train y X_test a un vector lineal\n",
        "nsamples, nx, ny, ncha = X_train.shape\n",
        "nsamples2, nx2, ny2, ncha2 = X_test.shape\n",
        "X_train_new = X_train.reshape((nsamples,nx*ny*ncha))\n",
        "X_test = X_test.reshape((nsamples2,nx2*ny2*ncha2))\n",
        "\n",
        "## label encoder para linealizar las tiquetas\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "y_train = encoder.transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhOOoeEFe1g_",
        "outputId": "2fc4e5d5-3ef3-4582-b819-c8c60cac2125"
      },
      "source": [
        "## Verificamos la transformación\n",
        "X_train_new.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1251, 150528), (339, 150528))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXgbHFrtlUvp",
        "outputId": "59d1ca28-01ee-4f35-eb93-4965d655a400"
      },
      "source": [
        "## Validamos que no se ha perdido la cantidad de etiquetas\n",
        "y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1251,), (339,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV-HEPnjmDTV",
        "outputId": "4fec7cd0-506e-4738-c7b3-3d06663debde"
      },
      "source": [
        "## Vemos como quedaron las etiquetas codificadas\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSZhrplYoTnC",
        "outputId": "704c0a50-85fb-4012-a11a-d92812141408"
      },
      "source": [
        "## super vector machine con el kernel 'linear'\n",
        "clf_l = svm.SVC(kernel='linear', C = 100.0)\n",
        "clf_l.fit(X_train_new,y_train)\n",
        "y_pred_l = clf_l.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred_l))\n",
        "print(confusion_matrix(y_test, y_pred_l))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.86       156\n",
            "           1       0.88      0.89      0.89       183\n",
            "\n",
            "    accuracy                           0.88       339\n",
            "   macro avg       0.88      0.87      0.88       339\n",
            "weighted avg       0.88      0.88      0.88       339\n",
            "\n",
            "[[134  22]\n",
            " [ 20 163]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3oERI3-QBay"
      },
      "source": [
        "**Resultados:**\n",
        "\n",
        "Vemos como la precisión se encuentra en 87% para identificar tapa bocas bien puestos y 88% para tapabocas mal puesto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icwsViaRmtfa",
        "outputId": "ea786f2a-0743-4ef7-92b2-f1aa17aa6788"
      },
      "source": [
        "clf_r = svm.SVC(kernel='rbf', gamma=0.1, C = 100.0)\n",
        "clf_r.fit(X_train_new,y_train)\n",
        "y_pred_r = clf_r.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred_r))\n",
        "print(confusion_matrix(y_test, y_pred_r))\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.08      0.14       156\n",
            "           1       0.56      1.00      0.72       183\n",
            "\n",
            "    accuracy                           0.58       339\n",
            "   macro avg       0.78      0.54      0.43       339\n",
            "weighted avg       0.76      0.58      0.45       339\n",
            "\n",
            "[[ 12 144]\n",
            " [  0 183]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOtp8JNJS0aQ"
      },
      "source": [
        "**Resultados:**\n",
        "\n",
        "Vemos como la precisión se encuentra en 100% para identificar tapa bocas bien puestos y 56% para tapabocas mal puesto. Se puede observar un gran overfitting y una solución poco viable al problema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWT9xUMQnW7x",
        "outputId": "df8bb974-084a-438b-86d9-7be1eb7883bc"
      },
      "source": [
        "score_l = accuracy_score(y_test, y_pred_l)\n",
        "score_r = accuracy_score(y_test, y_pred_r)\n",
        "score_l, score_r "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8761061946902655, 0.5752212389380531)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X9Fiigrngnk",
        "outputId": "f1cd45b1-3ed2-4c7a-a63c-6242100b8498"
      },
      "source": [
        "confusion_matrix(y_test, y_pred_l), confusion_matrix(y_test, y_pred_r)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[134,  22],\n",
              "        [ 20, 163]]), array([[ 12, 144],\n",
              "        [  0, 183]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "hG-Fr-w8nkc3",
        "outputId": "33426f37-598f-4f1a-9c6f-a048a14859e4"
      },
      "source": [
        "plt.figure()\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "## para svc linear\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_l)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
        "plt.show()\n",
        "\n",
        "## para svc rbf\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_r)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUZfb48c+BhIQaIASlgwgqvQSwIOCKgg3drw3FFdZC1bWvZXfVH5bd1bXuIogN194VRUVXAqiI9C4oIqbQQm/pOb8/7o0MIZlMwszcmcl5v17zyszcdu5Ncs99nufe5xFVxRhjjClPDa8DMMYYE9ksURhjjPHLEoUxxhi/LFEYY4zxyxKFMcYYvyxRGGOM8csShakSEVktIoO8jsNrIjJFRP4W5m1OE5EHw7nNUBGRESLyRRWXtb/BMBF7jiL6ichG4BigCNgPfA7coKr7vYwr1ojIKOA6Ve3vcRzTgExV/avHcdwPHK+qV4VhW9OIgH2urqxEETsuUNV6QA+gJ3C3x/FUmojEVcdte8mOuQmEJYoYo6pbgJk4CQMAETlZROaJyG4RWe5bXBeRxiLykohsEpFdIvKhz7TzRWSZu9w8EenmM22jiAwWkeYikiMijX2m9RSR7SIS736+RkR+cNc/U0Ta+MyrIjJBRH4Cfiprn0RkmFvNsFtEZovISaXiuFtE1rjrf0lEEiuxD3eKyArggIjEichdIvKziOxz1/l7d96TgCnAKSKyX0R2u9//Vg0kIoNEJFNEbhORbSKyWUT+6LO9ZBH5WET2ishCEXlQRL4p73cpIv19fm8ZbommRCMRmeHG+b2ItPdZ7il3/r0islhETveZdr+IvCsir4rIXmCUiPQVke/c7WwWkf+ISC2fZTqLyJcislNEtorIPSIyFLgHuNw9HsvdeZNE5AV3PVnuPtZ0p40SkW9F5AkR2QHc7373jTtd3Gnb3NhXikgXERkNjAD+7G7rY5/f32D3fU03rpLf3WIRaVXesTWVpKr2ivIXsBEY7L5vCawEnnI/twB2AOfiXBic5X5OcafPAN4CGgHxwED3+57ANqAfUBMY6W4noYxtzgKu94nnUWCK+/5CYD1wEhAH/BWY5zOvAl8CjYHaZexbR+CAG3c88Gd3fbV84lgFtHLX8S3wYCX2YZm7bG33u0uB5u6xutzddjN32ijgm1LxTfPZ3iCgEJjoxnoucBBo5E5/033VAToBGaXX57PeNsA+4Ap3XclAD59t7gD6usf0NeBNn2WvcuePA24DtgCJ7rT7gQLgIncfawO9gZPd+dsCPwA3u/PXBza760l0P/fzWderpeL+AHgWqAs0BRYAY3yOXyFwo7ut2r7HFBgCLAYaAoLzN9Os9HEu5+/+Dpy/+xPcZbsDyV7/b8bKy/MA7BWEX6LzD7PfPbEo8BXQ0J12J/BKqfln4pw0mwHFJSeyUvNMBh4o9d06DiUS33/S64BZ7ntxT4AD3M+fAdf6rKMGzsmzjftZgd/52be/AW+XWj4LGOQTx1if6ecCP1diH66p4NguAy503/92UvOZ/tsJDCdR5ABxPtO34ZyEa+KcoE/wmfZg6fX5TLsb+KCcadOA50vt81o/+7AL6O6+vx+YW8E+31yybZxEtbSc+e7HJ1HgtJPl4ZPw3eXTfI5feql1/HZMgd8BP7rHq0Z5x7nU333J3+C6kt+TvYL/sqqn2HGRqtbHOVmdCDRxv28DXOpWK+x2q0z64ySJVsBOVd1VxvraALeVWq4VztV2ae/hVMk0AwbgJJ+vfdbzlM86duIkkxY+y2f42a/mwK8lH1S12J2/vOV/9YkxkH04bNsicrVPVdVuoAuHjmUgdqhqoc/ng0A9IAXnKtp3e/72uxXws5/pW8rYBgAicrs4VX173H1I4vB9KL3PHUXkExHZ4lZHPewzf0Vx+GqDU/rZ7HP8nsUpWZS5bV+qOgv4DzAJ2CYiU0WkQYDbrkycppIsUcQYVZ2Dc/X1L/erDJwSRUOfV11V/Yc7rbGINCxjVRnAQ6WWq6Oqb5SxzV3AFzhVNVfiVIOoz3rGlFpPbVWd57sKP7u0CecEBDj12DgnhSyfeXzrolu7ywS6D79tW5y2k+eAG3CqLRriVGtJAHFWJBun2qVlOXGXlgG09zO9TG57xJ+By3BKig2BPRzaBzhyPyYDa4EOqtoAp+2hZP4M4LhyNld6PRk4JYomPse7gap29rPM4StUfVpVe+NUzXXEqVKqcDmqeLxMYCxRxKYngbNEpDvwKnCBiAxxG/wS3UbXlqq6Gadq6BkRaSQi8SIywF3Hc8BYEennNjLWFZHzRKR+Odt8HbgauMR9X2IKcLeIdIbfGjsvrcS+vA2cJyJnitM4fhvOycg30UwQkZbiNKj/BafNpSr7UBfnhJTtxvpHnBJFia1AS9+G3kCpahHwPk4Dbh0RORHneJXnNWCwiFwmTiN7soj08DN/ifo4CSkbiBORe4GKrsrrA3uB/W5c43ymfQI0E5GbRSRBROqLSD932lagrYjUcPdxM84Fw2Mi0kBEaohIexEZGEDciEgf93cVj9M2lItTOi3ZVnkJC+B54AER6eD+rruJSHIg2zUVs0QRg1Q1G/gvcK+qZuA0KN+Dc/LIwLlKK/nd/wGn7nwtTn36ze46FgHX41QF7MJpQB7lZ7PTgQ7AFlVd7hPLB8A/gTfdao1VwDmV2Jd1OI2z/wa2Axfg3Aqc7zPb6zgnqA041Q8PVmUfVHUN8BjwHc6JqStO43iJWcBqYIuIbA90H3zcgFMNtAV4BXgDJ+mVFUs6TtvDbTjVdctwGmgrMhPnOZofcarhcvFfxQVwO05JcB9Oci1JtKjqPpwbCS5w4/4JOMOd/I77c4eILHHfXw3UAtbgHPN3cao5A9HA3f4uN/YdODdGALwAdHKrtD4sY9nHcS4qvsBJei/gNJabILAH7kxUE+dhw+tU9X9ex1JZIvJP4FhVHel1LMb4YyUKY8JERE50q0RERPoC1+LcTmpMRLMnI40Jn/o41U3Ncaq2HgM+8jQiYwJgVU/GGGP8sqonY4wxfkVd1VOTJk20bdu2XodhjDFRZfHixdtVNaUqy0Zdomjbti2LFi3yOgxjjIkqIvJrxXOVzaqejDHG+GWJwhhjjF+WKIwxxvhlicIYY4xfliiMMcb4ZYnCGGOMXyFLFCLyojv27apypouIPC0i60VkhYj0ClUsxhhjqi6UJYppwFA/08/B6Za6AzAaZ/AUY4wxESZkD9yp6lwRaetnlguB/7ojoc0XkYYi0swd/MQYY0xFVKFgP+Rsh4PZzs9Sry2bdvPi5wlHtRkvn8xuweEDqmS63x2RKERkNE6pg9atW4clOGOMCbvCXMjZATlln/Q5mA25pb6rEQ+1m7ivlN/eF9VKpkbTXny1Ip49jQRnsMuqiYouPFR1KjAVIDU11bq7NcZEvuIiyN1R9gm/vBJAUd6hk36dFEhscuhzoxOg+WmHptVuAonJEH/kQH7Llm1hzJhP+MtfTmfE7ScwAnhkyrVV3hUvE0UWhw8u39L9zhhjIosq5O0p56RfztV/3h5IaHjopO77qtcCUrofVgKgdhOoVR9Eqhxmfn4Rd9/9P159dSUPP/w7zj+/Y1B238tEMR24QUTeBPoBe6x9whgTFgUHAz/h52x3qoPiah95wi95Nexw5HeJjaBGzbDsjqqSlbWPFi3q07RpXVatGkdKSt2grT9kiUJE3gAGAU1EJBO4D4gHUNUpwKc4g8evBw4CfwxVLMaYGFZUcGQVTzkNu78lBC0+8mq+pEqnSdcyTvrJEHd0DcKh8uuvu7nxxs/YtSuXuXNHceed/YO+jVDe9XRFBdMVmBCq7RtjopAWQ+7uAK/y3WkFByCxcamTu5sEktrBsX2OTAZxdY6qiidSvPPOasaNm8Ett5zM7befioRon6KiMdsYE4VUnZN4RSd836v/3J1OPX1ZJ/3aKdD4pCNP+glJINWrk4l58zLo2DGZ3r2b8/3319G+feOQbs8ShTEmMIV5ThVPRdU6vp+l5uEndd+TfNOeRyaDxMZQM97rPY1YO3fmcOedX/Lpp+t5773LOPnklmHZriUKY6qj4iLn6j3QE37OdijMOeJe/UO3bnaA5qeUmpYM8XW83tOYkZtbSK9ez3LBBR1Zs2Y8SUmJYdu2JQpjop0q5O8N/F79nO2Qt9u5dbOsO3jqNoOUbkd+X6tBTNTrR5u1a7fz6ac/ceutp7BgwfU0bRq8u5kCZYnCmEhTkFO5+/VztkNcYjm3bqZAw/bl3Lpp//6RLCengIcf/prJkxdx330DUVVPkgRYojAmtIoL3S4ZAjzhH8wGLSy7eqd2CiR3LjshROitm6bqpkxZxNq1O1i+fCwtWjTwNBZLFMYESosPfzo3kEbd/H1H3rpZ0qjboA0c0/vIZBBf16p4qqnNm/dx661fMG5cKjfddDK33BIZfweWKEz1pAqFBwM/4Zfcuhlft8wO2KjdBBqfUMZdPA2r3a2bpvKKioqZMmUR998/h9Gje5Ga2pwaNSIjSYAlChMrivL9nOzLSAa5253lfO/R9z3pp3Q/8pbOxMZQs5a3+2liTl5eIQALF25izpxRdOqU4nFER7JEYSJPcRHk7qrkrZsH/fTD0x6a9TsyGditm8ZDe/fmce+9aSxduoU5c0YxbdpFXodULksUJrRUnXr6ytzFk7vLedq2zFs3j4EmXY78PiHJ6vVN1Jg5cz3XXjudIUPa8957l3kdToUsUZjKKcwNrFrH93ONWmWf9OukOH3xHHHrZmO7ddPEpI0bd3PssfVo0CCB11+/mAED2ngdUkDsv7E6Ky488unccht23e+LC0qd1H3q8ZNPKjshxIXvCVJjIlF+fhGPPTaPxx77jg8/HE7//tE1UqclilhxxMAqAdzJk7fXefCqrA7Y6rc6vC+ekmQQX8+qeIyphAMH8unX73lat05i4cLradeukdchVZolikj128Aqgfa6ucPpOrn0ib1kKEXfgVVKpiU0DNvAKsZUN9u3H2TevAyGDTuBl166kNTU5iHrBjzULFGE0851sH9TYI26JQOrlDWM4m8Dq5TqgM1u3TTGc6rKtGnLuOuurxg1qjvDhp1Anz4tvA7rqFiiCJeMOfDRRYfuzy95JbWDZn3LqNePjYFVjKluHnnkW9599wc++2wEvXo18zqcoBBnoLnokZqaqosWLfI6jMr7+h6nmue0B7yOxBgTZAcPFvDQQ3O5+urutGzZgMTEOGrWjKwn8kVksaqmVmXZyNqTWJYxC1r9zusojDFB9tlnP9GlyzNs2LCbpKRE6tatFXFJ4mhZ1VM45O2F7aucgV2MMTFBVTlwoICJE+cyefJ5DBlyvNchhYwlinDI+hqO7WvPExgTA4qKipk0aSHffJPO229fyrx510Tt3UyBskQRDumzoNUZXkdhjDlKixdvYvToT2jQIIHJk88DiPkkAdZGER4ZadDa2ieMiVb79uWhqmzYsIubburHrFlXc+KJTbwOK2ysRBFqOTth109wbB+vIzHGVJKq8s47a7jllpm8886lXHppZ69D8oQlilDLnAMtTrOH4YyJMnv35nH55e+SmbmXt9++hFNPbeV1SJ6xRBFq1j5hTFTJyytk7drtdOt2DCNGdOXyyzsTH1+9u7qxNopQs/YJY6LG7Nkb6dHjWZ588ntEhKuu6lbtkwRYiSK0DmyF/ZlOL6zGmIj2+OPf8eST83n66XO48MITvA4noliJIpQyZkOLATYIjzERqrhYeemlpWzffpDLL+/M6tXjueiiE6vFLa+VYWewUMqYBa2tfcKYSLRq1TbGjv2EgoJiTj+9Dccf39jrkCKWlShCKSPN+ncyJgLt3p3LOee8xlVXdWPevGssSVTAShShsi/TeYYipavXkRhjXDNm/Mi8eRk89NCZrF9/IwkJdgoMREhLFCIyVETWich6EbmrjOmtRSRNRJaKyAoROTeU8YRVRhq0GgRihTZjvJaZuZeLL36bm2+eyaBBbQEsSVRCyI6UiNQEJgFnAZnAQhGZrqprfGb7K/C2qk4WkU7Ap0DbUMUUVumz7LZYYzxWXKzUqCG88cZKunZtymuv/R+JiZYgKiuUl7t9gfWqukFV84E3gQtLzaNAA/d9ErAphPGEj6o9aGeMxxYsyCI1dSqLF2/ijjtO4/77B1mSqKJQHrUWQIbP50ygX6l57ge+EJEbgbrA4LJWJCKjgdEArVu3DnqgQbfnFyjOh8Yneh2JMdXO/v35/PnPX/LBB2v517/OipnhSL3kdQX6FcA0VW0JnAu8InJkpb6qTlXVVFVNTUlJCXuQlZaR5pQm7F5sY8JGVdm27QDx8TVITq7NmjXjGTGimz0TEQShTBRZgG8vWi3d73xdC7wNoKrfAYlA9Pfdm27DnhoTTj/9tIMhQ15lwoRPSUiI44EHfkejRrW9DitmhDJRLAQ6iEg7EakFDAeml5onHTgTQEROwkkU2SGMKfRU7UE7Y8LouecWc8opLzBkSHveeONir8OJSSFro1DVQhG5AZgJ1AReVNXVIjIRWKSq04HbgOdE5Bachu1Rqqqhiiksdq6DGrUg6TivIzEmps2d+yt9+7agT58WLFkyhtatk7wOKWaF9BYAVf0U55ZX3+/u9Xm/BjgtlDGEXUlpwupFjQmJrVv3c/vtXzJ37q98/vkIevQ41uuQYp7Xjdmxx7rtMCZksrMP0K3bFJo1q8fq1eM56aQouLklBthNxcGkxZCeBgMf9zoSY2LKihVbWbp0MyNH9mDx4tG0bNmg4oVM0FiJIpi2r4LERtCg+g6ZaEww7d+fzx13fMHgwf+luNhpvrQkEX5WoggmexrbmKC67740srMPsmrVeJo2ret1ONWWJYpgykiDE6/wOgpjolp6+h5uvXUmDz98Jo88chY1a1rFh9fsNxAsxUWQOddKFMZUUUFBEf/61zx69XqW7t2PoU2bJEsSEcJKFMGybSnUaw51j/E6EmOiTkFBEXv35rFw4Sbmz7/OBhKKMJYogsW67TCm0nbtyuGuu/7Hnj15vPnmJbz11iVeh2TKEHC5TkTqhDKQqJeRZt12GFMJ7723hk6dniEurgZTppzvdTjGjwoThYicKiJrgLXu5+4i8kzII4smRQWw6VtoOdDrSIyJeBs37kZVSUiI46OPhjNp0nk0bJjodVjGj0BKFE8AQ4AdAKq6HBgQyqCizpaFkNQeaid7HYkxESs3t5D77ksjNXUqa9du5/zzO9K3bwuvwzIBCKjqSVUzSn1VFIJYoleGDXtqjD+bN++ja9fJrF6dzbJlY63rjSgTSGN2hoicCqiIxAM3AT+ENqwok5EGvW7xOgpjIs6WLftZt247Awa04aWXLqR//ygYodIcIZASxVhgAs7QpllAD2B8KIOKKoW5sPl7aGm1ccaUKCoqZvLkhXTtOpnvvstERCxJRLFAShQnqOoI3y9E5DTg29CEFGU2z4fkzpBg/c8YU+K2275g0aJNpKWNpEuXpl6HY45SICWKfwf4XfWUbu0TxgDs25fHPfd8xfbtB7nvvoHMnftHSxIxotwShYicApwKpIjIrT6TGuCMWGfASRSn3FvxfMbEKFXlww/XctNNn3Pmmcchgo1XHWP8VT3VAuq589T3+X4vYI9PAhQcgOxl0CK2BukzpjKysvbxwANzeeWV3zNwYFuvwzEhUG6iUNU5wBwRmaaqv4YxpuiR9Q007Qnx1v2xqV4KCop44on5ZGXt5amnzmHx4tGIDf8bswJpzD4oIo8CnYHfHp9UVauYT7dhT0318+236YwdO4MWLeozadK5AJYkYlwgjdmv4XTf0Q74f8BGYGEIY4oeGbOsfydTbRw8WADAkiWb+dvfBvDZZyNo3956ea0OAkkUyar6AlCgqnNU9RrALqPz9sCONdDsZK8jMSakVJWXX15G+/ZP8/PPO7nxxn5cdllnK0VUI4FUPRW4PzeLyHnAJsAuIzLnOkkizjozM7Fry5b9DB/+Lvv25fPxx1dYCaKaCiRRPCgiScBtOM9PNABuDmlU0SAjzUazMzErJ6eAzMy9tG6dxNVXd2fkyO422lw1VuFvXlU/UdU9qrpKVc9Q1d7AzjDEFtnsQTsTo2bOXE+XLpN5/vklJCTEcc01PS1JVHP+HrirCVyG08fT56q6SkTOB+4BagM9wxNiBMrZAXs2wDGpXkdiTFDdfff/eOut1UyadC7nnNPB63BMhPB3mfACcB2QDDwtIq8C/wIeUdXqmyQAMmZDi/5QM97rSIw5akVFxbz00lJycwu55pqerFo13pKEOYy/NopUoJuqFotIIrAFaK+qO8ITWgSz9gkTI5Ys2cyYMZ9Qu3YcQ4YcT4cONviWOZK/EkW+qhYDqGousMGShMvaJ0wM2LBhF+ed9zoTJvRhzpxRNG9ev+KFTLXkr0RxooiscN8L0N79LICqareQRxeJDmyBA5shpYfXkRhTaarKe+/9wKZN+/jTn/qxfv2N1K1by+uwTITzlyhOClsU0SQ9DVoOhBrWga6JLhs27OKGGz7l11/3MGXKeQCWJExA/HUKaB0BliUjzbrtMFFFVRERnn76ewYMaMOtt55CrVp2oWMCF9Kbo0VkqIisE5H1InJXOfNcJiJrRGS1iLweyniCImOWdQRoosbXX/9K795TSU/fw5NPDuWuu/pbkjCVFsiT2VXiPocxCTgLyAQWish0VV3jM08H4G7gNFXdJSKRPRzW3nSnj6cmnb2OxBi/du7M4fbbv+CLL37mqaeG0qqVDdVrqi6gRCEitYHWqrquEuvuC6xX1Q3uOt4ELgTW+MxzPTBJVXcBqOq2Sqw//EpuixV7StVEJlVl9+5cVJWmTeuyZs0EGjRI8DosE+UqPOOJyAXAMuBz93MPEZkewLpbABk+nzPd73x1BDqKyLciMl9EhgYWtkfSZ9nzEyZirV69jYEDp3HvvWkkJ9fhH/8YbEnCBEUgl8b345QOdgOo6jKcsSmCIQ7oAAwCrgCeE5GGpWcSkdEiskhEFmVnZwdp05Wk6jZkW/uEiTyPPPItgwa9zPDhXXjyyci+3jLRJ5BEUaCqe0p9pwEslwW08vnc0v3OVyYwXVULVPUX4EecxHH4xlSnqmqqqqampKQEsOkQ2P0zaBE06ujN9o0pw7ffpqOq9O3bghUrxjJ+fB/rwM8EXSB/UatF5Eqgpoh0EJF/A/MCWG4h0EFE2olILWA4ULrK6kOc0gQi0gSnKmpDoMGH1W/tEzZYi/FeVtZeLr30HUaO/JDNm/czaFBbmjWzJ6tNaASSKG7EGS87D3gd2EMA41GoaiFwAzAT+AF4W1VXi8hEERnmzjYT2CEia4A04I6I7SYk3W6LNZFh3brt9OjxLCed1ISVK8dZ1xsm5ETVfy2SiPRS1SVhiqdCqampumjRovBuVBWmNIMrv4OkYDXPGFM5CxdmsXXrAc47rwMbN+6mXbtGXodkooiILFbVKo2NEEiJ4jER+UFEHhCRLlXZSNTb+QPE1bYkYTyxZ08uN9zwKRdc8AY5OQWIiCUJE1YVPkehqmeIyLE4gxg9KyINgLdU9cGQRxcp0q1bceOdceNmUK9eLdasmUDjxrW9DsdUQwHdHqGqW1T1aWAszjMV94Y0qkiTYd2Km/D6+eedDB/+Ltu3H+Tlly9i6tQLLEkYzwTywN1JInK/iKwESu54ahnyyCKFFjsj2lmJwoRBXl4hDz44l379nqd372YkJSUQH299MxlvBdKFx4vAW8AQVd0U4ngiT/YKqN0E6pd+qNyY4CoqKiYjYy9Ll25h8eLRtGlzxLOnxngikDaKU8IRSMSyYU9NiGVnH+D2278kObk2jz8+hPfeu8zrkIw5TLlVTyLytvtzpYis8Hmt9Bn5LvbZsKcmhF5+eRldukwmJaUOEyfaBYmJTP5KFDe5P88PRyARqbgQsr6GIS94HYmJMVlZe2nRwun6+4svrqJ792M9jsiY8pVbolDVze7b8ar6q+8LGB+e8Dy2dQnUbwV1InuYDBM9DhzI5847v6Rnz2fZtu0AI0f2sCRhIl4gt8eeVcZ35wQ7kIhk7RMmiNau3U7nzs+QlbWPlSvH0bRpXa9DMiYg5VY9icg4nJLDcaXaJOoD34Y6sIiQPgu6j/M6ChPlMjP3kp19gE6dUnj55YsYOLCt1yEZUyn+ShSvAxfg9Ph6gc+rt6peFYbYvFWUD5vmQauBXkdiolRhYTFPPPEdPXpM4fvvs0hIiLMkYaKSv8ZsVdWNIjKh9AQRaayqO0MYl/c2L3DGnki0PnVM1YwY8T47dhxk3rxr6dgx2etwjKkyf4nidZw7nhbjDFTkOxCDAseFMC7vWbcdpgp2787l8ce/4557Tufpp4fStGldxMYwMVHO311P57s/26nqce7PkldsJwmwhmxTKarK66+vpFOnSWRnH6CgoIhjjqlnScLEhAqfzBaR04BlqnpARK4CegFPqmp6yKPzSkEObFkILU/3OhITJZYt28Ijj3zL++9fzsknV5+u0Ez1EEhfT5OB7iLSHbgNeB54BYjdVt7N30GTrlDLRg4z5cvLK+Qf//iGxMQ47ryzP0uWjKFGDStBmNgTyHMUheoMg3ch8B9VnYRzi2zssm47TAVmzfqFbt2msGzZVq68siuAJQkTswIpUewTkbuBPwCni0gNID60YXksIw1O/X9eR2EiUF5eIQkJcXz11QYeffQshg07weuQjAm5QEoUlwN5wDWqugVnLIpHQxqVl/L3Q/ZyaH6q15GYCFJcrDz77CKOP/7f7NyZw0MPnWlJwlQbgXQzvkVEXgP6iMj5wAJV/W/oQ/NI1jdwTG+Ir+N1JCZCbNiwixEj3kcEZsy40kaaM9VOICPcXQYsAC7FGTf7exG5JNSBeSZ9FrSy9gkD+/fnk5W1l6SkBK67rifffHMN3bod43VYxoRdIFVPfwH6qOpIVb0a6Av8LbRheSgjDVrb8xPV3UcfraVz52d4/fWVJCfX4dpre1ljtam2AmnMrqGq23w+7yCwBBN9cnfDzrVwbD+vIzEeuu666XzzTTrTpl3IGWe08zocYzwXyAn/cxGZKSKjRGQUMJ6jS4IAABjcSURBVAP4NLRheSRzLjQ7GeISvI7EhFlBQRGvv74SVeXGG/uyfPlYSxLGuAJpzL5DRP4P6O9+NVVVPwhtWB6x/p2qpe++y2Ds2Bkcc0xdzjuvgw0kZEwp/saj6AD8C2gPrARuV9WscAXmiYw0OGuq11GYMJo/P5OLL36bxx8fwuWXd7a+mYwpg78SxYvAf4G5OONQ/Bv4v3AE5YmD2bBno3NrrIlpqsqrr64gISGOSy/txNq1N9CggVU3GlMef4mivqo+575fJyJLwhGQZzLnOJ0A1gikfd9Eq3XrtjN+/Kfs2pXDs8+ej4hYkjCmAv7Oioki0pND41DU9v2sqrGVONJnWbfi1cC9985m2LCOTJjQl7i42Lx5z5hg85coNgOP+3ze4vNZgdhq9U2fBV2v9zoKEwJffvkz9947m5kzr+LNNy+2dghjKqncRKGq1efyev8myNkGTbt7HYkJoq1b93PLLTP57rtM/vOfc6yKyZgqsgp5cO52ajkIxKoiYkFRUTG5uYXs2ZNHmzZJPP/8MOrUie0Oj40JpZCeGUVkqIisE5H1InKXn/kuFhEVkdRQxlOudBv2NFYsXbqZU099kaee+p6OHZP5+98HW5Iw5iiFLFGISE1gEnAO0Am4QkQ6lTFffeAm4PtQxVIhe9AuJtxzz1cMHfoaY8b05q67+le8gDEmIIH0HisicpWI3Ot+bi0ifQNYd19gvapuUNV84E2cUfJKewD4J5BbibiDZ89GKDgAyUfkMBMFVJWFC53nQE8+uSWrVo3jmmt6Wgd+xgRRICWKZ4BTgCvcz/twSgoVaQFk+HzOdL/7jYj0Alqp6gx/KxKR0SKySEQWZWdnB7DpSshwq53sTpios3Hjbi644A1GjfqI/fvzGTbsBFJS6nodljExJ5BE0U9VJ+Be8avqLqDW0W7YHVL1ceC2iuZV1amqmqqqqSkpKUe76cNlWPtENJo3L4PU1Kmcdlorli4dQ716R/0naYwpRyB3PRW47Q0KICIpQHEAy2UBrXw+t3S/K1Ef6ALMdu9rPxaYLiLDVHVRAOs/eqrO8xMnx+7wGrHmm2/SqVFD6N27GQsXXk+7do28DsmYmBdIieJp4AOgqYg8BHwDPBzAcguBDiLSTkRqAcOB6SUTVXWPqjZR1baq2haYD4QvSQDsXu/8bHh82DZpqmbHjoNcd910hg9/lz17cklIiLMkYUyYBNLN+Gsishg4E6f7jotU9YcAlisUkRuAmUBN4EVVXS0iE4FFqjrd/xrCIN2928naJyLeJZe8Q9euTVmzZoI9OGdMmImq+p9BpHVZ36tqekgiqkBqaqouWhSkQscnw6HtUOgyKjjrM0H1ww/ZPPLIPKZMOQ9VSEy050ONqSoRWayqVXpWLZCqpxnAJ+7Pr4ANwGdV2VhEUbXxsSNUTk4Bf/3rLAYMmEavXscSF1fDkoQxHgqk6qmr72f3ltbxIYsoXHasgfh60KCN15EYH6rK4sWb+fHHHSxfPpbmzet7HZIx1V6lL9NUdYmI9AtFMGFl3YpHlE2b9nHLLTPp27c5t912Kv37l1njaYzxQIWJQkRu9flYA+gFbApZROGSkQYdL/E6CgNMmrSA+++fw5gxvRk/vo/X4RhjSgmkROFb9i/Eaat4LzThhIkWQ+ZsODOQB8xNqGzbdoCmTeuSm1vInDmj6NQpyA9TGmOCwm+icB+0q6+qt4cpnvDYthzqHAP1mnkdSbW0d28ef/3rLD76aB1r107gtttO9TokY4wf5d71JCJxqloEnBbGeMIjw9onvLJgQRadOk3i4MECliwZTe3a1gW4MZHOX4liAU57xDIRmQ68Axwomaiq74c4ttBJnwVd/uh1FNXKhg27AGjfvhFvvnmJNVYbE0UCeY4iEdiBM0b2+cAF7s/oVFQAWd84I9qZkMvPL+Lhh7+mb9/nWLgwi+TkOpYkjIky/koUTd07nlbhdAjo28+F/8e5I9nWxZDUFuo08TqSmKeqnH32K9SrV4tFi0bTtm1Dr0MyxlSBv0RRE6jH4QmiRPQmCutWPOS2bz/ICy8s4c9/Po1XX/0/WrSoj1h/WsZELX+JYrOqTgxbJOGSPgt63uh1FDGpuFiZNm0Zd9/9FVde2YX8/CJatmzgdVjGmKPkL1HE3iVgYR5sng8XvON1JDHps89+YsqURXz++Qh69rRbj42JFf4SxZlhiyJctnwPjU+ERKsrD5aDBwt48MG5dOqUwogRXRk69Hhq1gzkHgljTLQo9z9aVXeGM5CwSLf2iWD69NOf6Nz5GX75ZTeDBx+HiFiSMCYGVa++mzNmQd+7vY4i6hUUFBEXV4P33/+BZ589n7PPbu91SMaYEKo+l38FB51bY1v09zqSqFVYWMyTT86na9fJFBQU8/zzwyxJGFMNVJ8SxaZ5kNIdatXzOpKotGrVNkaO/JCkpAQ+/HA4tWrV9DokY0yYVJ9EkZHmjI9tKmXPnlyKi5VatWpy8839uOqqbvZMhDHVTPWperKBiipFVXnrrVV06vQM06evo2PHZP7wh+6WJIyphqpHiSJ/H2xfCc1O8TqSqKCqXHTRW/zyyy7eeedSTj21ldchGWM8VD0SRebXcGwfiK/tdSQRLS+vkM8/X8+FF57InXeeRp8+zYmPt7YIY6q76lH1lJEGrax9wp/ZszfSo8ezvPjiMgoKijj11FaWJIwxQHVJFNY+4deHH67l6qs/4O9/P5OPPhpuCcIYc5jYr3rK3QW7f4Jmfb2OJKIUFysvvriUDh0ac845x7NmzQTq1avldVjGmAgU+yWKjDlOI3ZNOwmWWLlyK6ef/hIvvLCUxo1rk5AQZ0nCGFOu2C9RZMyy5yd8qCo33PAZV1/djeuv702NGna7qzHGv2pQorCOAAE+/ngdQ4a8SlGRMnv2SMaMSbUkYYwJSGyXKA5ug30ZcEwvryPxTEbGHm666XNWrdrG5MnnERcX+9cGxpjgiu1EkTEbWpwONWJ7N8tSWFhMcbGyYcMuunc/htdfv5jExOp3HIwxRy+2Ly/Tq2f7xPffZ5KaOpXXXlvBwIFtue++QZYkjDFVFtuJopo9aFdcrIwfP4OLLnqLP//5NEaN6uF1SMaYGBDSRCEiQ0VknYisF5G7yph+q4isEZEVIvKViLQJ2sb3ZUHODkjpGrRVRipVZdWqbdSoIZxySkvWrBnPlVd2tQ78jDFBEbJEISI1gUnAOUAn4AoR6VRqtqVAqqp2A94FHglaABlp0GoQSGwXmn76aQdnn/0q1147naKiYv7wh+40amR9WhljgieUZ9G+wHpV3aCq+cCbwIW+M6hqmqoedD/OB1oGbevVoNuOjz9exymnvMC55x7Pt99eY+NVG2NCIpQtnC2ADJ/PmUA/P/NfC3xW1gQRGQ2MBmjdunVgW89Igz53BDZvlPnf/zbQqlUDTj21FUuXjqFVqySvQzLGxLCIuAQVkauAVODRsqar6lRVTVXV1JSUlIpXuOcXKMqFxicGN1CPbd26n6uuep/rrptOdvZBkpPrWJIwxoRcKEsUWYDviDct3e8OIyKDgb8AA1U1LyhbTnefxo6hxtziYuV3v/sv55/fgdWrx1O3rvXNZIwJj1AmioVABxFph5MghgNX+s4gIj2BZ4GhqrotaFvOiJ32ieXLt/DSS8t44okhLFhwnSUIY0zYhazqSVULgRuAmcAPwNuqulpEJorIMHe2R4F6wDsiskxEpgdhw077RJQ/aLd/fz633/4FZ531Cp07p6CKJQljjCdC+riuqn4KfFrqu3t93g8O+kZ3/QhSE5KOC/qqw0VV+eSTH8nOPsiqVeNp2rSu1yEZY6qx2OvXoaQ0EYXtE7/+ups//elzrryyC8OHOy9jjPFaRNz1FFRR+PxEUVExjz76Lb17T6VPn+ZcdFFs3a1ljIlusVWi0GKnRDHwX15HErBdu3Jo2DCR3btzmT//Oo4/vrHXIRljzGFiq0SxfTUkJEGDAB/K89DOnTmMGfMxgwa9jCo89NCZliSMMREpthJFxqyo6C32yy9/pnPnZ6hVqyZz546ykeaMMREttqqe0tPgxOFeR1GutWu306RJHdq1a8T06cPp06eF1yEZY0yFYqdEUVwEmXOcHmMjTE5OAffem0b//i+ydOlmjj++sSUJY0zUiJ0SRfYyqNcc6h7rdSSHKSwspm/f5znhhGSWLx9LixYNvA7JGGMqJXYSRYTdFrtly34++mgtY8ak8tFHwznuuEZeh2SMMVUSO1VPEdJtR1FRMc88s5CuXSezceNuVNWShDEmqsVGiaKoALK+gXNe8ToSnn9+CW+8sYrZs0fSuXNTr8MxxpijFhuJYusiSGoPtZM92fy+fXncd99sLrigI9de24vrr+9tt7waY2JGbFQ9pc+C1uFvn1BV3n//Bzp1eoZdu3Lp2vUY4uJqWJIwxsSU2ChRZKRBr5vDusmiomKKi5VXXlnBq6/+noED24Z1+8YYEy7RX6IozIPN30PL08OyuYKCIv75z28YMGAacXE1+OCDyy1JGGNiWvSXKDbPh+ROTh9PIbZgQRbXXPMRrVsn8corv0eisCtzY4yprOhPFGF4fmLHjoPUrVuL/Pwi7rtvIJdc0smShDGm2oj+qqcQPj+hqkybtozOnZ8hLe0X+vdvzaWXdrYkYYypVqK7RFFwELYtgRanBX3V+flFDBnyKvv35zNjxpX07t086NswxphoEN2JIutbaNoT4oM3pnROTgHz5mVw5pnH8Ze/nM4ZZ7SlZs3oL3gZY0xVRfcZMMjjT3z++Xq6dJnMyy8vR1UZPPg4SxLGmGovuksU6bNgwD+DsqopUxbx6KPzmDTpXIYOPT4o6zTGmFgQvYkibw/sWAPNTq7yKoqKipk8eRGDBx/HFVd0YeTI7tSuHR/EII0xJvpFb6LI/Bqa9YW4xCotvnjxJsaM+YR69WoxZEh7kpKqth5jjAm3goICMjMzyc3NPWJaYmIiLVu2JD4+eBe90ZsoMtKq3D6Rm1vIqFEfcfvtp3D11d3tdldjTFTJzMykfv36tG3b9rDzl6qyY8cOMjMzadeuXdC2F70ttZV80E5Veeed1YwY8T4JCTVZvnwsI0f2sCRhjIk6ubm5JCcnH3H+EhGSk5PLLGkcjegsUeTsgD0/w7F9App9w4ZdTJjwKRkZe5gy5XxEBMsPxphoVt5FbigufqMzUWTOgeanQU3/dXD5+UXEx9dgwYIszjijLbfccjLx8TXDE6MxxsSI6EwU6RV32zFnzkbGjZvBE08MYfjwLmEKzBhjYk90JoqMWTD05TIn5eQUMG7cDL766heefnooZ5/dPszBGWNM6KlqmdVMqhr0bUVfY3ZxAezf5HTd4ft1sbJ+/U4SE+Po06c5a9aM5/e/P8kaq40xMScxMZEdO3YckRRK7npKTAzu7f7RV6LI3wctB0CNQ20Nq1dvY+zYGTRokMCMGVcyYUJfDwM0xpjQatmyJZmZmWRnZx8xreQ5imCKzkTh0z4xbdoy7rjjSyZOHMTo0b29i8sYY8IkPj4+qM9JVERCUZ/128pFhgJPATWB51X1H6WmJwD/BXoDO4DLVXWjv3Wmtk3URQsX8OnC2vTt24IDB/JJSIjj2GPrhWYnjDEmBojIYlVNrcqyIWujEJGawCTgHKATcIWIdCo127XALlU9HngCqLCHv/wC5eKxP3DTTZ+TlbWXNm0aWpIwxpgQCmVjdl9gvapuUNV84E3gwlLzXAiU3L70LnCmVND6vHZrY7p0acrKlePo3v3YoAdtjDHmcKFso2gBZPh8zgT6lTePqhaKyB4gGdjuO5OIjAZGux/zJk783aqJE0MSc7RpQqljVY3ZsTjEjsUhdiwOOaGqC0ZFY7aqTgWmAojIoqrWs8UaOxaH2LE4xI7FIXYsDhGRRVVdNpRVT1lAK5/PLd3vypxHROKAJJxGbWOMMREilIliIdBBRNqJSC1gODC91DzTgZHu+0uAWRrK27CMMcZUWsiqntw2hxuAmTi3x76oqqtFZCKwSFWnAy8Ar4jIemAnTjKpyNRQxRyF7FgcYsfiEDsWh9ixOKTKxyKkz1EYY4yJftHX15MxxpiwskRhjDHGr4hNFCIyVETWich6EbmrjOkJIvKWO/17EWkb/ijDI4BjcauIrBGRFSLylYi08SLOcKjoWPjMd7GIqIjE7K2RgRwLEbnM/dtYLSKvhzvGcAngf6S1iKSJyFL3/+RcL+IMNRF5UUS2iciqcqaLiDztHqcVItIroBWrasS9cBq/fwaOA2oBy4FOpeYZD0xx3w8H3vI6bg+PxRlAHff9uOp8LNz56gNzgflAqtdxe/h30QFYCjRyPzf1Om4Pj8VUYJz7vhOw0eu4Q3QsBgC9gFXlTD8X+AwQ4GTg+0DWG6klipB0/xGlKjwWqpqmqgfdj/NxnlmJRYH8XQA8gNNvWHBHmI8sgRyL64FJqroLQFW3hTnGcAnkWCjQwH2fBGwKY3xho6pzce4gLc+FwH/VMR9oKCLNKlpvpCaKsrr/aFHePKpaCJR0/xFrAjkWvq7FuWKIRRUeC7co3UpVZ4QzMA8E8nfREegoIt+KyHy3N+dYFMixuB+4SkQygU+BG8MTWsSp7PkEiJIuPExgROQqIBUY6HUsXhCRGsDjwCiPQ4kUcTjVT4NwSplzRaSrqu72NCpvXAFMU9XHROQUnOe3uqhqsdeBRYNILVFY9x+HBHIsEJHBwF+AYaqaF6bYwq2iY1Ef6ALMFpGNOHWw02O0QTuQv4tMYLqqFqjqL8CPOIkj1gRyLK4F3gZQ1e+ARJwOA6ubgM4npUVqorDuPw6p8FiISE/gWZwkEav10FDBsVDVParaRFXbqmpbnPaaYapa5c7QIlgg/yMf4pQmEJEmOFVRG8IZZJgEcizSgTMBROQknERx5DiisW86cLV799PJwB5V3VzRQhFZ9aSh6/4j6gR4LB4F6gHvuO356ao6zLOgQyTAY1EtBHgsZgJni8gaoAi4Q1VjrtQd4LG4DXhORG7BadgeFYsXliLyBs7FQRO3PeY+IB5AVafgtM+cC6wHDgJ/DGi9MXisjDHGBFGkVj0ZY4yJEJYojDHG+GWJwhhjjF+WKIwxxvhlicIYY4xflihMRBKRIhFZ5vNq62fe/UHY3jQR+cXd1hL36d3KruN5Eenkvr+n1LR5Rxuju56S47JKRD4WkYYVzN8jVntKNeFjt8eaiCQi+1W1XrDn9bOOacAnqvquiJwN/EtVux3F+o46porWKyIvAz+q6kN+5h+F04PuDcGOxVQfVqIwUUFE6rljbSwRkZUickSvsSLSTETm+lxxn+5+f7aIfOcu+46IVHQCnwsc7y57q7uuVSJys/tdXRGZISLL3e8vd7+fLSKpIvIPoLYbx2vutP3uzzdF5DyfmKeJyCUiUlNEHhWRhe44AWMCOCzf4XboJiJ93X1cKiLzROQE9ynlicDlbiyXu7G/KCIL3HnL6n3XmMN53X+6vexV1gvnSeJl7usDnF4EGrjTmuA8WVpSIt7v/rwN+Iv7viZO309NcE78dd3v7wTuLWN704BL3PeXAt8DvYGVQF2cJ99XAz2Bi4HnfJZNcn/Oxh3/oiQmn3lKYvw98LL7vhZOT561gdHAX93vE4BFQLsy4tzvs3/vAEPdzw2AOPf9YOA99/0o4D8+yz8MXOW+b4jT/1Ndr3/f9orsV0R24WEMkKOqPUo+iEg88LCIDACKca6kjwG2+CyzEHjRnfdDVV0mIgNxBqr51u3epBbOlXhZHhWRv+L0AXQtTt9AH6jqATeG94HTgc+Bx0TknzjVVV9XYr8+A54SkQRgKDBXVXPc6q5uInKJO18STgd+v5RavraILHP3/wfgS5/5XxaRDjhdVMSXs/2zgWEicrv7ORFo7a7LmDJZojDRYgSQAvRW1QJxeodN9J1BVee6ieQ8YJqIPA7sAr5U1SsC2MYdqvpuyQcRObOsmVT1R3HGvTgXeFBEvlLViYHshKrmishsYAhwOc4gO+CMOHajqs6sYBU5qtpDROrg9G00AXgaZ7CmNFX9vdvwP7uc5QW4WFXXBRKvMWBtFCZ6JAHb3CRxBnDEuODijBW+VVWfA57HGRJyPnCaiJS0OdQVkY4BbvNr4CIRqSMidXGqjb4WkebAQVV9FadDxrLGHS5wSzZleQunM7aS0gk4J/1xJcuISEd3m2VSZ0TDPwG3yaFu9ku6ix7lM+s+nCq4EjOBG8UtXonT87AxflmiMNHiNSBVRFYCVwNry5hnELBcRJbiXK0/parZOCfON0RkBU6104mBbFBVl+C0XSzAabN4XlWXAl2BBW4V0H3Ag2UsPhVYUdKYXcoXOINL/U+doTvBSWxrgCUisgqn23i/JX43lhU4g/I8Avzd3Xff5dKATiWN2Tglj3g3ttXuZ2P8sttjjTHG+GUlCmOMMX5ZojDGGOOXJQpjjDF+WaIwxhjjlyUKY4wxflmiMMYY45clCmOMMX79f/8g8+FLvh0+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA_CvL72Twcz"
      },
      "source": [
        "Se puede ver lo alejado que estamos del 100%, este problema no debe ser realizado con svm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_iF_RRosKK-",
        "outputId": "484dc409-2764-4d63-a3f8-ba1b7fc90913"
      },
      "source": [
        "# compute the confusion matrix and and use it to derive the raw\n",
        "# accuracy, sensitivity, and specificity\n",
        "cm = confusion_matrix(y_test, y_pred_l)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[134  22]\n",
            " [ 20 163]]\n",
            "acc: 0.8761\n",
            "sensitivity: 0.8590\n",
            "specificity: 0.8907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-BqrZCmwCcw",
        "outputId": "d5a9a165-972c-4a13-95a6-57dcb1596f1a"
      },
      "source": [
        "# compute the confusion matrix and and use it to derive the raw\n",
        "# accuracy, sensitivity, and specificity\n",
        "cm = confusion_matrix(y_test, y_pred_r)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 12 144]\n",
            " [  0 183]]\n",
            "acc: 0.5752\n",
            "sensitivity: 0.0769\n",
            "specificity: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ekEczjewJMm"
      },
      "source": [
        "# **Red Neuronal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLLR1_RBwPlb"
      },
      "source": [
        "## Cargar las imágenes en X,y con un solo canal\n",
        "def get_data_one_channel(folder):\n",
        "    \"\"\"\n",
        "    Cargar los datos y las etiquetas desde una carpeta dada.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for mask_type in os.listdir(folder):\n",
        "        if not mask_type.startswith('.'):\n",
        "            if mask_type in ['correcto']:\n",
        "                ## tapabocas bien puesto\n",
        "                label = '0'\n",
        "            else:\n",
        "                ## tapabocas mal puesto\n",
        "                label = '1'\n",
        "            for image_filename in os.listdir(folder + mask_type):\n",
        "                img_file = cv2.imread(folder + mask_type + '/' + image_filename)\n",
        "                if img_file is not None:\n",
        "                    image = cv2.cvtColor(img_file, cv2.COLOR_BGR2GRAY) ## esto se aplicado para lograr obtenerlas en un canal\n",
        "                    image = cv2.resize(image, (224, 224))\n",
        "                    img_arr = np.asarray(image)\n",
        "                    X.append(img_arr)\n",
        "                    y.append(label)\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    return X,y"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETCIPhlhwoNq"
      },
      "source": [
        "X_train_one_channel, y_train_one_channel = get_data_one_channel(BASE_DIR + 'train/')\n",
        "X_test_one_channel, y_test_one_channel = get_data_one_channel(BASE_DIR + 'test/')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2qwRMOHxIPb"
      },
      "source": [
        "X_train_rn = X_train_one_channel\n",
        "X_test_rn = X_test_one_channel \n",
        "y_train_rn = y_train_one_channel\n",
        "y_test_rn = y_test_one_channel"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEhhdhBexOn3",
        "outputId": "8cbc7774-e5cf-4147-8727-e6b469c68f52"
      },
      "source": [
        "X_train_rn.shape, y_train_rn.shape, X_test_rn.shape, y_test_rn.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1251, 224, 224), (1251,), (339, 224, 224), (339,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "pN7koQ6m11qL",
        "outputId": "e50e2589-4574-4c65-a0c8-c92b6cdf9cf8"
      },
      "source": [
        "plt.imshow(X_train_rn[150,:,:]),y_train_rn[150]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<matplotlib.image.AxesImage at 0x7fa3d0529b50>, '0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8-lKqlZzLsT"
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "num_pixels = X_train_rn.shape[1] * X_train_rn.shape[2]\n",
        "X_train_rn = X_train_rn.reshape(X_train_rn.shape[0], num_pixels) .astype('float32')\n",
        "X_test_rn = X_test_rn.reshape(X_test_rn.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalizamos las imágenes desde 0-255 to 0-1\n",
        "X_train_rn = X_train_rn / 255\n",
        "X_test_rn = X_test_rn / 255\n",
        "\n",
        "# normalizamos los labels\n",
        "y_train_rn = np_utils.to_categorical(y_train_rn)\n",
        "y_test_rn = np_utils.to_categorical(y_test_rn)\n",
        "num_classes = y_test_rn.shape[1]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiDwwB6g1es-",
        "outputId": "2055ff36-5699-4e38-fbec-1feb6619cd33"
      },
      "source": [
        "num_pixels, num_classes"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50176, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUMesAFazUVf"
      },
      "source": [
        "## modelo básico con función de activación softmax y compilando con categorical_crossentpy\n",
        "def baseline_model():\n",
        "    model = Sequential()\n",
        "    ## una capa densa con el número de pixeles como entrada\n",
        "    model.add(Dense(32, input_dim=num_pixels, activation='relu'))\n",
        "    ## capas densas intermedias\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.summary()\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8Q4At1jzeWa",
        "outputId": "c56ff390-00a5-4109-e903-14da133ee320"
      },
      "source": [
        "## instancia y descripción del modelo\n",
        "model = baseline_model()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 32)                1605664   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 1,620,290\n",
            "Trainable params: 1,620,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E15Ncv8P2bMM",
        "outputId": "e0462197-c250-42f8-a7c9-3afb677964ae"
      },
      "source": [
        "X_test_rn.shape, y_test_rn.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((339, 50176), (339, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue34PZA9zqaX",
        "outputId": "479fb86c-7bb9-44b0-af04-bcec59e93528"
      },
      "source": [
        "model.fit(X_train_rn, y_train_rn, validation_data=(X_test_rn, y_test_rn), epochs=20, batch_size=64, verbose=2)\n",
        "\n",
        "scores = model.evaluate(X_test_rn, y_test_rn, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "20/20 - 1s - loss: 0.6969 - accuracy: 0.5092 - val_loss: 0.7450 - val_accuracy: 0.4543\n",
            "Epoch 2/20\n",
            "20/20 - 0s - loss: 0.6967 - accuracy: 0.5204 - val_loss: 0.6675 - val_accuracy: 0.6667\n",
            "Epoch 3/20\n",
            "20/20 - 0s - loss: 0.6514 - accuracy: 0.6411 - val_loss: 0.7126 - val_accuracy: 0.4808\n",
            "Epoch 4/20\n",
            "20/20 - 0s - loss: 0.6913 - accuracy: 0.5500 - val_loss: 0.7745 - val_accuracy: 0.5487\n",
            "Epoch 5/20\n",
            "20/20 - 0s - loss: 0.6461 - accuracy: 0.6379 - val_loss: 0.6657 - val_accuracy: 0.5900\n",
            "Epoch 6/20\n",
            "20/20 - 0s - loss: 0.6187 - accuracy: 0.6451 - val_loss: 0.5939 - val_accuracy: 0.6873\n",
            "Epoch 7/20\n",
            "20/20 - 0s - loss: 0.6106 - accuracy: 0.6715 - val_loss: 0.6604 - val_accuracy: 0.5664\n",
            "Epoch 8/20\n",
            "20/20 - 0s - loss: 0.5927 - accuracy: 0.6843 - val_loss: 0.5743 - val_accuracy: 0.7021\n",
            "Epoch 9/20\n",
            "20/20 - 0s - loss: 0.5517 - accuracy: 0.7130 - val_loss: 0.6291 - val_accuracy: 0.6283\n",
            "Epoch 10/20\n",
            "20/20 - 0s - loss: 0.5813 - accuracy: 0.7114 - val_loss: 0.6774 - val_accuracy: 0.6224\n",
            "Epoch 11/20\n",
            "20/20 - 0s - loss: 0.5661 - accuracy: 0.7090 - val_loss: 0.5996 - val_accuracy: 0.6755\n",
            "Epoch 12/20\n",
            "20/20 - 0s - loss: 0.5397 - accuracy: 0.7322 - val_loss: 0.5570 - val_accuracy: 0.7080\n",
            "Epoch 13/20\n",
            "20/20 - 0s - loss: 0.5928 - accuracy: 0.7234 - val_loss: 0.6825 - val_accuracy: 0.5723\n",
            "Epoch 14/20\n",
            "20/20 - 0s - loss: 0.5740 - accuracy: 0.7114 - val_loss: 0.6207 - val_accuracy: 0.6667\n",
            "Epoch 15/20\n",
            "20/20 - 0s - loss: 0.5158 - accuracy: 0.7530 - val_loss: 0.5313 - val_accuracy: 0.7316\n",
            "Epoch 16/20\n",
            "20/20 - 0s - loss: 0.5038 - accuracy: 0.7490 - val_loss: 0.5229 - val_accuracy: 0.7463\n",
            "Epoch 17/20\n",
            "20/20 - 0s - loss: 0.5142 - accuracy: 0.7274 - val_loss: 0.5345 - val_accuracy: 0.7109\n",
            "Epoch 18/20\n",
            "20/20 - 0s - loss: 0.5571 - accuracy: 0.7130 - val_loss: 0.5837 - val_accuracy: 0.7581\n",
            "Epoch 19/20\n",
            "20/20 - 0s - loss: 0.4894 - accuracy: 0.7730 - val_loss: 0.5192 - val_accuracy: 0.7463\n",
            "Epoch 20/20\n",
            "20/20 - 0s - loss: 0.5128 - accuracy: 0.7530 - val_loss: 0.5479 - val_accuracy: 0.7404\n",
            "Baseline Error: 25.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIZiCe5X3UpI"
      },
      "source": [
        "# crear un modelo secuencial creando capas densas \n",
        "def create_dense(layer_sizes):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(layer_sizes[0] , input_dim=num_pixels, activation='relu'))\n",
        "    for s in layer_sizes[1:]:\n",
        "        model.add(Dense(units = s, activation = 'relu'))\n",
        "\n",
        "    model.add(Dense(units=num_classes, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eTc82jg3VCE"
      },
      "source": [
        "## evaluar un modelo indicado, mostrando el resúmen, compilando con categorical_crossentropy, entrenando y mostrando el resultado.\n",
        "def evaluate(model, batch_size=128, epochs=5):\n",
        "    model.summary()\n",
        "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train_rn, y_train_rn, validation_data=(X_test_rn, y_test_rn), epochs=epochs, batch_size=batch_size, verbose=2)\n",
        "    scores = model.evaluate(X_test_rn, y_test_rn, verbose=0)\n",
        "    print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNaAJO9n3X9n",
        "outputId": "43365e99-a532-4c1a-d1f4-ec145994ca6d"
      },
      "source": [
        "# ir añadiendo capas densas cada una de 64 neuronas\n",
        "for layers in range(1, 5):\n",
        "    model = create_dense([64] * layers)\n",
        "    evaluate(model)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_17 (Dense)             (None, 64)                3211328   \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 3,211,458\n",
            "Trainable params: 3,211,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.7684 - accuracy: 0.5324 - val_loss: 0.7126 - val_accuracy: 0.4631\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6814 - accuracy: 0.5556 - val_loss: 0.7074 - val_accuracy: 0.4631\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6687 - accuracy: 0.5715 - val_loss: 0.6579 - val_accuracy: 0.5929\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6518 - accuracy: 0.5987 - val_loss: 0.7858 - val_accuracy: 0.4543\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6163 - accuracy: 0.6811 - val_loss: 0.5930 - val_accuracy: 0.7168\n",
            "Baseline Error: 28.32%\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_19 (Dense)             (None, 64)                3211328   \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 3,215,618\n",
            "Trainable params: 3,215,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 2.0171 - accuracy: 0.5012 - val_loss: 0.6980 - val_accuracy: 0.4572\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6935 - accuracy: 0.4588 - val_loss: 0.6918 - val_accuracy: 0.5221\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6776 - accuracy: 0.5643 - val_loss: 0.6478 - val_accuracy: 0.6962\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6710 - accuracy: 0.6027 - val_loss: 0.6994 - val_accuracy: 0.4543\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6659 - accuracy: 0.5588 - val_loss: 0.8447 - val_accuracy: 0.4602\n",
            "Baseline Error: 53.98%\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_22 (Dense)             (None, 64)                3211328   \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 3,219,778\n",
            "Trainable params: 3,219,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.9690 - accuracy: 0.4860 - val_loss: 0.7150 - val_accuracy: 0.4602\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6945 - accuracy: 0.5092 - val_loss: 0.6797 - val_accuracy: 0.5929\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6783 - accuracy: 0.6131 - val_loss: 0.7100 - val_accuracy: 0.5428\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.7018 - accuracy: 0.5508 - val_loss: 0.6753 - val_accuracy: 0.5516\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6733 - accuracy: 0.5612 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
            "Baseline Error: 33.33%\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_26 (Dense)             (None, 64)                3211328   \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 3,223,938\n",
            "Trainable params: 3,223,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.6817 - accuracy: 0.5476 - val_loss: 0.6454 - val_accuracy: 0.6726\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.7036 - accuracy: 0.5372 - val_loss: 0.6805 - val_accuracy: 0.5929\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6665 - accuracy: 0.6235 - val_loss: 0.6516 - val_accuracy: 0.6106\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6671 - accuracy: 0.6083 - val_loss: 0.7099 - val_accuracy: 0.4631\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6517 - accuracy: 0.6323 - val_loss: 0.7356 - val_accuracy: 0.4631\n",
            "Baseline Error: 53.69%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhbQoDRmcVE5"
      },
      "source": [
        "**Resultados:**\n",
        "\n",
        "No se ha obtenido un buen resultado, el mejor ha sido utilizar solo una capa densa de 64, pero solo obteniendo un valor para accuracy de 71.68%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-HWvmmI4Krc",
        "outputId": "97300905-62c4-407d-aab1-342880b6c3ef"
      },
      "source": [
        "## Vamos a intentar ir agregando i capas densas de diferentes tamaños.\n",
        "for i in range(1,5):\n",
        "  for nodes in [32, 64, 128, 256, 512, 1024, 2048]:\n",
        "      model = create_dense([nodes]* i)\n",
        "      evaluate(model)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_129 (Dense)            (None, 32)                1605664   \n",
            "_________________________________________________________________\n",
            "dense_130 (Dense)            (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 1,605,730\n",
            "Trainable params: 1,605,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.0909 - accuracy: 0.5196 - val_loss: 0.6922 - val_accuracy: 0.5487\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6927 - accuracy: 0.5276 - val_loss: 0.6913 - val_accuracy: 0.5428\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6911 - accuracy: 0.5284 - val_loss: 0.6888 - val_accuracy: 0.5398\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6893 - accuracy: 0.5268 - val_loss: 0.6882 - val_accuracy: 0.5398\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6873 - accuracy: 0.5460 - val_loss: 0.6964 - val_accuracy: 0.4661\n",
            "Baseline Error: 53.39%\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_131 (Dense)            (None, 64)                3211328   \n",
            "_________________________________________________________________\n",
            "dense_132 (Dense)            (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 3,211,458\n",
            "Trainable params: 3,211,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.0895 - accuracy: 0.4932 - val_loss: 0.6927 - val_accuracy: 0.5339\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6917 - accuracy: 0.5444 - val_loss: 0.7096 - val_accuracy: 0.4661\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.7004 - accuracy: 0.5204 - val_loss: 0.6894 - val_accuracy: 0.5457\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6866 - val_accuracy: 0.5398\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6877 - accuracy: 0.5276 - val_loss: 0.6745 - val_accuracy: 0.5398\n",
            "Baseline Error: 46.02%\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_133 (Dense)            (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dense_134 (Dense)            (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 6,422,914\n",
            "Trainable params: 6,422,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 3.3669 - accuracy: 0.5012 - val_loss: 0.6834 - val_accuracy: 0.5900\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6669 - accuracy: 0.6195 - val_loss: 0.6717 - val_accuracy: 0.5664\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6958 - accuracy: 0.5851 - val_loss: 0.6400 - val_accuracy: 0.7227\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6457 - accuracy: 0.6267 - val_loss: 0.6160 - val_accuracy: 0.6637\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6204 - accuracy: 0.6523 - val_loss: 0.6418 - val_accuracy: 0.5870\n",
            "Baseline Error: 41.30%\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_135 (Dense)            (None, 256)               12845312  \n",
            "_________________________________________________________________\n",
            "dense_136 (Dense)            (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 12,845,826\n",
            "Trainable params: 12,845,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 2.4139 - accuracy: 0.4836 - val_loss: 0.6906 - val_accuracy: 0.4631\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6754 - accuracy: 0.5667 - val_loss: 0.7008 - val_accuracy: 0.4572\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6713 - accuracy: 0.5771 - val_loss: 0.7060 - val_accuracy: 0.4690\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6466 - accuracy: 0.5915 - val_loss: 0.6247 - val_accuracy: 0.6549\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6182 - accuracy: 0.6363 - val_loss: 0.5948 - val_accuracy: 0.6873\n",
            "Baseline Error: 31.27%\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_137 (Dense)            (None, 512)               25690624  \n",
            "_________________________________________________________________\n",
            "dense_138 (Dense)            (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 25,691,650\n",
            "Trainable params: 25,691,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 2.2395 - accuracy: 0.5468 - val_loss: 0.6715 - val_accuracy: 0.5280\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6841 - accuracy: 0.5747 - val_loss: 0.7230 - val_accuracy: 0.4572\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6681 - accuracy: 0.6331 - val_loss: 0.6459 - val_accuracy: 0.6932\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6282 - accuracy: 0.6467 - val_loss: 0.6962 - val_accuracy: 0.4720\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6370 - accuracy: 0.6067 - val_loss: 0.5851 - val_accuracy: 0.7345\n",
            "Baseline Error: 26.55%\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_139 (Dense)            (None, 1024)              51381248  \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 51,383,298\n",
            "Trainable params: 51,383,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 3.0601 - accuracy: 0.5268 - val_loss: 0.6486 - val_accuracy: 0.6726\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6853 - accuracy: 0.6019 - val_loss: 0.6408 - val_accuracy: 0.6873\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6586 - accuracy: 0.5627 - val_loss: 0.6508 - val_accuracy: 0.5900\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6278 - accuracy: 0.6555 - val_loss: 0.6370 - val_accuracy: 0.6047\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6358 - accuracy: 0.6027 - val_loss: 0.6281 - val_accuracy: 0.6519\n",
            "Baseline Error: 34.81%\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_141 (Dense)            (None, 2048)              102762496 \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 102,766,594\n",
            "Trainable params: 102,766,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 3.7163 - accuracy: 0.5811 - val_loss: 0.6399 - val_accuracy: 0.5929\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6666 - accuracy: 0.5771 - val_loss: 0.6210 - val_accuracy: 0.7139\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6357 - accuracy: 0.6579 - val_loss: 0.8254 - val_accuracy: 0.4602\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6377 - accuracy: 0.6315 - val_loss: 0.7149 - val_accuracy: 0.5605\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6012 - accuracy: 0.7050 - val_loss: 0.6109 - val_accuracy: 0.6342\n",
            "Baseline Error: 36.58%\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_143 (Dense)            (None, 32)                1605664   \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 1,606,786\n",
            "Trainable params: 1,606,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.0367 - accuracy: 0.5260 - val_loss: 0.6798 - val_accuracy: 0.5398\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.7069 - accuracy: 0.5348 - val_loss: 0.7403 - val_accuracy: 0.4602\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.7013 - accuracy: 0.5076 - val_loss: 0.6915 - val_accuracy: 0.4720\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6648 - accuracy: 0.5939 - val_loss: 0.6890 - val_accuracy: 0.4779\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6592 - accuracy: 0.5851 - val_loss: 0.6323 - val_accuracy: 0.6519\n",
            "Baseline Error: 34.81%\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_146 (Dense)            (None, 64)                3211328   \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 3,215,618\n",
            "Trainable params: 3,215,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.3291 - accuracy: 0.5188 - val_loss: 0.6993 - val_accuracy: 0.4867\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6797 - accuracy: 0.5548 - val_loss: 0.6616 - val_accuracy: 0.5575\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6632 - accuracy: 0.6059 - val_loss: 0.6642 - val_accuracy: 0.5487\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6514 - accuracy: 0.6211 - val_loss: 0.6785 - val_accuracy: 0.4926\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6452 - accuracy: 0.5859 - val_loss: 0.6202 - val_accuracy: 0.6136\n",
            "Baseline Error: 38.64%\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_149 (Dense)            (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 6,439,426\n",
            "Trainable params: 6,439,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.9845 - accuracy: 0.5068 - val_loss: 0.6715 - val_accuracy: 0.7109\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6918 - accuracy: 0.5500 - val_loss: 0.7250 - val_accuracy: 0.4572\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6618 - accuracy: 0.6155 - val_loss: 0.6402 - val_accuracy: 0.6962\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6880 - accuracy: 0.6043 - val_loss: 0.6301 - val_accuracy: 0.6755\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.7249 - accuracy: 0.5580 - val_loss: 0.7128 - val_accuracy: 0.4100\n",
            "Baseline Error: 59.00%\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_152 (Dense)            (None, 256)               12845312  \n",
            "_________________________________________________________________\n",
            "dense_153 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_154 (Dense)            (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 12,911,618\n",
            "Trainable params: 12,911,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.2957 - accuracy: 0.5180 - val_loss: 0.6749 - val_accuracy: 0.6814\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.7330 - accuracy: 0.5508 - val_loss: 0.7038 - val_accuracy: 0.4749\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.7058 - accuracy: 0.5580 - val_loss: 0.6773 - val_accuracy: 0.5457\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6761 - accuracy: 0.5731 - val_loss: 0.6458 - val_accuracy: 0.5959\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6884 - accuracy: 0.5755 - val_loss: 0.7638 - val_accuracy: 0.5487\n",
            "Baseline Error: 45.13%\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_155 (Dense)            (None, 512)               25690624  \n",
            "_________________________________________________________________\n",
            "dense_156 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_157 (Dense)            (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 25,954,306\n",
            "Trainable params: 25,954,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.7221 - accuracy: 0.5228 - val_loss: 0.7351 - val_accuracy: 0.4543\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6798 - accuracy: 0.5484 - val_loss: 0.7205 - val_accuracy: 0.5457\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6936 - accuracy: 0.6243 - val_loss: 0.7514 - val_accuracy: 0.4602\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6702 - accuracy: 0.5500 - val_loss: 0.6594 - val_accuracy: 0.5516\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6640 - accuracy: 0.5620 - val_loss: 0.6557 - val_accuracy: 0.5841\n",
            "Baseline Error: 41.59%\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_158 (Dense)            (None, 1024)              51381248  \n",
            "_________________________________________________________________\n",
            "dense_159 (Dense)            (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_160 (Dense)            (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 52,432,898\n",
            "Trainable params: 52,432,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 2.3593 - accuracy: 0.5180 - val_loss: 0.6946 - val_accuracy: 0.4602\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6815 - accuracy: 0.5556 - val_loss: 0.6635 - val_accuracy: 0.6549\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6567 - accuracy: 0.6291 - val_loss: 0.7026 - val_accuracy: 0.4661\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6165 - accuracy: 0.6787 - val_loss: 1.1686 - val_accuracy: 0.4602\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.7218 - accuracy: 0.6195 - val_loss: 0.6404 - val_accuracy: 0.5929\n",
            "Baseline Error: 40.71%\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_161 (Dense)            (None, 2048)              102762496 \n",
            "_________________________________________________________________\n",
            "dense_162 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_163 (Dense)            (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 106,962,946\n",
            "Trainable params: 106,962,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.9726 - accuracy: 0.4932 - val_loss: 0.6618 - val_accuracy: 0.6873\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6750 - accuracy: 0.5907 - val_loss: 0.6472 - val_accuracy: 0.5811\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6406 - accuracy: 0.6147 - val_loss: 0.7514 - val_accuracy: 0.5487\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6627 - accuracy: 0.6315 - val_loss: 0.6193 - val_accuracy: 0.6077\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6195 - accuracy: 0.6459 - val_loss: 0.6107 - val_accuracy: 0.6460\n",
            "Baseline Error: 35.40%\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_164 (Dense)            (None, 32)                1605664   \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 1,607,842\n",
            "Trainable params: 1,607,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.6382 - accuracy: 0.5028 - val_loss: 0.6866 - val_accuracy: 0.6726\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6917 - accuracy: 0.5404 - val_loss: 0.6800 - val_accuracy: 0.6903\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6898 - accuracy: 0.5404 - val_loss: 0.7439 - val_accuracy: 0.4602\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6889 - accuracy: 0.5460 - val_loss: 0.6460 - val_accuracy: 0.6195\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6592 - accuracy: 0.6051 - val_loss: 0.6286 - val_accuracy: 0.7050\n",
            "Baseline Error: 29.50%\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_168 (Dense)            (None, 64)                3211328   \n",
            "_________________________________________________________________\n",
            "dense_169 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_170 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_171 (Dense)            (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 3,219,778\n",
            "Trainable params: 3,219,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.7581 - accuracy: 0.4900 - val_loss: 0.6730 - val_accuracy: 0.5398\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.7003 - accuracy: 0.5372 - val_loss: 0.6652 - val_accuracy: 0.5398\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6743 - accuracy: 0.5651 - val_loss: 0.6709 - val_accuracy: 0.5487\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6678 - accuracy: 0.5971 - val_loss: 0.6434 - val_accuracy: 0.5752\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6932 - accuracy: 0.5939 - val_loss: 0.6310 - val_accuracy: 0.6903\n",
            "Baseline Error: 30.97%\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_172 (Dense)            (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dense_173 (Dense)            (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_174 (Dense)            (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_175 (Dense)            (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 6,455,938\n",
            "Trainable params: 6,455,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.7966 - accuracy: 0.5204 - val_loss: 0.7599 - val_accuracy: 0.5398\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.7126 - accuracy: 0.5580 - val_loss: 0.7295 - val_accuracy: 0.4543\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6915 - accuracy: 0.5627 - val_loss: 0.6512 - val_accuracy: 0.6726\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6561 - accuracy: 0.6283 - val_loss: 0.7047 - val_accuracy: 0.4602\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6508 - accuracy: 0.5915 - val_loss: 0.6112 - val_accuracy: 0.6637\n",
            "Baseline Error: 33.63%\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_176 (Dense)            (None, 256)               12845312  \n",
            "_________________________________________________________________\n",
            "dense_177 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_178 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_179 (Dense)            (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 12,977,410\n",
            "Trainable params: 12,977,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.1528 - accuracy: 0.5020 - val_loss: 0.6798 - val_accuracy: 0.5398\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6699 - accuracy: 0.6059 - val_loss: 0.7072 - val_accuracy: 0.4602\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6993 - accuracy: 0.5276 - val_loss: 0.6934 - val_accuracy: 0.4572\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6852 - accuracy: 0.5588 - val_loss: 0.6469 - val_accuracy: 0.6018\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6470 - accuracy: 0.6171 - val_loss: 0.6562 - val_accuracy: 0.5870\n",
            "Baseline Error: 41.30%\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_180 (Dense)            (None, 512)               25690624  \n",
            "_________________________________________________________________\n",
            "dense_181 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_182 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_183 (Dense)            (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 26,216,962\n",
            "Trainable params: 26,216,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.9212 - accuracy: 0.4924 - val_loss: 0.6737 - val_accuracy: 0.5900\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6845 - accuracy: 0.5747 - val_loss: 0.6711 - val_accuracy: 0.6106\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6561 - accuracy: 0.5883 - val_loss: 0.6281 - val_accuracy: 0.6578\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6735 - accuracy: 0.6075 - val_loss: 0.6643 - val_accuracy: 0.5251\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6443 - accuracy: 0.6235 - val_loss: 0.7955 - val_accuracy: 0.4602\n",
            "Baseline Error: 53.98%\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_184 (Dense)            (None, 1024)              51381248  \n",
            "_________________________________________________________________\n",
            "dense_185 (Dense)            (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_186 (Dense)            (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_187 (Dense)            (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 53,482,498\n",
            "Trainable params: 53,482,498\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.2269 - accuracy: 0.4916 - val_loss: 0.6714 - val_accuracy: 0.6637\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6887 - accuracy: 0.5675 - val_loss: 0.6604 - val_accuracy: 0.5664\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6516 - accuracy: 0.6091 - val_loss: 0.6743 - val_accuracy: 0.5044\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6215 - accuracy: 0.6739 - val_loss: 0.6213 - val_accuracy: 0.6667\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6893 - accuracy: 0.5899 - val_loss: 0.6410 - val_accuracy: 0.6372\n",
            "Baseline Error: 36.28%\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_188 (Dense)            (None, 2048)              102762496 \n",
            "_________________________________________________________________\n",
            "dense_189 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_190 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_191 (Dense)            (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 111,159,298\n",
            "Trainable params: 111,159,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 1.2767 - accuracy: 0.5220 - val_loss: 0.6690 - val_accuracy: 0.6342\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6641 - accuracy: 0.5979 - val_loss: 0.6373 - val_accuracy: 0.6342\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6537 - accuracy: 0.6675 - val_loss: 0.6125 - val_accuracy: 0.7463\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6344 - accuracy: 0.6563 - val_loss: 0.6477 - val_accuracy: 0.5634\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.5962 - accuracy: 0.7234 - val_loss: 0.6834 - val_accuracy: 0.4690\n",
            "Baseline Error: 53.10%\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_192 (Dense)            (None, 32)                1605664   \n",
            "_________________________________________________________________\n",
            "dense_193 (Dense)            (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_194 (Dense)            (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_195 (Dense)            (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_196 (Dense)            (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 1,608,898\n",
            "Trainable params: 1,608,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.6968 - accuracy: 0.5092 - val_loss: 0.6842 - val_accuracy: 0.5428\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6995 - accuracy: 0.5436 - val_loss: 0.6872 - val_accuracy: 0.5398\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6902 - accuracy: 0.5276 - val_loss: 0.6873 - val_accuracy: 0.6018\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6842 - accuracy: 0.6155 - val_loss: 0.6799 - val_accuracy: 0.6814\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6748 - accuracy: 0.6707 - val_loss: 0.6847 - val_accuracy: 0.5162\n",
            "Baseline Error: 48.38%\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_197 (Dense)            (None, 64)                3211328   \n",
            "_________________________________________________________________\n",
            "dense_198 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_199 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_200 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_201 (Dense)            (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 3,223,938\n",
            "Trainable params: 3,223,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.6785 - accuracy: 0.5707 - val_loss: 0.6774 - val_accuracy: 0.5900\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6919 - accuracy: 0.5444 - val_loss: 0.6618 - val_accuracy: 0.6785\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6693 - accuracy: 0.5675 - val_loss: 0.6307 - val_accuracy: 0.6460\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6631 - accuracy: 0.6227 - val_loss: 0.6189 - val_accuracy: 0.6696\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6560 - accuracy: 0.6363 - val_loss: 0.6295 - val_accuracy: 0.6490\n",
            "Baseline Error: 35.10%\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_202 (Dense)            (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dense_203 (Dense)            (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_204 (Dense)            (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_205 (Dense)            (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_206 (Dense)            (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 6,472,450\n",
            "Trainable params: 6,472,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.7036 - accuracy: 0.5108 - val_loss: 0.6691 - val_accuracy: 0.5634\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6900 - accuracy: 0.5164 - val_loss: 0.7260 - val_accuracy: 0.4602\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6924 - accuracy: 0.5787 - val_loss: 0.6888 - val_accuracy: 0.4661\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6691 - accuracy: 0.5891 - val_loss: 0.6558 - val_accuracy: 0.5841\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6279 - accuracy: 0.6299 - val_loss: 0.7826 - val_accuracy: 0.4690\n",
            "Baseline Error: 53.10%\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_207 (Dense)            (None, 256)               12845312  \n",
            "_________________________________________________________________\n",
            "dense_208 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_209 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_210 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_211 (Dense)            (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 13,043,202\n",
            "Trainable params: 13,043,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.6973 - accuracy: 0.5484 - val_loss: 0.7627 - val_accuracy: 0.4543\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6608 - accuracy: 0.5947 - val_loss: 0.6225 - val_accuracy: 0.6755\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6754 - accuracy: 0.5915 - val_loss: 0.6842 - val_accuracy: 0.5575\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6571 - accuracy: 0.5891 - val_loss: 0.6431 - val_accuracy: 0.6401\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6403 - accuracy: 0.6443 - val_loss: 0.6388 - val_accuracy: 0.6195\n",
            "Baseline Error: 38.05%\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_212 (Dense)            (None, 512)               25690624  \n",
            "_________________________________________________________________\n",
            "dense_213 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_214 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_215 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_216 (Dense)            (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 26,479,618\n",
            "Trainable params: 26,479,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.7357 - accuracy: 0.5060 - val_loss: 0.6636 - val_accuracy: 0.6254\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6603 - accuracy: 0.6163 - val_loss: 0.7806 - val_accuracy: 0.4543\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6765 - accuracy: 0.5995 - val_loss: 0.6765 - val_accuracy: 0.5546\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6423 - accuracy: 0.6075 - val_loss: 0.6335 - val_accuracy: 0.6106\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6468 - accuracy: 0.6107 - val_loss: 0.6363 - val_accuracy: 0.6696\n",
            "Baseline Error: 33.04%\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_217 (Dense)            (None, 1024)              51381248  \n",
            "_________________________________________________________________\n",
            "dense_218 (Dense)            (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_219 (Dense)            (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_220 (Dense)            (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_221 (Dense)            (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 54,532,098\n",
            "Trainable params: 54,532,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.7960 - accuracy: 0.5268 - val_loss: 0.6736 - val_accuracy: 0.5752\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6590 - accuracy: 0.6195 - val_loss: 0.7770 - val_accuracy: 0.5457\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6761 - accuracy: 0.6139 - val_loss: 0.6582 - val_accuracy: 0.5693\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6826 - accuracy: 0.5899 - val_loss: 0.6634 - val_accuracy: 0.6165\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.6136 - accuracy: 0.6914 - val_loss: 0.5914 - val_accuracy: 0.7050\n",
            "Baseline Error: 29.50%\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_222 (Dense)            (None, 2048)              102762496 \n",
            "_________________________________________________________________\n",
            "dense_223 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_224 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_225 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_226 (Dense)            (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 115,355,650\n",
            "Trainable params: 115,355,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 - 1s - loss: 0.8602 - accuracy: 0.5404 - val_loss: 0.6733 - val_accuracy: 0.5221\n",
            "Epoch 2/5\n",
            "10/10 - 0s - loss: 0.6531 - accuracy: 0.6059 - val_loss: 0.7628 - val_accuracy: 0.5457\n",
            "Epoch 3/5\n",
            "10/10 - 0s - loss: 0.6414 - accuracy: 0.6339 - val_loss: 0.6096 - val_accuracy: 0.6490\n",
            "Epoch 4/5\n",
            "10/10 - 0s - loss: 0.6243 - accuracy: 0.6547 - val_loss: 0.6626 - val_accuracy: 0.5546\n",
            "Epoch 5/5\n",
            "10/10 - 0s - loss: 0.5935 - accuracy: 0.6811 - val_loss: 0.5907 - val_accuracy: 0.6637\n",
            "Baseline Error: 33.63%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMkNdbcYCD-R"
      },
      "source": [
        "**Probamos con módelos diferentes agregando capas n capas densas por diferente número de nodos, obteniendo los mejores resultados con los siguientes parámetros:**\n",
        "\n",
        "- 1 capa 256 nodos\tacc: 68.73%, err: 31.27%\n",
        "- 1 capa 512 nodos\tacc: 73.45%, err: 26.55%\n",
        "- 3 capas 32 nodos\tacc: 70.50%, err: 29.50%\n",
        "- 3 capas 64 nodos\tacc: 69.03%, err: 30.97%\n",
        "- 4 capas 1024 nodos\tacc: 70.50%, err: 29.50%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvtFwg3k3utu"
      },
      "source": [
        "**Al parecer crear capas densas no ayuda a tener un mejor resultado, pero también somos conscientes que esto es debido a que nuestro problema se basa en reconocer formas de la imagen y es por esto que este tipo de red no nos sirve de a mucho.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HkUZOhZ374e"
      },
      "source": [
        "# **Red Neuronal Convolucional**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgquIeZ84GgS"
      },
      "source": [
        "## Reutilizamos la data ya cargada en x,y en 3 capas.\n",
        "X_train_cn = X_train_multi_channel\n",
        "y_train_cn = y_train_multi_channel\n",
        "X_test_cn = X_test_multi_channel\n",
        "y_test_cn = y_test_multi_channel"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiAafLmHE-EY",
        "outputId": "3a57316f-ed65-4ff6-dae7-c009382d6121"
      },
      "source": [
        "X_train_cn.shape, X_test_cn.shape, y_train_cn.shape ,y_test_cn.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1251, 224, 224, 3), (339, 224, 224, 3), (1251,), (339,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBb7gR_PFhzA"
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# normalizamos los valores de las imágenes de 0-255 a 0-1\n",
        "X_train_cn = X_train_cn / 255\n",
        "X_test_cn = X_test_cn / 255\n",
        "\n",
        "# normalizamos los labels en categorías\n",
        "y_train_cn = np_utils.to_categorical(y_train_cn)\n",
        "y_test_cn = np_utils.to_categorical(y_test_cn)\n",
        "num_classes = y_test_cn.shape[1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xacFk23v-Yft"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEHOHjuJF0DH"
      },
      "source": [
        "## empezaremos probando con un model stándar donde se usan 64 filtros de 5x5 y una capa densa de 128\n",
        "def baseline_model_cnn():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (5, 5), input_shape=(224, 224,3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.2)) ## apagamos el 20% de los nodos\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "famsxzZUF443",
        "outputId": "bd8fc8cd-c728-4cea-de2a-f7612a548aa6"
      },
      "source": [
        "## Construimos el model\n",
        "model = baseline_model_cnn()\n",
        "# Entrenamos con 50 épocas y 32 batchsize\n",
        "model.fit(X_train_cn, y_train_cn, validation_data=(X_test_cn, y_test_cn), epochs=50, batch_size=32)\n",
        "# Evaluamos\n",
        "scores = model.evaluate(X_test_cn, y_test_cn, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 34s 114ms/step - loss: 16.3382 - accuracy: 0.6350 - val_loss: 0.4078 - val_accuracy: 0.8466\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.2900 - accuracy: 0.8946 - val_loss: 0.5623 - val_accuracy: 0.8112\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 3s 81ms/step - loss: 0.2698 - accuracy: 0.8910 - val_loss: 0.4501 - val_accuracy: 0.7847\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.1639 - accuracy: 0.9413 - val_loss: 0.3137 - val_accuracy: 0.8732\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.1576 - accuracy: 0.9423 - val_loss: 0.3013 - val_accuracy: 0.8879\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.1089 - accuracy: 0.9599 - val_loss: 0.2685 - val_accuracy: 0.8909\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.1537 - accuracy: 0.9464 - val_loss: 0.3490 - val_accuracy: 0.8702\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0770 - accuracy: 0.9707 - val_loss: 0.2682 - val_accuracy: 0.9027\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0431 - accuracy: 0.9898 - val_loss: 0.2853 - val_accuracy: 0.9086\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0545 - accuracy: 0.9816 - val_loss: 0.2666 - val_accuracy: 0.9115\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0730 - accuracy: 0.9780 - val_loss: 0.2551 - val_accuracy: 0.9174\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0410 - accuracy: 0.9884 - val_loss: 0.2783 - val_accuracy: 0.9145\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0397 - accuracy: 0.9836 - val_loss: 0.3131 - val_accuracy: 0.9115\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0396 - accuracy: 0.9919 - val_loss: 0.3471 - val_accuracy: 0.9174\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0380 - accuracy: 0.9873 - val_loss: 0.9965 - val_accuracy: 0.8348\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1269 - accuracy: 0.9673 - val_loss: 0.2956 - val_accuracy: 0.9145\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0696 - accuracy: 0.9863 - val_loss: 0.3271 - val_accuracy: 0.9115\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0393 - accuracy: 0.9812 - val_loss: 0.4230 - val_accuracy: 0.9027\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0457 - accuracy: 0.9854 - val_loss: 0.3590 - val_accuracy: 0.9086\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0312 - accuracy: 0.9911 - val_loss: 0.3651 - val_accuracy: 0.9174\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.2983 - val_accuracy: 0.9263\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.3573 - val_accuracy: 0.9204\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.2794 - val_accuracy: 0.9233\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0272 - accuracy: 0.9908 - val_loss: 3.0390 - val_accuracy: 0.8289\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0797 - accuracy: 0.9885 - val_loss: 0.3759 - val_accuracy: 0.9115\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.4026 - val_accuracy: 0.9233\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0269 - accuracy: 0.9895 - val_loss: 0.4101 - val_accuracy: 0.9204\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.4736 - val_accuracy: 0.9115\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0202 - accuracy: 0.9970 - val_loss: 0.4364 - val_accuracy: 0.9292\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0081 - accuracy: 0.9954 - val_loss: 0.5087 - val_accuracy: 0.8879\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.4381 - val_accuracy: 0.9086\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.4455 - val_accuracy: 0.9086\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.4204 - val_accuracy: 0.9115\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.3911 - val_accuracy: 0.9174\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0061 - accuracy: 0.9996 - val_loss: 0.5114 - val_accuracy: 0.9145\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.4209 - val_accuracy: 0.9115\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.4155 - val_accuracy: 0.9292\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4264 - val_accuracy: 0.9204\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 9.8226e-04 - accuracy: 0.9999 - val_loss: 0.4831 - val_accuracy: 0.9115\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.4402 - val_accuracy: 0.9204\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4351 - val_accuracy: 0.9233\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 0.4729 - val_accuracy: 0.9174\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.5306 - val_accuracy: 0.9056\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0322 - accuracy: 0.9916 - val_loss: 0.3791 - val_accuracy: 0.9204\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0315 - accuracy: 0.9950 - val_loss: 0.3807 - val_accuracy: 0.9115\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.4499 - val_accuracy: 0.9145\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.4819 - val_accuracy: 0.9056\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.5951 - val_accuracy: 0.8879\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.5405 - val_accuracy: 0.9086\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.5364 - val_accuracy: 0.8997\n",
            "Baseline Error: 10.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ3YcBegj8or"
      },
      "source": [
        "Vemos una mejora real al usar una red convolucional, y sobre todo con un filtro, obteniendo acc: 89.97% y err: 10.03%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4NkH0VNk5Ku"
      },
      "source": [
        "## empezaremos probando con un model stándar donde se usan 64 filtros de 5x5 y una capa densa de 128\n",
        "def baseline_model_cnn_multi_filtros_1():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (5, 5), input_shape=(224, 224,3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XckrEZhslk5J",
        "outputId": "0512eb85-10e1-4eb3-9d2a-49a4e4d49df5"
      },
      "source": [
        "## Construimos el model\n",
        "model = baseline_model_cnn_multi_filtros_1()\n",
        "# Entrenamos con 50 épocas y 32 batchsize\n",
        "model.fit(X_train_cn, y_train_cn, validation_data=(X_test_cn, y_test_cn), epochs=50, batch_size=32)\n",
        "# Evaluamos\n",
        "scores = model.evaluate(X_test_cn, y_test_cn, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 6s 107ms/step - loss: 0.7645 - accuracy: 0.6329 - val_loss: 0.3427 - val_accuracy: 0.8555\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.3169 - accuracy: 0.8750 - val_loss: 0.3702 - val_accuracy: 0.8407\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.2652 - accuracy: 0.8922 - val_loss: 0.2673 - val_accuracy: 0.8968\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.2127 - accuracy: 0.9316 - val_loss: 0.3152 - val_accuracy: 0.8820\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1317 - accuracy: 0.9563 - val_loss: 0.3596 - val_accuracy: 0.8289\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1641 - accuracy: 0.9404 - val_loss: 0.8862 - val_accuracy: 0.7109\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.2163 - accuracy: 0.9110 - val_loss: 0.2550 - val_accuracy: 0.8702\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1018 - accuracy: 0.9592 - val_loss: 0.2656 - val_accuracy: 0.8997\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0887 - accuracy: 0.9631 - val_loss: 0.2507 - val_accuracy: 0.8909\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0377 - accuracy: 0.9842 - val_loss: 0.2792 - val_accuracy: 0.9086\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0545 - accuracy: 0.9814 - val_loss: 0.3032 - val_accuracy: 0.8909\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0495 - accuracy: 0.9849 - val_loss: 0.2812 - val_accuracy: 0.9174\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0387 - accuracy: 0.9910 - val_loss: 0.3215 - val_accuracy: 0.9115\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.3106 - val_accuracy: 0.9086\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0260 - accuracy: 0.9924 - val_loss: 0.4778 - val_accuracy: 0.8791\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1079 - accuracy: 0.9602 - val_loss: 0.2636 - val_accuracy: 0.9145\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 0.3077 - val_accuracy: 0.9115\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.4384 - val_accuracy: 0.9145\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.3698 - val_accuracy: 0.9145\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.5655 - val_accuracy: 0.9056\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0613 - accuracy: 0.9844 - val_loss: 0.4243 - val_accuracy: 0.9027\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0455 - accuracy: 0.9807 - val_loss: 0.3868 - val_accuracy: 0.9174\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0705 - accuracy: 0.9793 - val_loss: 0.4974 - val_accuracy: 0.8968\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.2674 - val_accuracy: 0.9174\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0211 - accuracy: 0.9917 - val_loss: 0.2927 - val_accuracy: 0.9115\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.3321 - val_accuracy: 0.9145\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.3371 - val_accuracy: 0.9204\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.3126 - val_accuracy: 0.9292\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.3061 - val_accuracy: 0.9233\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9292\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9204\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 0.0029 - accuracy: 0.9980 - val_loss: 0.4019 - val_accuracy: 0.9115\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 6.3410e-04 - accuracy: 0.9999 - val_loss: 0.3390 - val_accuracy: 0.9292\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 6.8734e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9174\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 3.5423e-04 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.9322\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 5.3455e-04 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9174\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 1.5701e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9145\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 7.6018e-04 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9204\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 6.5588e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9292\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 5.4868e-04 - accuracy: 0.9997 - val_loss: 0.3862 - val_accuracy: 0.9292\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9174\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 1.0131e-04 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9145\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 1.1712e-04 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.9204\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 1.5765e-04 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9204\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 9.4862e-04 - accuracy: 0.9998 - val_loss: 0.3397 - val_accuracy: 0.9351\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 0.0605 - accuracy: 0.9803 - val_loss: 0.4727 - val_accuracy: 0.8938\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 0.0516 - accuracy: 0.9872 - val_loss: 0.5495 - val_accuracy: 0.9115\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 0.0145 - accuracy: 0.9944 - val_loss: 0.4527 - val_accuracy: 0.9174\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.4785 - val_accuracy: 0.9145\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 3s 85ms/step - loss: 0.7478 - accuracy: 0.9270 - val_loss: 0.9844 - val_accuracy: 0.8171\n",
            "Baseline Error: 18.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISbx_mo2mWex"
      },
      "source": [
        "El agregar varios filtros no ha servido mucho, intentamos el mismo modelo pero apagando más nodos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW-c4ZB6mqie"
      },
      "source": [
        "## empezaremos probando con un model stándar donde se usan 64 filtros de 5x5 y una capa densa de 128\n",
        "def baseline_model_cnn_multi_filtros_2():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (5, 5), input_shape=(224, 224,3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.7)) ## se apagarán 70% de los nodos\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBeeGG32m6x9",
        "outputId": "aabe778c-37f0-459e-8e37-3f8ab13c7c28"
      },
      "source": [
        "## Construimos el model\n",
        "model = baseline_model_cnn_multi_filtros_2()\n",
        "# Entrenamos con 50 épocas y 32 batchsize\n",
        "model.fit(X_train_cn, y_train_cn, validation_data=(X_test_cn, y_test_cn), epochs=50, batch_size=32)\n",
        "# Evaluamos\n",
        "scores = model.evaluate(X_test_cn, y_test_cn, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 38s 112ms/step - loss: 0.9952 - accuracy: 0.5397 - val_loss: 0.3765 - val_accuracy: 0.8407\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 3s 81ms/step - loss: 0.4063 - accuracy: 0.8360 - val_loss: 0.4408 - val_accuracy: 0.8201\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.3550 - accuracy: 0.8678 - val_loss: 0.4047 - val_accuracy: 0.8348\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.3415 - accuracy: 0.8681 - val_loss: 0.3830 - val_accuracy: 0.8260\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.2630 - accuracy: 0.8962 - val_loss: 0.4217 - val_accuracy: 0.8437\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.2839 - accuracy: 0.8904 - val_loss: 0.3293 - val_accuracy: 0.8555\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 81ms/step - loss: 0.2387 - accuracy: 0.8989 - val_loss: 0.3144 - val_accuracy: 0.8761\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.2149 - accuracy: 0.9206 - val_loss: 0.2912 - val_accuracy: 0.8820\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1898 - accuracy: 0.9339 - val_loss: 0.3010 - val_accuracy: 0.8643\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.2884 - accuracy: 0.8921 - val_loss: 0.2740 - val_accuracy: 0.8791\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.1769 - accuracy: 0.9292 - val_loss: 0.3090 - val_accuracy: 0.8909\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.1658 - accuracy: 0.9386 - val_loss: 0.2280 - val_accuracy: 0.9233\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1190 - accuracy: 0.9501 - val_loss: 0.2343 - val_accuracy: 0.9115\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1717 - accuracy: 0.9266 - val_loss: 0.2588 - val_accuracy: 0.8997\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1250 - accuracy: 0.9537 - val_loss: 0.2416 - val_accuracy: 0.8968\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1230 - accuracy: 0.9579 - val_loss: 0.1879 - val_accuracy: 0.9322\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0802 - accuracy: 0.9735 - val_loss: 0.2350 - val_accuracy: 0.9145\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.1017 - accuracy: 0.9577 - val_loss: 0.2114 - val_accuracy: 0.9263\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1154 - accuracy: 0.9617 - val_loss: 0.2251 - val_accuracy: 0.9115\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.1004 - accuracy: 0.9654 - val_loss: 0.2247 - val_accuracy: 0.9351\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0751 - accuracy: 0.9724 - val_loss: 0.1664 - val_accuracy: 0.9528\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0752 - accuracy: 0.9784 - val_loss: 0.2093 - val_accuracy: 0.9351\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0570 - accuracy: 0.9828 - val_loss: 0.1947 - val_accuracy: 0.9381\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0655 - accuracy: 0.9794 - val_loss: 0.1905 - val_accuracy: 0.9381\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 3s 82ms/step - loss: 0.0421 - accuracy: 0.9831 - val_loss: 0.3668 - val_accuracy: 0.8850\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.1038 - accuracy: 0.9691 - val_loss: 0.1659 - val_accuracy: 0.9440\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0634 - accuracy: 0.9807 - val_loss: 0.1792 - val_accuracy: 0.9499\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0635 - accuracy: 0.9795 - val_loss: 0.1958 - val_accuracy: 0.9440\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.1746 - val_accuracy: 0.9381\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0356 - accuracy: 0.9874 - val_loss: 0.1936 - val_accuracy: 0.9381\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0271 - accuracy: 0.9873 - val_loss: 0.2340 - val_accuracy: 0.9440\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0357 - accuracy: 0.9840 - val_loss: 0.2014 - val_accuracy: 0.9469\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0391 - accuracy: 0.9840 - val_loss: 0.2420 - val_accuracy: 0.9381\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0304 - accuracy: 0.9862 - val_loss: 0.1802 - val_accuracy: 0.9499\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0425 - accuracy: 0.9838 - val_loss: 0.3273 - val_accuracy: 0.9351\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0466 - accuracy: 0.9848 - val_loss: 0.1931 - val_accuracy: 0.9528\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0411 - accuracy: 0.9890 - val_loss: 0.2743 - val_accuracy: 0.9440\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0326 - accuracy: 0.9858 - val_loss: 0.2404 - val_accuracy: 0.9410\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0353 - accuracy: 0.9875 - val_loss: 0.2300 - val_accuracy: 0.9381\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 83ms/step - loss: 0.0163 - accuracy: 0.9937 - val_loss: 0.2205 - val_accuracy: 0.9528\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.2428 - val_accuracy: 0.9558\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.2507 - val_accuracy: 0.9587\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.2563 - val_accuracy: 0.9558\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0359 - accuracy: 0.9886 - val_loss: 0.3165 - val_accuracy: 0.9469\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.3175 - val_accuracy: 0.9499\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.2690 - val_accuracy: 0.9351\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0358 - accuracy: 0.9837 - val_loss: 0.4387 - val_accuracy: 0.9322\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0689 - accuracy: 0.9753 - val_loss: 0.2664 - val_accuracy: 0.9381\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0469 - accuracy: 0.9817 - val_loss: 0.2996 - val_accuracy: 0.9263\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 3s 84ms/step - loss: 0.0446 - accuracy: 0.9825 - val_loss: 0.2925 - val_accuracy: 0.9410\n",
            "Baseline Error: 5.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lOaQu5Goeb2"
      },
      "source": [
        "Se nota una mejora en el valor de accuracy logrando un 94.10%, ha sido notoria la mejora al desconectar un porcentaje mayor de nodos, ahora queremos intentar crear un model que nos permita tunnear el tamaño de los filtros que vamos a usar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vABi565JpFKS"
      },
      "source": [
        "def baseline_model_cnn_multi_filtros_3(t_filtro:5):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (t_filtro, t_filtro), input_shape=(224, 224,3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (t_filtro, t_filtro), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (t_filtro, t_filtro), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.7)) ## se apagarán 70% de los nodos\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUb_SAoYpYZf",
        "outputId": "95adae62-271e-4522-fe0e-a08831412bd2"
      },
      "source": [
        "results = \"Resultados\\n\"\n",
        "for indice in range(1, 6):\n",
        "  ## Construimos el model\n",
        "  model = baseline_model_cnn_multi_filtros_3(indice)\n",
        "  # Entrenamos con 50 épocas y 32 batchsize\n",
        "  model.fit(X_train_cn, y_train_cn, validation_data=(X_test_cn, y_test_cn), epochs=50, batch_size=32)\n",
        "  # Evaluamos\n",
        "  scores = model.evaluate(X_test_cn, y_test_cn, verbose=0)\n",
        "  r = (\"Error: %.2f%%, Acc: %.2f%% usando filtros de %r \" % ((100-scores[1]*100), scores[1]*100, str(indice)+\" X \"+str(indice)))+\"\\n\"\n",
        "  print(r)\n",
        "  results += r+\"\\n\"\n",
        "print(results)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 4s 79ms/step - loss: 0.9702 - accuracy: 0.6242 - val_loss: 0.4632 - val_accuracy: 0.7847\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 3s 71ms/step - loss: 0.3867 - accuracy: 0.8428 - val_loss: 0.3513 - val_accuracy: 0.8584\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.3407 - accuracy: 0.8749 - val_loss: 0.3310 - val_accuracy: 0.8702\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.2865 - accuracy: 0.8851 - val_loss: 0.3099 - val_accuracy: 0.8732\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.2719 - accuracy: 0.8966 - val_loss: 0.2812 - val_accuracy: 0.8938\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.2670 - accuracy: 0.9002 - val_loss: 0.2681 - val_accuracy: 0.8791\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.2094 - accuracy: 0.9079 - val_loss: 0.2356 - val_accuracy: 0.9056\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1824 - accuracy: 0.9366 - val_loss: 0.2344 - val_accuracy: 0.8997\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1765 - accuracy: 0.9371 - val_loss: 0.2228 - val_accuracy: 0.9086\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1616 - accuracy: 0.9352 - val_loss: 0.2214 - val_accuracy: 0.9115\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1393 - accuracy: 0.9442 - val_loss: 0.2168 - val_accuracy: 0.9233\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.1526 - accuracy: 0.9289 - val_loss: 0.2516 - val_accuracy: 0.8938\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.1461 - accuracy: 0.9472 - val_loss: 0.2397 - val_accuracy: 0.9027\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1413 - accuracy: 0.9493 - val_loss: 0.2410 - val_accuracy: 0.9145\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.1159 - accuracy: 0.9549 - val_loss: 0.2226 - val_accuracy: 0.9233\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1421 - accuracy: 0.9403 - val_loss: 0.2157 - val_accuracy: 0.9381\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0888 - accuracy: 0.9598 - val_loss: 0.1978 - val_accuracy: 0.9351\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1111 - accuracy: 0.9526 - val_loss: 0.2320 - val_accuracy: 0.9292\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1202 - accuracy: 0.9567 - val_loss: 0.2833 - val_accuracy: 0.9174\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1182 - accuracy: 0.9569 - val_loss: 0.1704 - val_accuracy: 0.9410\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0690 - accuracy: 0.9768 - val_loss: 0.1901 - val_accuracy: 0.9381\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0757 - accuracy: 0.9708 - val_loss: 0.2549 - val_accuracy: 0.9263\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 3s 71ms/step - loss: 0.0818 - accuracy: 0.9691 - val_loss: 0.2039 - val_accuracy: 0.9381\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0907 - accuracy: 0.9697 - val_loss: 0.2331 - val_accuracy: 0.9381\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 0.1890 - val_accuracy: 0.9469\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0552 - accuracy: 0.9762 - val_loss: 0.2223 - val_accuracy: 0.9440\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 3s 71ms/step - loss: 0.0548 - accuracy: 0.9796 - val_loss: 0.1919 - val_accuracy: 0.9469\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0692 - accuracy: 0.9679 - val_loss: 0.2642 - val_accuracy: 0.9322\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0779 - accuracy: 0.9691 - val_loss: 0.2590 - val_accuracy: 0.9410\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0712 - accuracy: 0.9745 - val_loss: 0.2275 - val_accuracy: 0.9263\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0437 - accuracy: 0.9868 - val_loss: 0.2309 - val_accuracy: 0.9469\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0688 - accuracy: 0.9658 - val_loss: 0.2364 - val_accuracy: 0.9440\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0489 - accuracy: 0.9791 - val_loss: 0.2164 - val_accuracy: 0.9558\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1129 - accuracy: 0.9540 - val_loss: 0.2639 - val_accuracy: 0.9174\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0780 - accuracy: 0.9676 - val_loss: 0.2254 - val_accuracy: 0.9469\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 0.2217 - val_accuracy: 0.9410\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0552 - accuracy: 0.9809 - val_loss: 0.2135 - val_accuracy: 0.9469\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 0.2271 - val_accuracy: 0.9469\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 0.2692 - val_accuracy: 0.9469\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 74ms/step - loss: 0.0601 - accuracy: 0.9825 - val_loss: 0.2448 - val_accuracy: 0.9410\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0374 - accuracy: 0.9840 - val_loss: 0.2328 - val_accuracy: 0.9440\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0447 - accuracy: 0.9824 - val_loss: 0.2282 - val_accuracy: 0.9528\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0387 - accuracy: 0.9826 - val_loss: 0.2556 - val_accuracy: 0.9528\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.3033 - val_accuracy: 0.9322\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0299 - accuracy: 0.9887 - val_loss: 0.3340 - val_accuracy: 0.9499\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0922 - accuracy: 0.9676 - val_loss: 0.2630 - val_accuracy: 0.9322\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0432 - accuracy: 0.9781 - val_loss: 0.3136 - val_accuracy: 0.9410\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.1644 - accuracy: 0.9478 - val_loss: 0.2346 - val_accuracy: 0.9440\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0658 - accuracy: 0.9690 - val_loss: 0.2069 - val_accuracy: 0.9469\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0523 - accuracy: 0.9791 - val_loss: 0.2663 - val_accuracy: 0.9528\n",
            "Error: 4.72%, Acc: 95.28% usando filtros de '1 X 1' \n",
            "\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.7454 - accuracy: 0.5943 - val_loss: 0.5094 - val_accuracy: 0.7581\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.3777 - accuracy: 0.8515 - val_loss: 0.4588 - val_accuracy: 0.8289\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.3287 - accuracy: 0.8917 - val_loss: 0.2692 - val_accuracy: 0.8997\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2870 - accuracy: 0.8948 - val_loss: 0.2607 - val_accuracy: 0.8997\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2287 - accuracy: 0.9085 - val_loss: 0.2832 - val_accuracy: 0.8820\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.3031 - accuracy: 0.8874 - val_loss: 0.2890 - val_accuracy: 0.8997\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1979 - accuracy: 0.9218 - val_loss: 0.2263 - val_accuracy: 0.9145\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.1676 - accuracy: 0.9336 - val_loss: 0.2840 - val_accuracy: 0.8997\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2296 - accuracy: 0.9179 - val_loss: 0.2162 - val_accuracy: 0.9204\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.1032 - accuracy: 0.9669 - val_loss: 0.2069 - val_accuracy: 0.9233\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1073 - accuracy: 0.9633 - val_loss: 0.2233 - val_accuracy: 0.9174\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.1412 - accuracy: 0.9442 - val_loss: 0.2186 - val_accuracy: 0.9233\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1326 - accuracy: 0.9454 - val_loss: 0.2182 - val_accuracy: 0.9204\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1409 - accuracy: 0.9404 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0833 - accuracy: 0.9702 - val_loss: 0.2143 - val_accuracy: 0.9381\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0983 - accuracy: 0.9594 - val_loss: 0.1893 - val_accuracy: 0.9351\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0935 - accuracy: 0.9642 - val_loss: 0.1988 - val_accuracy: 0.9351\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0569 - accuracy: 0.9802 - val_loss: 0.2121 - val_accuracy: 0.9322\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0913 - accuracy: 0.9613 - val_loss: 0.2135 - val_accuracy: 0.9322\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0552 - accuracy: 0.9791 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0506 - accuracy: 0.9796 - val_loss: 0.2256 - val_accuracy: 0.9410\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0599 - accuracy: 0.9772 - val_loss: 0.1755 - val_accuracy: 0.9469\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0667 - accuracy: 0.9682 - val_loss: 0.1990 - val_accuracy: 0.9292\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0427 - accuracy: 0.9852 - val_loss: 0.2075 - val_accuracy: 0.9351\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0698 - accuracy: 0.9764 - val_loss: 0.1582 - val_accuracy: 0.9469\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0455 - accuracy: 0.9834 - val_loss: 0.1722 - val_accuracy: 0.9499\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0459 - accuracy: 0.9830 - val_loss: 0.1797 - val_accuracy: 0.9528\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0490 - accuracy: 0.9830 - val_loss: 0.1816 - val_accuracy: 0.9528\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0365 - accuracy: 0.9799 - val_loss: 0.2485 - val_accuracy: 0.9381\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0494 - accuracy: 0.9848 - val_loss: 0.1942 - val_accuracy: 0.9558\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0599 - accuracy: 0.9752 - val_loss: 0.2519 - val_accuracy: 0.9292\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0731 - accuracy: 0.9735 - val_loss: 0.1721 - val_accuracy: 0.9440\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 0.1719 - val_accuracy: 0.9499\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0700 - accuracy: 0.9752 - val_loss: 0.1719 - val_accuracy: 0.9617\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0528 - accuracy: 0.9793 - val_loss: 0.2210 - val_accuracy: 0.9351\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0656 - accuracy: 0.9774 - val_loss: 0.1900 - val_accuracy: 0.9469\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0280 - accuracy: 0.9934 - val_loss: 0.2160 - val_accuracy: 0.9469\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.2220 - val_accuracy: 0.9469\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0468 - accuracy: 0.9821 - val_loss: 0.2331 - val_accuracy: 0.9381\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.2288 - val_accuracy: 0.9381\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.0323 - accuracy: 0.9874 - val_loss: 0.2166 - val_accuracy: 0.9558\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0347 - accuracy: 0.9878 - val_loss: 0.2066 - val_accuracy: 0.9528\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0242 - accuracy: 0.9895 - val_loss: 0.3207 - val_accuracy: 0.9322\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0917 - accuracy: 0.9563 - val_loss: 0.1831 - val_accuracy: 0.9440\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0604 - accuracy: 0.9760 - val_loss: 0.2063 - val_accuracy: 0.9469\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0349 - accuracy: 0.9811 - val_loss: 0.2201 - val_accuracy: 0.9499\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 0.2249 - val_accuracy: 0.9381\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0233 - accuracy: 0.9931 - val_loss: 0.2423 - val_accuracy: 0.9381\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0475 - accuracy: 0.9880 - val_loss: 0.2169 - val_accuracy: 0.9440\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.0449 - accuracy: 0.9894 - val_loss: 0.2436 - val_accuracy: 0.9469\n",
            "Error: 5.31%, Acc: 94.69% usando filtros de '2 X 2' \n",
            "\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.8253 - accuracy: 0.6247 - val_loss: 0.4126 - val_accuracy: 0.8142\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.3870 - accuracy: 0.8466 - val_loss: 0.5846 - val_accuracy: 0.7670\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.3924 - accuracy: 0.8287 - val_loss: 0.3796 - val_accuracy: 0.8584\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.2813 - accuracy: 0.8883 - val_loss: 0.3156 - val_accuracy: 0.8702\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2504 - accuracy: 0.9002 - val_loss: 0.2471 - val_accuracy: 0.9145\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2052 - accuracy: 0.9229 - val_loss: 0.2517 - val_accuracy: 0.9056\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1964 - accuracy: 0.9386 - val_loss: 0.2751 - val_accuracy: 0.9086\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1681 - accuracy: 0.9420 - val_loss: 0.2480 - val_accuracy: 0.9145\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1603 - accuracy: 0.9433 - val_loss: 0.3069 - val_accuracy: 0.8732\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1859 - accuracy: 0.9330 - val_loss: 0.2198 - val_accuracy: 0.9233\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.1154 - accuracy: 0.9567 - val_loss: 0.3191 - val_accuracy: 0.8791\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1544 - accuracy: 0.9379 - val_loss: 0.2153 - val_accuracy: 0.9086\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.1358 - accuracy: 0.9459 - val_loss: 0.2481 - val_accuracy: 0.9174\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1005 - accuracy: 0.9778 - val_loss: 0.2207 - val_accuracy: 0.9056\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1130 - accuracy: 0.9588 - val_loss: 0.2045 - val_accuracy: 0.9263\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2087 - accuracy: 0.9287 - val_loss: 0.2210 - val_accuracy: 0.9292\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1378 - accuracy: 0.9528 - val_loss: 0.1668 - val_accuracy: 0.9410\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0918 - accuracy: 0.9691 - val_loss: 0.2276 - val_accuracy: 0.9351\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0648 - accuracy: 0.9774 - val_loss: 0.1939 - val_accuracy: 0.9381\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0835 - accuracy: 0.9692 - val_loss: 0.2011 - val_accuracy: 0.9292\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1596 - accuracy: 0.9494 - val_loss: 0.3324 - val_accuracy: 0.8909\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1520 - accuracy: 0.9565 - val_loss: 0.1837 - val_accuracy: 0.9410\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0861 - accuracy: 0.9688 - val_loss: 0.1751 - val_accuracy: 0.9587\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0751 - accuracy: 0.9777 - val_loss: 0.1973 - val_accuracy: 0.9410\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0808 - accuracy: 0.9682 - val_loss: 0.1948 - val_accuracy: 0.9528\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0498 - accuracy: 0.9864 - val_loss: 0.1940 - val_accuracy: 0.9440\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0426 - accuracy: 0.9901 - val_loss: 0.1841 - val_accuracy: 0.9528\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0597 - accuracy: 0.9780 - val_loss: 0.1623 - val_accuracy: 0.9440\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.2262 - val_accuracy: 0.9410\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0363 - accuracy: 0.9888 - val_loss: 0.3031 - val_accuracy: 0.9322\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0869 - accuracy: 0.9718 - val_loss: 0.2235 - val_accuracy: 0.9233\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0690 - accuracy: 0.9721 - val_loss: 0.2201 - val_accuracy: 0.9292\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.2551 - val_accuracy: 0.9351\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0414 - accuracy: 0.9845 - val_loss: 0.2858 - val_accuracy: 0.9263\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0571 - accuracy: 0.9759 - val_loss: 0.2123 - val_accuracy: 0.9469\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0328 - accuracy: 0.9942 - val_loss: 0.2717 - val_accuracy: 0.9322\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0553 - accuracy: 0.9770 - val_loss: 0.2311 - val_accuracy: 0.9381\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0337 - accuracy: 0.9927 - val_loss: 0.4177 - val_accuracy: 0.9086\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0888 - accuracy: 0.9814 - val_loss: 0.1821 - val_accuracy: 0.9499\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0601 - accuracy: 0.9836 - val_loss: 0.2315 - val_accuracy: 0.9351\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0411 - accuracy: 0.9881 - val_loss: 0.2123 - val_accuracy: 0.9410\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0425 - accuracy: 0.9838 - val_loss: 0.1611 - val_accuracy: 0.9499\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0389 - accuracy: 0.9869 - val_loss: 0.1843 - val_accuracy: 0.9469\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0206 - accuracy: 0.9919 - val_loss: 0.1960 - val_accuracy: 0.9499\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.2406 - val_accuracy: 0.9558\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0102 - accuracy: 0.9948 - val_loss: 0.2548 - val_accuracy: 0.9440\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0128 - accuracy: 0.9941 - val_loss: 0.2648 - val_accuracy: 0.9440\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0226 - accuracy: 0.9919 - val_loss: 0.1991 - val_accuracy: 0.9499\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0311 - accuracy: 0.9872 - val_loss: 0.2875 - val_accuracy: 0.9440\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0271 - accuracy: 0.9891 - val_loss: 0.2808 - val_accuracy: 0.9440\n",
            "Error: 5.60%, Acc: 94.40% usando filtros de '3 X 3' \n",
            "\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 6s 110ms/step - loss: 0.7515 - accuracy: 0.6047 - val_loss: 0.3970 - val_accuracy: 0.8289\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.3848 - accuracy: 0.8438 - val_loss: 0.3651 - val_accuracy: 0.8525\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.3607 - accuracy: 0.8823 - val_loss: 0.3676 - val_accuracy: 0.8289\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.3168 - accuracy: 0.8846 - val_loss: 0.3154 - val_accuracy: 0.8643\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.2918 - accuracy: 0.8881 - val_loss: 0.3077 - val_accuracy: 0.8761\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.3248 - accuracy: 0.8564 - val_loss: 0.2895 - val_accuracy: 0.8879\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.2462 - accuracy: 0.9089 - val_loss: 0.2910 - val_accuracy: 0.8702\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.2023 - accuracy: 0.9237 - val_loss: 0.3158 - val_accuracy: 0.8997\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.2287 - accuracy: 0.9215 - val_loss: 0.2916 - val_accuracy: 0.8791\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.2043 - accuracy: 0.9271 - val_loss: 0.2968 - val_accuracy: 0.8909\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.1697 - accuracy: 0.9407 - val_loss: 0.3953 - val_accuracy: 0.8732\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.1598 - accuracy: 0.9287 - val_loss: 0.2282 - val_accuracy: 0.9174\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.1665 - accuracy: 0.9423 - val_loss: 0.2164 - val_accuracy: 0.9322\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.1112 - accuracy: 0.9629 - val_loss: 0.2540 - val_accuracy: 0.9322\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.1382 - accuracy: 0.9421 - val_loss: 0.2431 - val_accuracy: 0.9322\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.1192 - accuracy: 0.9524 - val_loss: 0.1922 - val_accuracy: 0.9440\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0818 - accuracy: 0.9750 - val_loss: 0.2451 - val_accuracy: 0.9174\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.1055 - accuracy: 0.9622 - val_loss: 0.2132 - val_accuracy: 0.9381\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.0987 - accuracy: 0.9658 - val_loss: 0.2377 - val_accuracy: 0.9204\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 87ms/step - loss: 0.1124 - accuracy: 0.9622 - val_loss: 0.2082 - val_accuracy: 0.9322\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0691 - accuracy: 0.9797 - val_loss: 0.1873 - val_accuracy: 0.9440\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0554 - accuracy: 0.9841 - val_loss: 0.1948 - val_accuracy: 0.9410\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0742 - accuracy: 0.9827 - val_loss: 0.2171 - val_accuracy: 0.9499\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0480 - accuracy: 0.9781 - val_loss: 0.1945 - val_accuracy: 0.9381\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.0778 - accuracy: 0.9793 - val_loss: 0.1768 - val_accuracy: 0.9410\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.0376 - accuracy: 0.9835 - val_loss: 0.1923 - val_accuracy: 0.9528\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 4s 90ms/step - loss: 0.0424 - accuracy: 0.9862 - val_loss: 0.1784 - val_accuracy: 0.9499\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.0426 - accuracy: 0.9847 - val_loss: 0.2058 - val_accuracy: 0.9499\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0917 - accuracy: 0.9729 - val_loss: 0.2319 - val_accuracy: 0.9322\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0434 - accuracy: 0.9884 - val_loss: 0.1872 - val_accuracy: 0.9558\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 87ms/step - loss: 0.0572 - accuracy: 0.9871 - val_loss: 0.2368 - val_accuracy: 0.9351\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0291 - accuracy: 0.9855 - val_loss: 0.5181 - val_accuracy: 0.8761\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.0663 - accuracy: 0.9733 - val_loss: 0.2474 - val_accuracy: 0.9292\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.0665 - accuracy: 0.9741 - val_loss: 0.1920 - val_accuracy: 0.9528\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.2266 - val_accuracy: 0.9410\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 87ms/step - loss: 0.0121 - accuracy: 0.9990 - val_loss: 0.2319 - val_accuracy: 0.9499\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.0307 - accuracy: 0.9899 - val_loss: 0.2132 - val_accuracy: 0.9528\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.0123 - accuracy: 0.9952 - val_loss: 0.2810 - val_accuracy: 0.9499\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 87ms/step - loss: 0.0222 - accuracy: 0.9917 - val_loss: 0.2518 - val_accuracy: 0.9469\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 87ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.2174 - val_accuracy: 0.9558\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0494 - accuracy: 0.9904 - val_loss: 0.1899 - val_accuracy: 0.9558\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.3174 - val_accuracy: 0.9351\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.2673 - val_accuracy: 0.9499\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 87ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.2503 - val_accuracy: 0.9558\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.2258 - val_accuracy: 0.9528\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.2222 - val_accuracy: 0.9558\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.3182 - val_accuracy: 0.9469\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.0312 - accuracy: 0.9914 - val_loss: 0.2392 - val_accuracy: 0.9528\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.0191 - accuracy: 0.9889 - val_loss: 0.2727 - val_accuracy: 0.9558\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.3651 - val_accuracy: 0.9351\n",
            "Error: 6.49%, Acc: 93.51% usando filtros de '4 X 4' \n",
            "\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 7s 129ms/step - loss: 1.1132 - accuracy: 0.5064 - val_loss: 0.7450 - val_accuracy: 0.4484\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.6647 - accuracy: 0.6166 - val_loss: 0.4779 - val_accuracy: 0.8024\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.3847 - accuracy: 0.8378 - val_loss: 0.4619 - val_accuracy: 0.8083\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.3404 - accuracy: 0.8573 - val_loss: 0.3196 - val_accuracy: 0.8407\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.3105 - accuracy: 0.8710 - val_loss: 0.3327 - val_accuracy: 0.8614\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.3275 - accuracy: 0.8754 - val_loss: 0.3428 - val_accuracy: 0.8614\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.2525 - accuracy: 0.8984 - val_loss: 0.3640 - val_accuracy: 0.8466\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.2382 - accuracy: 0.9056 - val_loss: 0.3231 - val_accuracy: 0.8702\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.2971 - accuracy: 0.8868 - val_loss: 0.3268 - val_accuracy: 0.8614\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2182 - accuracy: 0.9228 - val_loss: 0.3141 - val_accuracy: 0.8643\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2153 - accuracy: 0.9103 - val_loss: 0.3205 - val_accuracy: 0.8555\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2562 - accuracy: 0.9126 - val_loss: 0.2682 - val_accuracy: 0.9145\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1865 - accuracy: 0.9307 - val_loss: 0.2646 - val_accuracy: 0.9145\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.1893 - accuracy: 0.9384 - val_loss: 0.3618 - val_accuracy: 0.8820\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.1562 - accuracy: 0.9248 - val_loss: 0.2720 - val_accuracy: 0.9204\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1789 - accuracy: 0.9365 - val_loss: 0.2963 - val_accuracy: 0.8997\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1785 - accuracy: 0.9348 - val_loss: 0.2207 - val_accuracy: 0.9292\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1188 - accuracy: 0.9616 - val_loss: 0.2117 - val_accuracy: 0.9292\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.1342 - accuracy: 0.9638 - val_loss: 0.3678 - val_accuracy: 0.8673\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1995 - accuracy: 0.9288 - val_loss: 0.2055 - val_accuracy: 0.9263\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1165 - accuracy: 0.9651 - val_loss: 0.2563 - val_accuracy: 0.9381\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1214 - accuracy: 0.9607 - val_loss: 0.2557 - val_accuracy: 0.8997\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1356 - accuracy: 0.9478 - val_loss: 0.2277 - val_accuracy: 0.9174\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1213 - accuracy: 0.9526 - val_loss: 0.1851 - val_accuracy: 0.9587\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0798 - accuracy: 0.9695 - val_loss: 0.2541 - val_accuracy: 0.9322\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0886 - accuracy: 0.9658 - val_loss: 0.1988 - val_accuracy: 0.9499\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0763 - accuracy: 0.9659 - val_loss: 0.1799 - val_accuracy: 0.9528\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0574 - accuracy: 0.9786 - val_loss: 0.1647 - val_accuracy: 0.9499\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0661 - accuracy: 0.9768 - val_loss: 0.1960 - val_accuracy: 0.9499\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0489 - accuracy: 0.9864 - val_loss: 0.1888 - val_accuracy: 0.9440\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0551 - accuracy: 0.9832 - val_loss: 0.2276 - val_accuracy: 0.9558\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0922 - accuracy: 0.9726 - val_loss: 0.1851 - val_accuracy: 0.9617\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0770 - accuracy: 0.9691 - val_loss: 0.2043 - val_accuracy: 0.9558\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0543 - accuracy: 0.9797 - val_loss: 0.1906 - val_accuracy: 0.9499\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0416 - accuracy: 0.9841 - val_loss: 0.2014 - val_accuracy: 0.9528\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0593 - accuracy: 0.9789 - val_loss: 0.1647 - val_accuracy: 0.9676\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0324 - accuracy: 0.9897 - val_loss: 0.2312 - val_accuracy: 0.9469\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1355 - accuracy: 0.9582 - val_loss: 0.2076 - val_accuracy: 0.9558\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0497 - accuracy: 0.9801 - val_loss: 0.2442 - val_accuracy: 0.9528\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0399 - accuracy: 0.9851 - val_loss: 0.2789 - val_accuracy: 0.9469\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0622 - accuracy: 0.9805 - val_loss: 0.2604 - val_accuracy: 0.9351\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0483 - accuracy: 0.9850 - val_loss: 0.2128 - val_accuracy: 0.9440\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0342 - accuracy: 0.9869 - val_loss: 0.2333 - val_accuracy: 0.9558\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0659 - accuracy: 0.9836 - val_loss: 0.2606 - val_accuracy: 0.9469\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0359 - accuracy: 0.9883 - val_loss: 0.2492 - val_accuracy: 0.9499\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0224 - accuracy: 0.9917 - val_loss: 0.1614 - val_accuracy: 0.9676\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.2401 - val_accuracy: 0.9558\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.2412 - val_accuracy: 0.9528\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0390 - accuracy: 0.9852 - val_loss: 0.2186 - val_accuracy: 0.9558\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.2929 - val_accuracy: 0.9469\n",
            "Error: 5.31%, Acc: 94.69% usando filtros de '5 X 5' \n",
            "\n",
            "Resultados\n",
            "Error: 4.72%, Acc: 95.28% usando filtros de '1 X 1' \n",
            "\n",
            "Error: 5.31%, Acc: 94.69% usando filtros de '2 X 2' \n",
            "\n",
            "Error: 5.60%, Acc: 94.40% usando filtros de '3 X 3' \n",
            "\n",
            "Error: 6.49%, Acc: 93.51% usando filtros de '4 X 4' \n",
            "\n",
            "Error: 5.31%, Acc: 94.69% usando filtros de '5 X 5' \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90h8FEH7y6XK"
      },
      "source": [
        "Vemos que agregar 3 capas de filtros de 1x1, mejora el accuracy llegando a un 95.28%, siendo el mejor valor obtenido para nuestro problema. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv9Z7cj4zS4i"
      },
      "source": [
        "Intentemos ver que pasa si se varían las épocas y los batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iifAn4aRYtYC",
        "outputId": "7a4ed3f6-9949-4271-ace2-bfbcdff87e6e"
      },
      "source": [
        "model_keras = KerasClassifier(build_fn=baseline_model_cnn_multi_filtros_3, t_filtro=1, verbose=1)\n",
        "batch_size = [16, 32, 64]\n",
        "epochs = [10,30, 50,100]\n",
        "\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model_keras, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train_cn, y_train_cn)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0383 - accuracy: 0.9888\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0437 - accuracy: 0.9816\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0671 - accuracy: 0.9794\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0227 - accuracy: 0.9934\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0155 - accuracy: 0.9953\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0193 - accuracy: 0.9932\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0111 - accuracy: 0.9988\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0385 - accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0832 - accuracy: 0.9640\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0477 - accuracy: 0.9734\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 3.0480 - accuracy: 0.6920\n",
            "Epoch 1/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.8602 - accuracy: 0.6515\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3623 - accuracy: 0.8470\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3236 - accuracy: 0.8769\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.2890 - accuracy: 0.8503\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.2947 - accuracy: 0.8872\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.2549 - accuracy: 0.8931\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2436 - accuracy: 0.9006\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1575 - accuracy: 0.9383\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1719 - accuracy: 0.9299\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1509 - accuracy: 0.9558\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1538 - accuracy: 0.9509\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1512 - accuracy: 0.9409\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1192 - accuracy: 0.9482\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1164 - accuracy: 0.9541\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1369 - accuracy: 0.9448\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0901 - accuracy: 0.9666\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.1158 - accuracy: 0.9513\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1125 - accuracy: 0.9539\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0673 - accuracy: 0.9784\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0677 - accuracy: 0.9800\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0620 - accuracy: 0.9815\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0444 - accuracy: 0.9811\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0664 - accuracy: 0.9773\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0734 - accuracy: 0.9707\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0587 - accuracy: 0.9737\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0583 - accuracy: 0.9758\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0724 - accuracy: 0.9778\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0377 - accuracy: 0.9849\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0424 - accuracy: 0.9800\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0729 - accuracy: 0.9714\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0526 - accuracy: 0.9764\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0404 - accuracy: 0.9818\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0344 - accuracy: 0.9869\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0554 - accuracy: 0.9764\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0504 - accuracy: 0.9770\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0255 - accuracy: 0.9940\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0684 - accuracy: 0.9683\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.0889 - accuracy: 0.9751\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0656 - accuracy: 0.9736\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0386 - accuracy: 0.9853\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0300 - accuracy: 0.9866\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0700 - accuracy: 0.9840\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0313 - accuracy: 0.9872\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0351 - accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0136 - accuracy: 0.9940\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0243 - accuracy: 0.9886\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0396 - accuracy: 0.9788\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0234 - accuracy: 0.9916\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0178 - accuracy: 0.9920\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0297 - accuracy: 0.9877\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1853 - accuracy: 0.9360\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.3456 - accuracy: 0.6637\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3518 - accuracy: 0.8429\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.2046 - accuracy: 0.9293\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1818 - accuracy: 0.9351\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1247 - accuracy: 0.9456\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1236 - accuracy: 0.9571\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1205 - accuracy: 0.9513\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1395 - accuracy: 0.9492\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0723 - accuracy: 0.9758\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1109 - accuracy: 0.9598\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0979 - accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0727 - accuracy: 0.9831\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0532 - accuracy: 0.9848\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0944 - accuracy: 0.9672\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0615 - accuracy: 0.9796\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0445 - accuracy: 0.9814\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0464 - accuracy: 0.9813\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0535 - accuracy: 0.9798\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0530 - accuracy: 0.9759\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0287 - accuracy: 0.9886\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0360 - accuracy: 0.9881\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0292 - accuracy: 0.9930\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0227 - accuracy: 0.9895\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0297 - accuracy: 0.9884\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0220 - accuracy: 0.9924\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0131 - accuracy: 0.9972\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0585 - accuracy: 0.9784\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0346 - accuracy: 0.9859\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0247 - accuracy: 0.9869\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.0242 - accuracy: 0.9922\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0525 - accuracy: 0.9824\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0269 - accuracy: 0.9890\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0763 - accuracy: 0.9696\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0584 - accuracy: 0.9829\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0294 - accuracy: 0.9897\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0210 - accuracy: 0.9895\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0333 - accuracy: 0.9896\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0367 - accuracy: 0.9862\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0127 - accuracy: 0.9956\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0120 - accuracy: 0.9988\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0084 - accuracy: 0.9991\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0178 - accuracy: 0.9919\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0148 - accuracy: 0.9904\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0271 - accuracy: 0.9890\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0166 - accuracy: 0.9898\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0211 - accuracy: 0.9934\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0110 - accuracy: 0.9979\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0228 - accuracy: 0.9922\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0188 - accuracy: 0.9942\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0219 - accuracy: 0.9925\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0158 - accuracy: 0.9992\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0140 - accuracy: 0.9958\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0345 - accuracy: 0.9874\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0245 - accuracy: 0.9899\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0109 - accuracy: 0.9954\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0090 - accuracy: 0.9968\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1368 - accuracy: 0.9699\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0359 - accuracy: 0.9838\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0198 - accuracy: 0.9935\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0182 - accuracy: 0.9942\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0103 - accuracy: 0.9980\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0106 - accuracy: 0.9985\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0087 - accuracy: 0.9978\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0077 - accuracy: 0.9959\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0150 - accuracy: 0.9908\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0049 - accuracy: 0.9995\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.0190 - accuracy: 0.9943\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0132 - accuracy: 0.9947\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0242 - accuracy: 0.9914\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0283 - accuracy: 0.9913\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0181 - accuracy: 0.9967\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0026 - accuracy: 0.9998\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0048 - accuracy: 0.9993\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0082 - accuracy: 0.9966\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0071 - accuracy: 0.9987\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0054 - accuracy: 0.9997\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0052 - accuracy: 0.9964\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0037 - accuracy: 0.9999\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0111 - accuracy: 0.9907\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0076 - accuracy: 0.9979\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0022 - accuracy: 0.9983\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0073 - accuracy: 0.9972\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0046 - accuracy: 0.9994\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0254 - accuracy: 0.9900\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0246 - accuracy: 0.9916\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0095 - accuracy: 0.9973\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0084 - accuracy: 0.9977\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0176 - accuracy: 0.9980\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0043 - accuracy: 0.9967\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0035 - accuracy: 0.9990\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0403 - accuracy: 0.9962\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0066 - accuracy: 0.9959\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0056 - accuracy: 0.9977\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0151 - accuracy: 0.9964\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0050 - accuracy: 0.9996\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0084 - accuracy: 0.9981\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0114 - accuracy: 0.9969\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0268 - accuracy: 0.9882\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 10.2364 - accuracy: 0.2749\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.9795 - accuracy: 0.6785\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3577 - accuracy: 0.8656\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3074 - accuracy: 0.8817\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.2504 - accuracy: 0.8938\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.2170 - accuracy: 0.9164\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.2177 - accuracy: 0.9198\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.2067 - accuracy: 0.9215\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1888 - accuracy: 0.9259\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1822 - accuracy: 0.9211\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1952 - accuracy: 0.9356\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1470 - accuracy: 0.9499\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1319 - accuracy: 0.9449\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1321 - accuracy: 0.9374\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1177 - accuracy: 0.9587\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1117 - accuracy: 0.9430\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1208 - accuracy: 0.9576\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1394 - accuracy: 0.9385\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1175 - accuracy: 0.9658\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1045 - accuracy: 0.9494\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.0859 - accuracy: 0.9719\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0630 - accuracy: 0.9752\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0627 - accuracy: 0.9814\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1053 - accuracy: 0.9660\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0490 - accuracy: 0.9851\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0886 - accuracy: 0.9636\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0733 - accuracy: 0.9640\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1057 - accuracy: 0.9752\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0567 - accuracy: 0.9765\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0623 - accuracy: 0.9742\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0415 - accuracy: 0.9783\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0504 - accuracy: 0.9814\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0306 - accuracy: 0.9877\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0523 - accuracy: 0.9793\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0568 - accuracy: 0.9779\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0462 - accuracy: 0.9838\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0648 - accuracy: 0.9780\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0855 - accuracy: 0.9678\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0445 - accuracy: 0.9787\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0633 - accuracy: 0.9730\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0400 - accuracy: 0.9902\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0481 - accuracy: 0.9827\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0678 - accuracy: 0.9777\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0460 - accuracy: 0.9777\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0488 - accuracy: 0.9778\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0443 - accuracy: 0.9804\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0479 - accuracy: 0.9791\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0394 - accuracy: 0.9859\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0215 - accuracy: 0.9933\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0250 - accuracy: 0.9892\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1126 - accuracy: 0.9704\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0377 - accuracy: 0.9854\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0362 - accuracy: 0.9835\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0203 - accuracy: 0.9952\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0374 - accuracy: 0.9834\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0233 - accuracy: 0.9921\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0205 - accuracy: 0.9896\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0270 - accuracy: 0.9913\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0264 - accuracy: 0.9812\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0226 - accuracy: 0.9906\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.0174 - accuracy: 0.9952\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0208 - accuracy: 0.9926\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0192 - accuracy: 0.9891\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0063 - accuracy: 0.9979\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0205 - accuracy: 0.9878\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0280 - accuracy: 0.9884\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0417 - accuracy: 0.9863\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0418 - accuracy: 0.9842\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0528 - accuracy: 0.9800\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0361 - accuracy: 0.9878\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0334 - accuracy: 0.9828\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0607 - accuracy: 0.9714\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0261 - accuracy: 0.9903\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0418 - accuracy: 0.9844\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0823 - accuracy: 0.9659\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1180 - accuracy: 0.9579\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0332 - accuracy: 0.9847\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0233 - accuracy: 0.9933\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0250 - accuracy: 0.9891\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0221 - accuracy: 0.9897\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0219 - accuracy: 0.9913\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0583 - accuracy: 0.9831\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0700 - accuracy: 0.9862\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0226 - accuracy: 0.9909\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0149 - accuracy: 0.9938\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0228 - accuracy: 0.9902\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0267 - accuracy: 0.9899\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0341 - accuracy: 0.9889\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0232 - accuracy: 0.9907\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0144 - accuracy: 0.9947\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0151 - accuracy: 0.9929\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0167 - accuracy: 0.9957\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0245 - accuracy: 0.9923\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0478 - accuracy: 0.9841\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0332 - accuracy: 0.9867\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0216 - accuracy: 0.9898\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0318 - accuracy: 0.9845\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0259 - accuracy: 0.9893\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0228 - accuracy: 0.9908\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0239 - accuracy: 0.9943\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0330 - accuracy: 0.9910\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 1.2631 - accuracy: 0.8920\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 3s 33ms/step - loss: 1.0325 - accuracy: 0.5807\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3902 - accuracy: 0.8496\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3697 - accuracy: 0.8370\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3041 - accuracy: 0.8692\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2632 - accuracy: 0.8963\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2450 - accuracy: 0.9087\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2285 - accuracy: 0.9046\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.2144 - accuracy: 0.9109\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2187 - accuracy: 0.9022\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1949 - accuracy: 0.9157\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1728 - accuracy: 0.9209\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1404 - accuracy: 0.9292\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1534 - accuracy: 0.9412\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1384 - accuracy: 0.9437\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1416 - accuracy: 0.9411\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1153 - accuracy: 0.9663\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1062 - accuracy: 0.9534\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1239 - accuracy: 0.9497\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0962 - accuracy: 0.9483\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1020 - accuracy: 0.9549\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1463 - accuracy: 0.9497\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0757 - accuracy: 0.9660\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1138 - accuracy: 0.9564\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0933 - accuracy: 0.9648\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0848 - accuracy: 0.9568\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0912 - accuracy: 0.9761\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0721 - accuracy: 0.9648\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0775 - accuracy: 0.9695\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0766 - accuracy: 0.9664\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0802 - accuracy: 0.9695\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0530 - accuracy: 0.9804\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0688 - accuracy: 0.9785\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0795 - accuracy: 0.9734\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0709 - accuracy: 0.9753\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0597 - accuracy: 0.9734\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0390 - accuracy: 0.9868\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0533 - accuracy: 0.9766\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0377 - accuracy: 0.9835\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0492 - accuracy: 0.9817\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0626 - accuracy: 0.9773\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0309 - accuracy: 0.9905\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0764 - accuracy: 0.9711\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0277 - accuracy: 0.9865\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0531 - accuracy: 0.9746\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0748 - accuracy: 0.9694\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0433 - accuracy: 0.9864\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2337 - accuracy: 0.9352\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0625 - accuracy: 0.9774\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0476 - accuracy: 0.9780\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0475 - accuracy: 0.9868\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0475 - accuracy: 0.9786\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0483 - accuracy: 0.9840\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0673 - accuracy: 0.9770\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0418 - accuracy: 0.9839\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0330 - accuracy: 0.9893\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0340 - accuracy: 0.9883\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0433 - accuracy: 0.9781\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0403 - accuracy: 0.9800\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0230 - accuracy: 0.9940\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0390 - accuracy: 0.9862\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0362 - accuracy: 0.9903\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0201 - accuracy: 0.9916\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0284 - accuracy: 0.9917\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0337 - accuracy: 0.9877\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0189 - accuracy: 0.9948\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0176 - accuracy: 0.9899\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0267 - accuracy: 0.9928\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0319 - accuracy: 0.9853\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0320 - accuracy: 0.9863\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0433 - accuracy: 0.9791\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0226 - accuracy: 0.9900\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0235 - accuracy: 0.9917\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0261 - accuracy: 0.9888\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0405 - accuracy: 0.9836\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0308 - accuracy: 0.9934\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0352 - accuracy: 0.9790\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0229 - accuracy: 0.9885\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0281 - accuracy: 0.9835\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0483 - accuracy: 0.9809\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0292 - accuracy: 0.9890\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0300 - accuracy: 0.9854\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0170 - accuracy: 0.9931\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0134 - accuracy: 0.9940\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0145 - accuracy: 0.9941\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0176 - accuracy: 0.9966\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0170 - accuracy: 0.9942\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0272 - accuracy: 0.9918\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0376 - accuracy: 0.9896\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0159 - accuracy: 0.9937\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0290 - accuracy: 0.9904\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0441 - accuracy: 0.9862\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0446 - accuracy: 0.9800\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0243 - accuracy: 0.9884\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0223 - accuracy: 0.9870\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0246 - accuracy: 0.9926\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0765 - accuracy: 0.9737\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0647 - accuracy: 0.9710\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0237 - accuracy: 0.9906\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0214 - accuracy: 0.9950\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0121 - accuracy: 0.9980\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0676 - accuracy: 0.9880\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 3s 34ms/step - loss: 1.0146 - accuracy: 0.5876\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3375 - accuracy: 0.8615\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2170 - accuracy: 0.9213\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2201 - accuracy: 0.9101\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1704 - accuracy: 0.9304\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1438 - accuracy: 0.9527\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.1365 - accuracy: 0.9452\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1353 - accuracy: 0.9540\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0905 - accuracy: 0.9718\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0903 - accuracy: 0.9695\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1049 - accuracy: 0.9643\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0607 - accuracy: 0.9764\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0782 - accuracy: 0.9691\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0763 - accuracy: 0.9767\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0572 - accuracy: 0.9785\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0960 - accuracy: 0.9691\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0573 - accuracy: 0.9837\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0396 - accuracy: 0.9837\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0391 - accuracy: 0.9858\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0440 - accuracy: 0.9823\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0507 - accuracy: 0.9814\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0406 - accuracy: 0.9861\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0435 - accuracy: 0.9798\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0354 - accuracy: 0.9856\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0420 - accuracy: 0.9847\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0330 - accuracy: 0.9856\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0341 - accuracy: 0.9868\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0737 - accuracy: 0.9762\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0276 - accuracy: 0.9881\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0203 - accuracy: 0.9963\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0175 - accuracy: 0.9926\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0579 - accuracy: 0.9862\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0366 - accuracy: 0.9884\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0433 - accuracy: 0.9881\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1968 - accuracy: 0.9429\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0403 - accuracy: 0.9866\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0396 - accuracy: 0.9847\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0311 - accuracy: 0.9891\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0261 - accuracy: 0.9883\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0170 - accuracy: 0.9949\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0180 - accuracy: 0.9934\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0497 - accuracy: 0.9734\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0251 - accuracy: 0.9921\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0279 - accuracy: 0.9911\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0136 - accuracy: 0.9965\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0448 - accuracy: 0.9885\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0140 - accuracy: 0.9946\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0087 - accuracy: 0.9997\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0098 - accuracy: 0.9961\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0156 - accuracy: 0.9941\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0229 - accuracy: 0.9934\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0177 - accuracy: 0.9946\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0647 - accuracy: 0.9827\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0633 - accuracy: 0.9761\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0574 - accuracy: 0.9822\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0142 - accuracy: 0.9984\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0286 - accuracy: 0.9825\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0181 - accuracy: 0.9914\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0137 - accuracy: 0.9948\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0131 - accuracy: 0.9951\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0249 - accuracy: 0.9926\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0106 - accuracy: 0.9977\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0188 - accuracy: 0.9918\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0712 - accuracy: 0.9773\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0137 - accuracy: 0.9946\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0156 - accuracy: 0.9933\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0151 - accuracy: 0.9958\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0063 - accuracy: 0.9981\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0089 - accuracy: 0.9962\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0094 - accuracy: 0.9967\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0239 - accuracy: 0.9966\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0261 - accuracy: 0.9922\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0065 - accuracy: 0.9996\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0289 - accuracy: 0.9921\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0226 - accuracy: 0.9920\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0102 - accuracy: 0.9977\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0276 - accuracy: 0.9936\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0177 - accuracy: 0.9898\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0170 - accuracy: 0.9907\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0171 - accuracy: 0.9927\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0238 - accuracy: 0.9930\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0194 - accuracy: 0.9941\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0138 - accuracy: 0.9970\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0124 - accuracy: 0.9967\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0090 - accuracy: 0.9951\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0052 - accuracy: 0.9980\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0031 - accuracy: 0.9986\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0236 - accuracy: 0.9895\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0157 - accuracy: 0.9958\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0245 - accuracy: 0.9954\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1190 - accuracy: 0.9895\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0090 - accuracy: 0.9970\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0085 - accuracy: 0.9953\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0261 - accuracy: 0.9924\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0425 - accuracy: 0.9887\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0226 - accuracy: 0.9931\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0064 - accuracy: 0.9976\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0144 - accuracy: 0.9953\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 3.7200 - accuracy: 0.6960\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 3s 33ms/step - loss: 0.7981 - accuracy: 0.6312\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3962 - accuracy: 0.8254\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2761 - accuracy: 0.8940\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2722 - accuracy: 0.8872\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.2868 - accuracy: 0.8917\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2148 - accuracy: 0.9059\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1999 - accuracy: 0.9266\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1810 - accuracy: 0.9278\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.1946 - accuracy: 0.9158\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1342 - accuracy: 0.9429\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1519 - accuracy: 0.9470\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1236 - accuracy: 0.9525\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1579 - accuracy: 0.9421\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0963 - accuracy: 0.9577\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1098 - accuracy: 0.9635\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0756 - accuracy: 0.9641\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0737 - accuracy: 0.9725\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0829 - accuracy: 0.9688\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0596 - accuracy: 0.9747\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0611 - accuracy: 0.9818\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0568 - accuracy: 0.9806\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0803 - accuracy: 0.9711\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0538 - accuracy: 0.9789\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0747 - accuracy: 0.9720\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0825 - accuracy: 0.9681\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0526 - accuracy: 0.9770\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0455 - accuracy: 0.9818\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0955 - accuracy: 0.9702\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0516 - accuracy: 0.9804\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0560 - accuracy: 0.9761\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0374 - accuracy: 0.9856\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0384 - accuracy: 0.9819\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0289 - accuracy: 0.9905\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0511 - accuracy: 0.9842\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0259 - accuracy: 0.9929\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0151 - accuracy: 0.9934\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0385 - accuracy: 0.9906\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0745 - accuracy: 0.9762\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0321 - accuracy: 0.9919\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0557 - accuracy: 0.9772\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0305 - accuracy: 0.9908\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0293 - accuracy: 0.9877\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0412 - accuracy: 0.9824\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0365 - accuracy: 0.9882\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0480 - accuracy: 0.9812\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0370 - accuracy: 0.9863\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0552 - accuracy: 0.9741\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0278 - accuracy: 0.9935\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0239 - accuracy: 0.9941\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0199 - accuracy: 0.9953\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0390 - accuracy: 0.9856\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0132 - accuracy: 0.9938\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0203 - accuracy: 0.9933\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0507 - accuracy: 0.9793\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1023 - accuracy: 0.9672\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0281 - accuracy: 0.9889\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0460 - accuracy: 0.9769\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0307 - accuracy: 0.9853\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0347 - accuracy: 0.9874\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0114 - accuracy: 0.9966\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0360 - accuracy: 0.9909\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0254 - accuracy: 0.9922\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0206 - accuracy: 0.9948\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0079 - accuracy: 0.9969\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0225 - accuracy: 0.9899\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0267 - accuracy: 0.9940\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0214 - accuracy: 0.9884\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0825 - accuracy: 0.9897\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0228 - accuracy: 0.9939\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0318 - accuracy: 0.9895\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0462 - accuracy: 0.9891\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0309 - accuracy: 0.9917\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0542 - accuracy: 0.9801\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0395 - accuracy: 0.9808\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0103 - accuracy: 0.9978\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0102 - accuracy: 0.9934\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0205 - accuracy: 0.9945\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0327 - accuracy: 0.9840\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0199 - accuracy: 0.9920\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0137 - accuracy: 0.9929\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0162 - accuracy: 0.9957\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0151 - accuracy: 0.9947\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0111 - accuracy: 0.9944\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0169 - accuracy: 0.9948\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0187 - accuracy: 0.9931\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0320 - accuracy: 0.9884\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0558 - accuracy: 0.9867\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0300 - accuracy: 0.9898\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0276 - accuracy: 0.9882\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0664 - accuracy: 0.9784\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0269 - accuracy: 0.9930\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0283 - accuracy: 0.9927\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0280 - accuracy: 0.9863\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0149 - accuracy: 0.9955\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0205 - accuracy: 0.9932\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0511 - accuracy: 0.9818\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0242 - accuracy: 0.9894\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0108 - accuracy: 0.9944\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0165 - accuracy: 0.9933\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.0104 - accuracy: 0.9959\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.5492 - accuracy: 0.8880\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 3s 64ms/step - loss: 1.3266 - accuracy: 0.6175\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3437 - accuracy: 0.8643\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.2275 - accuracy: 0.9121\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1859 - accuracy: 0.9252\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1565 - accuracy: 0.9403\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1510 - accuracy: 0.9351\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1261 - accuracy: 0.9518\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1277 - accuracy: 0.9504\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1056 - accuracy: 0.9571\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 0.0964 - accuracy: 0.9629\n",
            "8/8 [==============================] - 1s 54ms/step - loss: 2.6253 - accuracy: 0.4701\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 3s 65ms/step - loss: 1.0102 - accuracy: 0.5803\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.5011 - accuracy: 0.7684\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.3588 - accuracy: 0.8420\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3227 - accuracy: 0.8745\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2840 - accuracy: 0.8789\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2887 - accuracy: 0.8949\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2375 - accuracy: 0.9085\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2620 - accuracy: 0.8962\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2681 - accuracy: 0.8885\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2034 - accuracy: 0.9129\n",
            "8/8 [==============================] - 1s 52ms/step - loss: 0.3838 - accuracy: 0.8080\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.9012 - accuracy: 0.5707\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.4031 - accuracy: 0.8559\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.3246 - accuracy: 0.8727\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.2655 - accuracy: 0.8868\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.2558 - accuracy: 0.9223\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1985 - accuracy: 0.9098\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.2266 - accuracy: 0.9126\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2106 - accuracy: 0.9210\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1707 - accuracy: 0.9331\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1439 - accuracy: 0.9572\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.1060 - accuracy: 0.9720\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.9336 - accuracy: 0.5948\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.3882 - accuracy: 0.8390\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2894 - accuracy: 0.8962\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2488 - accuracy: 0.9058\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.2606 - accuracy: 0.9013\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1825 - accuracy: 0.9269\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 0.1835 - accuracy: 0.9359\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1670 - accuracy: 0.9415\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1260 - accuracy: 0.9486\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1125 - accuracy: 0.9511\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9828 - accuracy: 0.6920\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 3s 66ms/step - loss: 1.1970 - accuracy: 0.5780\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.4877 - accuracy: 0.8007\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.3528 - accuracy: 0.8429\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3070 - accuracy: 0.8691\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3042 - accuracy: 0.8837\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2892 - accuracy: 0.8578\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2506 - accuracy: 0.9072\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2455 - accuracy: 0.9020\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2029 - accuracy: 0.9166\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1934 - accuracy: 0.9321\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.2179 - accuracy: 0.9200\n",
            "Epoch 1/30\n",
            "32/32 [==============================] - 3s 65ms/step - loss: 0.6884 - accuracy: 0.6821\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2634 - accuracy: 0.8972\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2014 - accuracy: 0.9220\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1489 - accuracy: 0.9564\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1480 - accuracy: 0.9359\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1426 - accuracy: 0.9427\n",
            "Epoch 7/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1056 - accuracy: 0.9660\n",
            "Epoch 8/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0828 - accuracy: 0.9780\n",
            "Epoch 9/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0968 - accuracy: 0.9623\n",
            "Epoch 10/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1315 - accuracy: 0.9540\n",
            "Epoch 11/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0619 - accuracy: 0.9784\n",
            "Epoch 12/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0666 - accuracy: 0.9720\n",
            "Epoch 13/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0569 - accuracy: 0.9807\n",
            "Epoch 14/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0408 - accuracy: 0.9852\n",
            "Epoch 15/30\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 0.0664 - accuracy: 0.9774\n",
            "Epoch 16/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0496 - accuracy: 0.9831\n",
            "Epoch 17/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0462 - accuracy: 0.9839\n",
            "Epoch 18/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0274 - accuracy: 0.9910\n",
            "Epoch 19/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0310 - accuracy: 0.9866\n",
            "Epoch 20/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0302 - accuracy: 0.9860\n",
            "Epoch 21/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0340 - accuracy: 0.9871\n",
            "Epoch 22/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0299 - accuracy: 0.9877\n",
            "Epoch 23/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0360 - accuracy: 0.9830\n",
            "Epoch 24/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0188 - accuracy: 0.9933\n",
            "Epoch 25/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0183 - accuracy: 0.9932\n",
            "Epoch 26/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0325 - accuracy: 0.9868\n",
            "Epoch 27/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0214 - accuracy: 0.9896\n",
            "Epoch 28/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0245 - accuracy: 0.9866\n",
            "Epoch 29/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0250 - accuracy: 0.9889\n",
            "Epoch 30/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0113 - accuracy: 0.9991\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 7.2152 - accuracy: 0.2988\n",
            "Epoch 1/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.8146 - accuracy: 0.6439\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3426 - accuracy: 0.8617\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2676 - accuracy: 0.9043\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2646 - accuracy: 0.8932\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.2099 - accuracy: 0.9240\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2017 - accuracy: 0.9209\n",
            "Epoch 7/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1784 - accuracy: 0.9251\n",
            "Epoch 8/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1813 - accuracy: 0.9349\n",
            "Epoch 9/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1343 - accuracy: 0.9524\n",
            "Epoch 10/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1299 - accuracy: 0.9483\n",
            "Epoch 11/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1225 - accuracy: 0.9515\n",
            "Epoch 12/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1462 - accuracy: 0.9441\n",
            "Epoch 13/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1018 - accuracy: 0.9743\n",
            "Epoch 14/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1156 - accuracy: 0.9490\n",
            "Epoch 15/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0928 - accuracy: 0.9672\n",
            "Epoch 16/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0753 - accuracy: 0.9777\n",
            "Epoch 17/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0863 - accuracy: 0.9677\n",
            "Epoch 18/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0775 - accuracy: 0.9681\n",
            "Epoch 19/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0589 - accuracy: 0.9823\n",
            "Epoch 20/30\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 0.0741 - accuracy: 0.9690\n",
            "Epoch 21/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0733 - accuracy: 0.9727\n",
            "Epoch 22/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1028 - accuracy: 0.9677\n",
            "Epoch 23/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0786 - accuracy: 0.9732\n",
            "Epoch 24/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0588 - accuracy: 0.9768\n",
            "Epoch 25/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0381 - accuracy: 0.9926\n",
            "Epoch 26/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0570 - accuracy: 0.9809\n",
            "Epoch 27/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0399 - accuracy: 0.9917\n",
            "Epoch 28/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0889 - accuracy: 0.9738\n",
            "Epoch 29/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0698 - accuracy: 0.9806\n",
            "Epoch 30/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0411 - accuracy: 0.9906\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4914 - accuracy: 0.8840\n",
            "Epoch 1/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 1.0678 - accuracy: 0.5526\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.4643 - accuracy: 0.8055\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.3537 - accuracy: 0.8668\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.3128 - accuracy: 0.8807\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2672 - accuracy: 0.8891\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2621 - accuracy: 0.8836\n",
            "Epoch 7/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1898 - accuracy: 0.9225\n",
            "Epoch 8/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2280 - accuracy: 0.8922\n",
            "Epoch 9/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2285 - accuracy: 0.9088\n",
            "Epoch 10/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1834 - accuracy: 0.9320\n",
            "Epoch 11/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1682 - accuracy: 0.9248\n",
            "Epoch 12/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1506 - accuracy: 0.9402\n",
            "Epoch 13/30\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1603 - accuracy: 0.9346\n",
            "Epoch 14/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1377 - accuracy: 0.9443\n",
            "Epoch 15/30\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1093 - accuracy: 0.9584\n",
            "Epoch 16/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1189 - accuracy: 0.9608\n",
            "Epoch 17/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1134 - accuracy: 0.9575\n",
            "Epoch 18/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0970 - accuracy: 0.9681\n",
            "Epoch 19/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1023 - accuracy: 0.9667\n",
            "Epoch 20/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1152 - accuracy: 0.9507\n",
            "Epoch 21/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0868 - accuracy: 0.9597\n",
            "Epoch 22/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0886 - accuracy: 0.9675\n",
            "Epoch 23/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0732 - accuracy: 0.9731\n",
            "Epoch 24/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0736 - accuracy: 0.9745\n",
            "Epoch 25/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1023 - accuracy: 0.9467\n",
            "Epoch 26/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0668 - accuracy: 0.9737\n",
            "Epoch 27/30\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0643 - accuracy: 0.9720\n",
            "Epoch 28/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0652 - accuracy: 0.9705\n",
            "Epoch 29/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0530 - accuracy: 0.9768\n",
            "Epoch 30/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0463 - accuracy: 0.9835\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0655 - accuracy: 0.9760\n",
            "Epoch 1/30\n",
            "32/32 [==============================] - 3s 64ms/step - loss: 1.1949 - accuracy: 0.5540\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3705 - accuracy: 0.8488\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.2565 - accuracy: 0.9027\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1889 - accuracy: 0.9288\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1880 - accuracy: 0.9348\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1613 - accuracy: 0.9357\n",
            "Epoch 7/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1628 - accuracy: 0.9359\n",
            "Epoch 8/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1197 - accuracy: 0.9571\n",
            "Epoch 9/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1136 - accuracy: 0.9634\n",
            "Epoch 10/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1107 - accuracy: 0.9529\n",
            "Epoch 11/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0949 - accuracy: 0.9637\n",
            "Epoch 12/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0890 - accuracy: 0.9694\n",
            "Epoch 13/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0815 - accuracy: 0.9764\n",
            "Epoch 14/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0784 - accuracy: 0.9704\n",
            "Epoch 15/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0831 - accuracy: 0.9654\n",
            "Epoch 16/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0575 - accuracy: 0.9801\n",
            "Epoch 17/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0575 - accuracy: 0.9761\n",
            "Epoch 18/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0491 - accuracy: 0.9855\n",
            "Epoch 19/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0812 - accuracy: 0.9647\n",
            "Epoch 20/30\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 0.0665 - accuracy: 0.9766\n",
            "Epoch 21/30\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0382 - accuracy: 0.9879\n",
            "Epoch 22/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0512 - accuracy: 0.9801\n",
            "Epoch 23/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0607 - accuracy: 0.9802\n",
            "Epoch 24/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0485 - accuracy: 0.9781\n",
            "Epoch 25/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0412 - accuracy: 0.9856\n",
            "Epoch 26/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0326 - accuracy: 0.9857\n",
            "Epoch 27/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0318 - accuracy: 0.9869\n",
            "Epoch 28/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0249 - accuracy: 0.9899\n",
            "Epoch 29/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0629 - accuracy: 0.9703\n",
            "Epoch 30/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0464 - accuracy: 0.9820\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.7628 - accuracy: 0.6240\n",
            "Epoch 1/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 1.0583 - accuracy: 0.5449\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.4660 - accuracy: 0.8115\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.3484 - accuracy: 0.8389\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.3245 - accuracy: 0.8685\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2471 - accuracy: 0.9024\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2482 - accuracy: 0.9079\n",
            "Epoch 7/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2538 - accuracy: 0.8979\n",
            "Epoch 8/30\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.2402 - accuracy: 0.9014\n",
            "Epoch 9/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1865 - accuracy: 0.9291\n",
            "Epoch 10/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1789 - accuracy: 0.9334\n",
            "Epoch 11/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1505 - accuracy: 0.9418\n",
            "Epoch 12/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1691 - accuracy: 0.9362\n",
            "Epoch 13/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1613 - accuracy: 0.9438\n",
            "Epoch 14/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1382 - accuracy: 0.9462\n",
            "Epoch 15/30\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1058 - accuracy: 0.9677\n",
            "Epoch 16/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1059 - accuracy: 0.9661\n",
            "Epoch 17/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1199 - accuracy: 0.9476\n",
            "Epoch 18/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1031 - accuracy: 0.9620\n",
            "Epoch 19/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1130 - accuracy: 0.9586\n",
            "Epoch 20/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1175 - accuracy: 0.9556\n",
            "Epoch 21/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0764 - accuracy: 0.9818\n",
            "Epoch 22/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0860 - accuracy: 0.9660\n",
            "Epoch 23/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1248 - accuracy: 0.9530\n",
            "Epoch 24/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0758 - accuracy: 0.9813\n",
            "Epoch 25/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0633 - accuracy: 0.9750\n",
            "Epoch 26/30\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0638 - accuracy: 0.9770\n",
            "Epoch 27/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0539 - accuracy: 0.9751\n",
            "Epoch 28/30\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0645 - accuracy: 0.9781\n",
            "Epoch 29/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0584 - accuracy: 0.9747\n",
            "Epoch 30/30\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0570 - accuracy: 0.9814\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3257 - accuracy: 0.8760\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.7671 - accuracy: 0.6743\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2770 - accuracy: 0.9099\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2045 - accuracy: 0.9108\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1583 - accuracy: 0.9409\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1507 - accuracy: 0.9437\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1415 - accuracy: 0.9514\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1196 - accuracy: 0.9519\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0934 - accuracy: 0.9688\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0773 - accuracy: 0.9657\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0945 - accuracy: 0.9674\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0698 - accuracy: 0.9722\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0591 - accuracy: 0.9783\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0757 - accuracy: 0.9712\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0595 - accuracy: 0.9777\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0514 - accuracy: 0.9812\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0459 - accuracy: 0.9857\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0407 - accuracy: 0.9823\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0485 - accuracy: 0.9790\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0442 - accuracy: 0.9836\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0386 - accuracy: 0.9797\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0326 - accuracy: 0.9852\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0249 - accuracy: 0.9913\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0283 - accuracy: 0.9833\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0281 - accuracy: 0.9900\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0242 - accuracy: 0.9951\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0159 - accuracy: 0.9928\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0193 - accuracy: 0.9902\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0227 - accuracy: 0.9887\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0217 - accuracy: 0.9913\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0235 - accuracy: 0.9926\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0321 - accuracy: 0.9846\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0207 - accuracy: 0.9905\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0194 - accuracy: 0.9932\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0197 - accuracy: 0.9931\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0130 - accuracy: 0.9989\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0328 - accuracy: 0.9873\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0137 - accuracy: 0.9965\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0111 - accuracy: 0.9961\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0385 - accuracy: 0.9874\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0250 - accuracy: 0.9902\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0140 - accuracy: 0.9939\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0084 - accuracy: 0.9976\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0074 - accuracy: 0.9985\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0183 - accuracy: 0.9878\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0135 - accuracy: 0.9963\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3246 - accuracy: 0.9271\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1022 - accuracy: 0.9468\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0516 - accuracy: 0.9772\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0467 - accuracy: 0.9799\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0312 - accuracy: 0.9906\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 6.8960 - accuracy: 0.2829\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 65ms/step - loss: 1.2341 - accuracy: 0.5787\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.5372 - accuracy: 0.7381\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3722 - accuracy: 0.8659\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.2983 - accuracy: 0.9002\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2594 - accuracy: 0.9026\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2807 - accuracy: 0.8982\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2133 - accuracy: 0.9203\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2312 - accuracy: 0.9171\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1732 - accuracy: 0.9320\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1859 - accuracy: 0.9363\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1442 - accuracy: 0.9484\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1697 - accuracy: 0.9379\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1303 - accuracy: 0.9491\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1338 - accuracy: 0.9515\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1347 - accuracy: 0.9499\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0965 - accuracy: 0.9597\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1142 - accuracy: 0.9585\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1268 - accuracy: 0.9553\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0985 - accuracy: 0.9612\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0953 - accuracy: 0.9615\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1183 - accuracy: 0.9605\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1424 - accuracy: 0.9512\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0964 - accuracy: 0.9609\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1068 - accuracy: 0.9610\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0841 - accuracy: 0.9647\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0922 - accuracy: 0.9695\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0841 - accuracy: 0.9646\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0976 - accuracy: 0.9596\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0888 - accuracy: 0.9561\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0656 - accuracy: 0.9681\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0747 - accuracy: 0.9638\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0738 - accuracy: 0.9671\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0574 - accuracy: 0.9736\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0604 - accuracy: 0.9659\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0676 - accuracy: 0.9663\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0670 - accuracy: 0.9697\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0691 - accuracy: 0.9674\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0685 - accuracy: 0.9682\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0416 - accuracy: 0.9753\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0455 - accuracy: 0.9753\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0648 - accuracy: 0.9767\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0579 - accuracy: 0.9703\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0603 - accuracy: 0.9767\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0518 - accuracy: 0.9818\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0626 - accuracy: 0.9791\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0521 - accuracy: 0.9847\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0857 - accuracy: 0.9662\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0387 - accuracy: 0.9812\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0380 - accuracy: 0.9840\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0538 - accuracy: 0.9747\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1224 - accuracy: 0.8080\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 64ms/step - loss: 0.9880 - accuracy: 0.5262\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.5438 - accuracy: 0.7552\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.3625 - accuracy: 0.8513\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.3218 - accuracy: 0.8601\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2798 - accuracy: 0.8916\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2598 - accuracy: 0.8909\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.2415 - accuracy: 0.8926\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2297 - accuracy: 0.9043\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2271 - accuracy: 0.8990\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1868 - accuracy: 0.9186\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1743 - accuracy: 0.9397\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1549 - accuracy: 0.9456\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1765 - accuracy: 0.9235\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1695 - accuracy: 0.9290\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1407 - accuracy: 0.9467\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1371 - accuracy: 0.9480\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1513 - accuracy: 0.9431\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1444 - accuracy: 0.9280\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1468 - accuracy: 0.9408\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.1236 - accuracy: 0.9574\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1005 - accuracy: 0.9625\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1296 - accuracy: 0.9399\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1345 - accuracy: 0.9447\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1250 - accuracy: 0.9490\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0901 - accuracy: 0.9576\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0812 - accuracy: 0.9651\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1002 - accuracy: 0.9461\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0835 - accuracy: 0.9643\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0724 - accuracy: 0.9666\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0662 - accuracy: 0.9650\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0693 - accuracy: 0.9737\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0746 - accuracy: 0.9690\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0827 - accuracy: 0.9580\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0597 - accuracy: 0.9777\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0636 - accuracy: 0.9709\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0585 - accuracy: 0.9804\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0715 - accuracy: 0.9705\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0503 - accuracy: 0.9804\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0962 - accuracy: 0.9579\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0736 - accuracy: 0.9677\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0633 - accuracy: 0.9754\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0568 - accuracy: 0.9757\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0918 - accuracy: 0.9558\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0842 - accuracy: 0.9633\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0881 - accuracy: 0.9631\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0876 - accuracy: 0.9639\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0574 - accuracy: 0.9757\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0443 - accuracy: 0.9756\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0448 - accuracy: 0.9817\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0466 - accuracy: 0.9745\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0992 - accuracy: 0.9640\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.8651 - accuracy: 0.6050\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.3361 - accuracy: 0.8844\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2249 - accuracy: 0.9218\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1994 - accuracy: 0.9252\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1556 - accuracy: 0.9375\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1665 - accuracy: 0.9466\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2086 - accuracy: 0.9315\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1335 - accuracy: 0.9504\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1226 - accuracy: 0.9618\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1106 - accuracy: 0.9572\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1041 - accuracy: 0.9668\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0851 - accuracy: 0.9715\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0854 - accuracy: 0.9673\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1009 - accuracy: 0.9641\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1139 - accuracy: 0.9534\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1030 - accuracy: 0.9625\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0633 - accuracy: 0.9763\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0534 - accuracy: 0.9840\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0503 - accuracy: 0.9741\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0713 - accuracy: 0.9695\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0612 - accuracy: 0.9706\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0411 - accuracy: 0.9877\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0566 - accuracy: 0.9838\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0622 - accuracy: 0.9836\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0456 - accuracy: 0.9822\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0361 - accuracy: 0.9854\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0654 - accuracy: 0.9806\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0469 - accuracy: 0.9806\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0283 - accuracy: 0.9894\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0250 - accuracy: 0.9940\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0311 - accuracy: 0.9846\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0313 - accuracy: 0.9884\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0601 - accuracy: 0.9829\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0559 - accuracy: 0.9844\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0302 - accuracy: 0.9874\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0247 - accuracy: 0.9933\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0345 - accuracy: 0.9870\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0422 - accuracy: 0.9880\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0428 - accuracy: 0.9886\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0392 - accuracy: 0.9833\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0174 - accuracy: 0.9920\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0233 - accuracy: 0.9861\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0264 - accuracy: 0.9926\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0367 - accuracy: 0.9843\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0257 - accuracy: 0.9907\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0361 - accuracy: 0.9879\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0118 - accuracy: 0.9987\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0243 - accuracy: 0.9896\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0259 - accuracy: 0.9912\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0394 - accuracy: 0.9859\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 3.9121 - accuracy: 0.6360\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.7894 - accuracy: 0.6010\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.4112 - accuracy: 0.8175\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.3527 - accuracy: 0.8446\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2602 - accuracy: 0.8955\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2640 - accuracy: 0.9023\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2296 - accuracy: 0.9115\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2278 - accuracy: 0.9116\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1869 - accuracy: 0.9225\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1697 - accuracy: 0.9323\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1930 - accuracy: 0.9265\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1783 - accuracy: 0.9313\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1476 - accuracy: 0.9393\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.1088 - accuracy: 0.9571\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1292 - accuracy: 0.9473\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1045 - accuracy: 0.9584\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1029 - accuracy: 0.9646\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1336 - accuracy: 0.9464\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0852 - accuracy: 0.9661\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0807 - accuracy: 0.9780\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0846 - accuracy: 0.9666\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0685 - accuracy: 0.9753\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0592 - accuracy: 0.9852\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0470 - accuracy: 0.9816\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0666 - accuracy: 0.9756\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0618 - accuracy: 0.9760\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0436 - accuracy: 0.9821\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0451 - accuracy: 0.9846\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0348 - accuracy: 0.9913\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0567 - accuracy: 0.9757\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0434 - accuracy: 0.9837\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0508 - accuracy: 0.9807\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0439 - accuracy: 0.9805\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0393 - accuracy: 0.9795\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0318 - accuracy: 0.9887\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0357 - accuracy: 0.9855\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0437 - accuracy: 0.9866\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0461 - accuracy: 0.9846\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0359 - accuracy: 0.9858\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0405 - accuracy: 0.9888\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0515 - accuracy: 0.9778\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0357 - accuracy: 0.9905\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0284 - accuracy: 0.9841\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0345 - accuracy: 0.9839\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0411 - accuracy: 0.9849\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0185 - accuracy: 0.9941\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0157 - accuracy: 0.9965\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0194 - accuracy: 0.9899\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0203 - accuracy: 0.9973\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0328 - accuracy: 0.9875\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0452 - accuracy: 0.9769\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6025 - accuracy: 0.8440\n",
            "Epoch 1/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.7136 - accuracy: 0.6605\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3230 - accuracy: 0.8613\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1991 - accuracy: 0.9216\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1783 - accuracy: 0.9225\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1309 - accuracy: 0.9567\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1130 - accuracy: 0.9591\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1144 - accuracy: 0.9577\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1105 - accuracy: 0.9587\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1220 - accuracy: 0.9504\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0553 - accuracy: 0.9796\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0713 - accuracy: 0.9740\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0608 - accuracy: 0.9773\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0705 - accuracy: 0.9807\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0624 - accuracy: 0.9757\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0537 - accuracy: 0.9826\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0437 - accuracy: 0.9863\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0289 - accuracy: 0.9891\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0451 - accuracy: 0.9866\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0478 - accuracy: 0.9803\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0466 - accuracy: 0.9859\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0227 - accuracy: 0.9921\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0397 - accuracy: 0.9869\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0417 - accuracy: 0.9855\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0238 - accuracy: 0.9965\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0256 - accuracy: 0.9953\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0321 - accuracy: 0.9873\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0220 - accuracy: 0.9937\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0195 - accuracy: 0.9948\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0249 - accuracy: 0.9919\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0171 - accuracy: 0.9910\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0174 - accuracy: 0.9955\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0265 - accuracy: 0.9877\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0223 - accuracy: 0.9899\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0115 - accuracy: 0.9979\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0222 - accuracy: 0.9936\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0107 - accuracy: 0.9976\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0148 - accuracy: 0.9952\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0127 - accuracy: 0.9929\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0365 - accuracy: 0.9861\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0125 - accuracy: 0.9969\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0210 - accuracy: 0.9877\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0483 - accuracy: 0.9898\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0209 - accuracy: 0.9955\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0220 - accuracy: 0.9906\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0458 - accuracy: 0.9880\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0164 - accuracy: 0.9881\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0066 - accuracy: 0.9982\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0148 - accuracy: 0.9924\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0204 - accuracy: 0.9932\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0128 - accuracy: 0.9946\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0221 - accuracy: 0.9904\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0213 - accuracy: 0.9952\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0074 - accuracy: 0.9989\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0048 - accuracy: 0.9978\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0066 - accuracy: 0.9961\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0085 - accuracy: 0.9981\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0072 - accuracy: 0.9988\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0080 - accuracy: 0.9966\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0737 - accuracy: 0.9841\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1080 - accuracy: 0.9630\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0693 - accuracy: 0.9739\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0250 - accuracy: 0.9925\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0143 - accuracy: 0.9975\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0150 - accuracy: 0.9972\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0195 - accuracy: 0.9928\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0238 - accuracy: 0.9926\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0102 - accuracy: 0.9960\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0088 - accuracy: 0.9987\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0078 - accuracy: 0.9985\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0089 - accuracy: 0.9990\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0038 - accuracy: 0.9983\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0028 - accuracy: 0.9998\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0132 - accuracy: 0.9948\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0070 - accuracy: 0.9966\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0052 - accuracy: 0.9994\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0128 - accuracy: 0.9966\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0099 - accuracy: 0.9984\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0073 - accuracy: 0.9997\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0049 - accuracy: 0.9991\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0051 - accuracy: 0.9990\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0050 - accuracy: 0.9980\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0224 - accuracy: 0.9955\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0369 - accuracy: 0.9842\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0121 - accuracy: 0.9936\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0132 - accuracy: 0.9950\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0032 - accuracy: 0.9999\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0084 - accuracy: 0.9951\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0074 - accuracy: 0.9961\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0074 - accuracy: 0.9936\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0032 - accuracy: 0.9992\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0071 - accuracy: 0.9978\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 11.7230 - accuracy: 0.2908\n",
            "Epoch 1/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1060 - accuracy: 0.6466\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.4027 - accuracy: 0.8303\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.3508 - accuracy: 0.8856\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2923 - accuracy: 0.8890\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2433 - accuracy: 0.8934\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2323 - accuracy: 0.9119\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1962 - accuracy: 0.9302\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1983 - accuracy: 0.9246\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1894 - accuracy: 0.9364\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1711 - accuracy: 0.9297\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1635 - accuracy: 0.9394\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1458 - accuracy: 0.9391\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1246 - accuracy: 0.9623\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1568 - accuracy: 0.9316\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1166 - accuracy: 0.9467\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1281 - accuracy: 0.9506\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1166 - accuracy: 0.9588\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1053 - accuracy: 0.9557\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1134 - accuracy: 0.9524\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1166 - accuracy: 0.9676\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1074 - accuracy: 0.9497\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1009 - accuracy: 0.9567\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0802 - accuracy: 0.9757\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0801 - accuracy: 0.9701\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0844 - accuracy: 0.9659\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0818 - accuracy: 0.9671\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0790 - accuracy: 0.9631\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0667 - accuracy: 0.9756\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0743 - accuracy: 0.9704\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0823 - accuracy: 0.9775\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0601 - accuracy: 0.9780\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0529 - accuracy: 0.9821\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0595 - accuracy: 0.9790\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0826 - accuracy: 0.9601\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0848 - accuracy: 0.9740\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0857 - accuracy: 0.9670\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0737 - accuracy: 0.9812\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0691 - accuracy: 0.9679\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0519 - accuracy: 0.9823\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0552 - accuracy: 0.9829\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0646 - accuracy: 0.9716\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0616 - accuracy: 0.9744\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0597 - accuracy: 0.9746\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0555 - accuracy: 0.9738\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0361 - accuracy: 0.9914\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0514 - accuracy: 0.9774\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0344 - accuracy: 0.9843\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0317 - accuracy: 0.9845\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0480 - accuracy: 0.9860\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0367 - accuracy: 0.9849\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0457 - accuracy: 0.9888\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0292 - accuracy: 0.9889\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0624 - accuracy: 0.9810\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0813 - accuracy: 0.9675\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0410 - accuracy: 0.9841\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0635 - accuracy: 0.9782\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0360 - accuracy: 0.9895\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0384 - accuracy: 0.9890\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0233 - accuracy: 0.9953\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0386 - accuracy: 0.9801\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0319 - accuracy: 0.9860\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0367 - accuracy: 0.9869\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0422 - accuracy: 0.9839\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0337 - accuracy: 0.9860\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0252 - accuracy: 0.9905\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0159 - accuracy: 0.9961\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0261 - accuracy: 0.9896\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0315 - accuracy: 0.9856\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0189 - accuracy: 0.9949\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0301 - accuracy: 0.9864\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0237 - accuracy: 0.9924\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0550 - accuracy: 0.9800\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0492 - accuracy: 0.9783\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0615 - accuracy: 0.9778\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0358 - accuracy: 0.9922\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0467 - accuracy: 0.9837\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0327 - accuracy: 0.9891\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0325 - accuracy: 0.9851\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0367 - accuracy: 0.9879\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0368 - accuracy: 0.9872\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0291 - accuracy: 0.9860\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0206 - accuracy: 0.9938\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0189 - accuracy: 0.9943\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0299 - accuracy: 0.9849\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0307 - accuracy: 0.9872\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0287 - accuracy: 0.9852\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0157 - accuracy: 0.9950\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0172 - accuracy: 0.9921\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0126 - accuracy: 0.9974\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0158 - accuracy: 0.9942\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0195 - accuracy: 0.9919\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0198 - accuracy: 0.9927\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0208 - accuracy: 0.9906\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0254 - accuracy: 0.9896\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0375 - accuracy: 0.9890\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0478 - accuracy: 0.9808\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0193 - accuracy: 0.9974\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0259 - accuracy: 0.9903\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0267 - accuracy: 0.9866\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0302 - accuracy: 0.9891\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7699 - accuracy: 0.9240\n",
            "Epoch 1/100\n",
            "32/32 [==============================] - 3s 64ms/step - loss: 0.9445 - accuracy: 0.5429\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.4453 - accuracy: 0.8008\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3511 - accuracy: 0.8551\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2902 - accuracy: 0.8907\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2442 - accuracy: 0.9225\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2688 - accuracy: 0.8930\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2008 - accuracy: 0.9286\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1969 - accuracy: 0.9122\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1986 - accuracy: 0.9135\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1868 - accuracy: 0.9231\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1881 - accuracy: 0.9208\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1701 - accuracy: 0.9328\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1533 - accuracy: 0.9377\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1307 - accuracy: 0.9430\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.1270 - accuracy: 0.9507\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1298 - accuracy: 0.9453\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1060 - accuracy: 0.9572\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1000 - accuracy: 0.9587\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0952 - accuracy: 0.9544\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1107 - accuracy: 0.9605\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0810 - accuracy: 0.9708\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0784 - accuracy: 0.9679\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0992 - accuracy: 0.9611\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1566 - accuracy: 0.9423\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0944 - accuracy: 0.9672\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0799 - accuracy: 0.9716\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0600 - accuracy: 0.9829\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0802 - accuracy: 0.9693\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0724 - accuracy: 0.9685\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0727 - accuracy: 0.9629\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0788 - accuracy: 0.9652\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0607 - accuracy: 0.9763\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0739 - accuracy: 0.9705\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0664 - accuracy: 0.9710\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0861 - accuracy: 0.9673\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0555 - accuracy: 0.9768\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0581 - accuracy: 0.9785\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0473 - accuracy: 0.9793\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0594 - accuracy: 0.9716\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0404 - accuracy: 0.9865\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0382 - accuracy: 0.9920\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0549 - accuracy: 0.9784\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0476 - accuracy: 0.9847\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0374 - accuracy: 0.9761\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0379 - accuracy: 0.9800\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0330 - accuracy: 0.9869\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0357 - accuracy: 0.9808\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0337 - accuracy: 0.9900\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0465 - accuracy: 0.9772\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0596 - accuracy: 0.9706\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0959 - accuracy: 0.9693\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0477 - accuracy: 0.9750\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0455 - accuracy: 0.9857\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0272 - accuracy: 0.9887\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0289 - accuracy: 0.9883\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0431 - accuracy: 0.9827\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0381 - accuracy: 0.9871\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0553 - accuracy: 0.9678\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0327 - accuracy: 0.9901\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0280 - accuracy: 0.9884\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0372 - accuracy: 0.9868\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0255 - accuracy: 0.9909\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0393 - accuracy: 0.9782\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0535 - accuracy: 0.9810\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0366 - accuracy: 0.9863\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0324 - accuracy: 0.9838\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0246 - accuracy: 0.9873\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0278 - accuracy: 0.9889\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0526 - accuracy: 0.9805\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0287 - accuracy: 0.9903\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0318 - accuracy: 0.9894\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0182 - accuracy: 0.9898\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0152 - accuracy: 0.9917\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0209 - accuracy: 0.9953\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0171 - accuracy: 0.9918\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0304 - accuracy: 0.9822\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0261 - accuracy: 0.9870\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0622 - accuracy: 0.9729\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0463 - accuracy: 0.9810\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0366 - accuracy: 0.9832\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0322 - accuracy: 0.9871\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0261 - accuracy: 0.9893\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0301 - accuracy: 0.9849\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0307 - accuracy: 0.9887\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0324 - accuracy: 0.9890\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0321 - accuracy: 0.9844\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0180 - accuracy: 0.9954\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0192 - accuracy: 0.9930\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0131 - accuracy: 0.9950\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0225 - accuracy: 0.9892\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0158 - accuracy: 0.9915\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0227 - accuracy: 0.9903\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0196 - accuracy: 0.9883\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0221 - accuracy: 0.9929\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0239 - accuracy: 0.9909\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0265 - accuracy: 0.9846\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0242 - accuracy: 0.9900\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0199 - accuracy: 0.9879\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0146 - accuracy: 0.9946\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0215 - accuracy: 0.9927\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0712 - accuracy: 0.9800\n",
            "Epoch 1/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.9049 - accuracy: 0.6288\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2847 - accuracy: 0.8898\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2303 - accuracy: 0.9251\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1850 - accuracy: 0.9336\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1544 - accuracy: 0.9424\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1711 - accuracy: 0.9363\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1342 - accuracy: 0.9498\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1409 - accuracy: 0.9625\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1178 - accuracy: 0.9547\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1114 - accuracy: 0.9534\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1192 - accuracy: 0.9437\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0955 - accuracy: 0.9590\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0794 - accuracy: 0.9772\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0662 - accuracy: 0.9808\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0709 - accuracy: 0.9736\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0865 - accuracy: 0.9726\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0659 - accuracy: 0.9725\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0903 - accuracy: 0.9718\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0735 - accuracy: 0.9755\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0444 - accuracy: 0.9824\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0398 - accuracy: 0.9862\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0405 - accuracy: 0.9794\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0429 - accuracy: 0.9809\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0404 - accuracy: 0.9848\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0376 - accuracy: 0.9830\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0668 - accuracy: 0.9818\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0596 - accuracy: 0.9765\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0376 - accuracy: 0.9858\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0396 - accuracy: 0.9841\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0437 - accuracy: 0.9820\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0292 - accuracy: 0.9905\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0267 - accuracy: 0.9928\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0182 - accuracy: 0.9945\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0391 - accuracy: 0.9836\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0428 - accuracy: 0.9853\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0179 - accuracy: 0.9948\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0269 - accuracy: 0.9888\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0195 - accuracy: 0.9944\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0252 - accuracy: 0.9920\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0177 - accuracy: 0.9950\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0231 - accuracy: 0.9905\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0186 - accuracy: 0.9892\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0462 - accuracy: 0.9872\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0238 - accuracy: 0.9941\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0164 - accuracy: 0.9923\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0216 - accuracy: 0.9928\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0171 - accuracy: 0.9964\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0153 - accuracy: 0.9938\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0294 - accuracy: 0.9920\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0352 - accuracy: 0.9879\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0180 - accuracy: 0.9951\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0264 - accuracy: 0.9898\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0246 - accuracy: 0.9934\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0146 - accuracy: 0.9951\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 0.0417 - accuracy: 0.9883\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3077 - accuracy: 0.9264\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0460 - accuracy: 0.9860\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0284 - accuracy: 0.9880\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0149 - accuracy: 0.9975\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0265 - accuracy: 0.9918\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0327 - accuracy: 0.9914\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0328 - accuracy: 0.9935\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0174 - accuracy: 0.9946\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0174 - accuracy: 0.9926\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0181 - accuracy: 0.9911\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0072 - accuracy: 0.9999\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0037 - accuracy: 0.9999\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0190 - accuracy: 0.9973\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0141 - accuracy: 0.9964\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0074 - accuracy: 0.9991\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0081 - accuracy: 0.9969\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0051 - accuracy: 0.9988\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0050 - accuracy: 0.9986\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0136 - accuracy: 0.9963\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0049 - accuracy: 0.9986\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0186 - accuracy: 0.9944\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0174 - accuracy: 0.9948\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0161 - accuracy: 0.9927\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0116 - accuracy: 0.9963\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0199 - accuracy: 0.9923\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0080 - accuracy: 0.9977\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0147 - accuracy: 0.9948\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0203 - accuracy: 0.9954\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0065 - accuracy: 0.9983\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0166 - accuracy: 0.9920\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0056 - accuracy: 0.9993\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0094 - accuracy: 0.9969\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0090 - accuracy: 0.9977\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0170 - accuracy: 0.9939\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0211 - accuracy: 0.9908\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0124 - accuracy: 0.9942\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0128 - accuracy: 0.9976\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0080 - accuracy: 0.9984\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0101 - accuracy: 0.9953\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0052 - accuracy: 0.9993\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0108 - accuracy: 0.9977\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0058 - accuracy: 0.9987\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0040 - accuracy: 0.9988\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0060 - accuracy: 0.9975\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0054 - accuracy: 0.9989\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 6.0587 - accuracy: 0.6360\n",
            "Epoch 1/100\n",
            "32/32 [==============================] - 3s 63ms/step - loss: 0.9834 - accuracy: 0.5931\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.4169 - accuracy: 0.8235\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3707 - accuracy: 0.8330\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.3269 - accuracy: 0.8673\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2746 - accuracy: 0.8857\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.2471 - accuracy: 0.9137\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.2099 - accuracy: 0.9075\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1985 - accuracy: 0.9160\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1959 - accuracy: 0.9252\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1884 - accuracy: 0.9185\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.1796 - accuracy: 0.9367\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1363 - accuracy: 0.9475\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1205 - accuracy: 0.9616\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1301 - accuracy: 0.9437\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1205 - accuracy: 0.9474\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0982 - accuracy: 0.9702\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1013 - accuracy: 0.9558\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0880 - accuracy: 0.9628\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.1020 - accuracy: 0.9667\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0705 - accuracy: 0.9768\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0652 - accuracy: 0.9769\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0886 - accuracy: 0.9652\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0681 - accuracy: 0.9776\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0638 - accuracy: 0.9739\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0842 - accuracy: 0.9701\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0648 - accuracy: 0.9761\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0663 - accuracy: 0.9731\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0628 - accuracy: 0.9787\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0588 - accuracy: 0.9826\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0494 - accuracy: 0.9863\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0454 - accuracy: 0.9857\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0467 - accuracy: 0.9829\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0415 - accuracy: 0.9862\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0564 - accuracy: 0.9866\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0433 - accuracy: 0.9883\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0471 - accuracy: 0.9836\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0295 - accuracy: 0.9897\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0275 - accuracy: 0.9901\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0412 - accuracy: 0.9879\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0525 - accuracy: 0.9843\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0325 - accuracy: 0.9905\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0457 - accuracy: 0.9873\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0442 - accuracy: 0.9773\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0315 - accuracy: 0.9938\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0297 - accuracy: 0.9887\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0254 - accuracy: 0.9892\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0256 - accuracy: 0.9922\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0253 - accuracy: 0.9938\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0357 - accuracy: 0.9853\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0339 - accuracy: 0.9827\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0268 - accuracy: 0.9913\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0285 - accuracy: 0.9880\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0213 - accuracy: 0.9930\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0178 - accuracy: 0.9934\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0300 - accuracy: 0.9869\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0296 - accuracy: 0.9870\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0227 - accuracy: 0.9933\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0165 - accuracy: 0.9968\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0182 - accuracy: 0.9940\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0194 - accuracy: 0.9886\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0310 - accuracy: 0.9859\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0214 - accuracy: 0.9885\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0188 - accuracy: 0.9930\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0184 - accuracy: 0.9940\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0409 - accuracy: 0.9810\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0432 - accuracy: 0.9777\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0262 - accuracy: 0.9878\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0178 - accuracy: 0.9923\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0151 - accuracy: 0.9936\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0192 - accuracy: 0.9916\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0097 - accuracy: 0.9945\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0128 - accuracy: 0.9982\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0621 - accuracy: 0.9853\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0212 - accuracy: 0.9928\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0156 - accuracy: 0.9977\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0103 - accuracy: 0.9986\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0155 - accuracy: 0.9943\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0744 - accuracy: 0.9736\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.1233 - accuracy: 0.9634\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0418 - accuracy: 0.9818\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0501 - accuracy: 0.9853\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0241 - accuracy: 0.9950\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0233 - accuracy: 0.9890\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0224 - accuracy: 0.9924\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0170 - accuracy: 0.9964\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0134 - accuracy: 0.9953\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0142 - accuracy: 0.9968\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0137 - accuracy: 0.9961\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0258 - accuracy: 0.9909\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0189 - accuracy: 0.9926\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0149 - accuracy: 0.9934\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0097 - accuracy: 0.9968\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0134 - accuracy: 0.9914\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0073 - accuracy: 0.9980\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0101 - accuracy: 0.9967\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0305 - accuracy: 0.9943\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0219 - accuracy: 0.9909\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0309 - accuracy: 0.9857\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0343 - accuracy: 0.9885\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0269 - accuracy: 0.9930\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5271 - accuracy: 0.8640\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 4s 151ms/step - loss: 1.2573 - accuracy: 0.5453\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.5633 - accuracy: 0.6754\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.3966 - accuracy: 0.8447\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.2931 - accuracy: 0.8841\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.2409 - accuracy: 0.8997\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2333 - accuracy: 0.8921\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2045 - accuracy: 0.9103\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2035 - accuracy: 0.9328\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1641 - accuracy: 0.9448\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.1463 - accuracy: 0.9481\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 1.6468 - accuracy: 0.5657\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 3s 154ms/step - loss: 1.0967 - accuracy: 0.6138\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.4930 - accuracy: 0.7772\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.3915 - accuracy: 0.8574\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.3154 - accuracy: 0.8831\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2664 - accuracy: 0.8946\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2378 - accuracy: 0.9008\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2114 - accuracy: 0.9232\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2216 - accuracy: 0.9263\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1976 - accuracy: 0.9310\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1750 - accuracy: 0.9483\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 0.3966 - accuracy: 0.8320\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 2.0410 - accuracy: 0.5254\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.5957 - accuracy: 0.6711\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.4614 - accuracy: 0.8254\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.3651 - accuracy: 0.8501\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.3554 - accuracy: 0.8633\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2931 - accuracy: 0.8733\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.2928 - accuracy: 0.8794\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2496 - accuracy: 0.9012\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2297 - accuracy: 0.9114\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2314 - accuracy: 0.9031\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1688 - accuracy: 0.9480\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 1.4227 - accuracy: 0.5247\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.5122 - accuracy: 0.7794\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.3268 - accuracy: 0.8766\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2677 - accuracy: 0.9051\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1849 - accuracy: 0.9447\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1932 - accuracy: 0.9406\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1627 - accuracy: 0.9350\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.1589 - accuracy: 0.9467\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1441 - accuracy: 0.9484\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1339 - accuracy: 0.9544\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.6190 - accuracy: 0.6200\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 1.0558 - accuracy: 0.5157\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.5779 - accuracy: 0.6951\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.4791 - accuracy: 0.7711\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.3676 - accuracy: 0.8534\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.3373 - accuracy: 0.8461\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.3081 - accuracy: 0.8627\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2889 - accuracy: 0.8845\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.2542 - accuracy: 0.9002\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2561 - accuracy: 0.8949\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2238 - accuracy: 0.9201\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1708 - accuracy: 0.9680\n",
            "Epoch 1/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.9354 - accuracy: 0.5803\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.4873 - accuracy: 0.7857\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.3211 - accuracy: 0.8515\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.2759 - accuracy: 0.8867\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.2252 - accuracy: 0.9200\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1747 - accuracy: 0.9383\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1505 - accuracy: 0.9434\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1494 - accuracy: 0.9418\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1583 - accuracy: 0.9487\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1058 - accuracy: 0.9709\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.1157 - accuracy: 0.9619\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0981 - accuracy: 0.9717\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0999 - accuracy: 0.9632\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1265 - accuracy: 0.9552\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0923 - accuracy: 0.9682\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0683 - accuracy: 0.9771\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0767 - accuracy: 0.9671\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0923 - accuracy: 0.9668\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0622 - accuracy: 0.9698\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0611 - accuracy: 0.9801\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0502 - accuracy: 0.9816\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0539 - accuracy: 0.9842\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0471 - accuracy: 0.9824\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0512 - accuracy: 0.9851\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0472 - accuracy: 0.9858\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0419 - accuracy: 0.9891\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0368 - accuracy: 0.9870\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0506 - accuracy: 0.9826\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0613 - accuracy: 0.9832\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0371 - accuracy: 0.9868\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 6.4629 - accuracy: 0.3944\n",
            "Epoch 1/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 1.2423 - accuracy: 0.6431\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.4630 - accuracy: 0.8127\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.3396 - accuracy: 0.8785\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.3171 - accuracy: 0.8868\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2750 - accuracy: 0.9005\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2492 - accuracy: 0.9136\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.2382 - accuracy: 0.9088\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.1778 - accuracy: 0.9288\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.2032 - accuracy: 0.9372\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1629 - accuracy: 0.9422\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1522 - accuracy: 0.9384\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1508 - accuracy: 0.9475\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1170 - accuracy: 0.9629\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0968 - accuracy: 0.9723\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0969 - accuracy: 0.9617\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1444 - accuracy: 0.9400\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1370 - accuracy: 0.9347\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0781 - accuracy: 0.9702\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0912 - accuracy: 0.9702\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0799 - accuracy: 0.9652\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0627 - accuracy: 0.9809\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0725 - accuracy: 0.9735\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0702 - accuracy: 0.9715\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0808 - accuracy: 0.9703\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0577 - accuracy: 0.9783\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0594 - accuracy: 0.9813\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0659 - accuracy: 0.9727\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0564 - accuracy: 0.9814\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0674 - accuracy: 0.9792\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0392 - accuracy: 0.9875\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4544 - accuracy: 0.9120\n",
            "Epoch 1/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.9979 - accuracy: 0.5523\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.4754 - accuracy: 0.8002\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.3161 - accuracy: 0.8705\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.3223 - accuracy: 0.8909\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2851 - accuracy: 0.8937\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2384 - accuracy: 0.9114\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2552 - accuracy: 0.9023\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2267 - accuracy: 0.9071\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2084 - accuracy: 0.9121\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.1683 - accuracy: 0.9314\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1486 - accuracy: 0.9382\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.1334 - accuracy: 0.9508\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.1085 - accuracy: 0.9566\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1464 - accuracy: 0.9391\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.1074 - accuracy: 0.9579\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1046 - accuracy: 0.9645\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0990 - accuracy: 0.9669\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0925 - accuracy: 0.9647\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0943 - accuracy: 0.9612\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.1045 - accuracy: 0.9567\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0911 - accuracy: 0.9630\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0728 - accuracy: 0.9744\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0706 - accuracy: 0.9706\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0619 - accuracy: 0.9811\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0640 - accuracy: 0.9737\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0663 - accuracy: 0.9725\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0675 - accuracy: 0.9707\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0560 - accuracy: 0.9805\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1015 - accuracy: 0.9596\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0624 - accuracy: 0.9759\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.1226 - accuracy: 0.9640\n",
            "Epoch 1/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 1.1864 - accuracy: 0.4994\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.5308 - accuracy: 0.7586\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.3455 - accuracy: 0.8720\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2533 - accuracy: 0.9026\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2361 - accuracy: 0.9213\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2125 - accuracy: 0.9272\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2000 - accuracy: 0.9278\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.2021 - accuracy: 0.9195\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1696 - accuracy: 0.9390\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1528 - accuracy: 0.9326\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1484 - accuracy: 0.9465\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1271 - accuracy: 0.9581\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1128 - accuracy: 0.9636\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1189 - accuracy: 0.9617\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1129 - accuracy: 0.9554\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0913 - accuracy: 0.9599\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1207 - accuracy: 0.9596\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0735 - accuracy: 0.9774\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0739 - accuracy: 0.9706\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0801 - accuracy: 0.9646\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0754 - accuracy: 0.9681\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0692 - accuracy: 0.9677\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0932 - accuracy: 0.9551\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0694 - accuracy: 0.9767\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0478 - accuracy: 0.9849\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0528 - accuracy: 0.9790\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0584 - accuracy: 0.9765\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0515 - accuracy: 0.9799\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0539 - accuracy: 0.9714\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0648 - accuracy: 0.9559\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 3.0576 - accuracy: 0.6600\n",
            "Epoch 1/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 2.0924 - accuracy: 0.5687\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.6227 - accuracy: 0.6598\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.5214 - accuracy: 0.7911\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.4195 - accuracy: 0.8338\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.3360 - accuracy: 0.8623\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.3016 - accuracy: 0.8761\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2806 - accuracy: 0.8816\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2193 - accuracy: 0.9163\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.2451 - accuracy: 0.8996\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2135 - accuracy: 0.9230\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2351 - accuracy: 0.9048\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1857 - accuracy: 0.9332\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2109 - accuracy: 0.9148\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1886 - accuracy: 0.9243\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.1468 - accuracy: 0.9356\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1685 - accuracy: 0.9311\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1543 - accuracy: 0.9414\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1360 - accuracy: 0.9382\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1403 - accuracy: 0.9439\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1324 - accuracy: 0.9533\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1287 - accuracy: 0.9478\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1051 - accuracy: 0.9575\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1135 - accuracy: 0.9593\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0878 - accuracy: 0.9622\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0921 - accuracy: 0.9657\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1322 - accuracy: 0.9438\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1401 - accuracy: 0.9482\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0842 - accuracy: 0.9660\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0915 - accuracy: 0.9658\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1076 - accuracy: 0.9624\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3691 - accuracy: 0.8240\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 1.3589 - accuracy: 0.5597\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.5403 - accuracy: 0.7255\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.3854 - accuracy: 0.8337\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2931 - accuracy: 0.8852\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2016 - accuracy: 0.9237\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1745 - accuracy: 0.9301\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.2163 - accuracy: 0.9181\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1527 - accuracy: 0.9504\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1405 - accuracy: 0.9555\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1314 - accuracy: 0.9498\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.1275 - accuracy: 0.9480\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1293 - accuracy: 0.9518\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1177 - accuracy: 0.9564\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.1001 - accuracy: 0.9701\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1085 - accuracy: 0.9543\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0795 - accuracy: 0.9751\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0796 - accuracy: 0.9738\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0740 - accuracy: 0.9762\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0623 - accuracy: 0.9815\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0822 - accuracy: 0.9696\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0715 - accuracy: 0.9782\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0781 - accuracy: 0.9683\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0643 - accuracy: 0.9721\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0477 - accuracy: 0.9880\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0610 - accuracy: 0.9728\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0604 - accuracy: 0.9791\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0432 - accuracy: 0.9848\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0490 - accuracy: 0.9761\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0459 - accuracy: 0.9827\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0406 - accuracy: 0.9843\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0360 - accuracy: 0.9866\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0358 - accuracy: 0.9922\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0486 - accuracy: 0.9843\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0300 - accuracy: 0.9947\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0340 - accuracy: 0.9889\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0293 - accuracy: 0.9892\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0259 - accuracy: 0.9942\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0521 - accuracy: 0.9798\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0400 - accuracy: 0.9864\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0340 - accuracy: 0.9864\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0400 - accuracy: 0.9868\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0220 - accuracy: 0.9882\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0282 - accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0295 - accuracy: 0.9869\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0317 - accuracy: 0.9892\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0366 - accuracy: 0.9866\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0367 - accuracy: 0.9877\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0321 - accuracy: 0.9816\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0357 - accuracy: 0.9906\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0263 - accuracy: 0.9937\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 9.1357 - accuracy: 0.2869\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.9152 - accuracy: 0.6301\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.4260 - accuracy: 0.8323\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.3382 - accuracy: 0.8583\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.3008 - accuracy: 0.8865\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2844 - accuracy: 0.8926\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2363 - accuracy: 0.9121\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.2144 - accuracy: 0.9207\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1862 - accuracy: 0.9162\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1630 - accuracy: 0.9364\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1587 - accuracy: 0.9410\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1426 - accuracy: 0.9503\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1318 - accuracy: 0.9554\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1413 - accuracy: 0.9403\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1268 - accuracy: 0.9521\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.1163 - accuracy: 0.9560\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1083 - accuracy: 0.9574\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0824 - accuracy: 0.9718\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1052 - accuracy: 0.9671\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0930 - accuracy: 0.9622\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0782 - accuracy: 0.9691\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0602 - accuracy: 0.9769\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0833 - accuracy: 0.9674\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0531 - accuracy: 0.9853\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0859 - accuracy: 0.9649\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0530 - accuracy: 0.9861\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0545 - accuracy: 0.9851\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0589 - accuracy: 0.9772\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0891 - accuracy: 0.9720\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0504 - accuracy: 0.9869\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0369 - accuracy: 0.9888\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0380 - accuracy: 0.9877\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0413 - accuracy: 0.9802\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0314 - accuracy: 0.9869\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0300 - accuracy: 0.9894\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0385 - accuracy: 0.9860\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0281 - accuracy: 0.9885\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0241 - accuracy: 0.9944\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0477 - accuracy: 0.9842\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0240 - accuracy: 0.9932\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0308 - accuracy: 0.9840\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0244 - accuracy: 0.9906\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0375 - accuracy: 0.9841\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0353 - accuracy: 0.9859\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0202 - accuracy: 0.9940\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0299 - accuracy: 0.9856\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0334 - accuracy: 0.9860\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0330 - accuracy: 0.9830\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0241 - accuracy: 0.9906\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0225 - accuracy: 0.9917\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0277 - accuracy: 0.9890\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6622 - accuracy: 0.8840\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 1.3894 - accuracy: 0.5447\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.5614 - accuracy: 0.7554\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.4226 - accuracy: 0.8313\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.3643 - accuracy: 0.8646\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.3646 - accuracy: 0.8511\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2929 - accuracy: 0.8848\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.3097 - accuracy: 0.8649\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2624 - accuracy: 0.8936\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2531 - accuracy: 0.8944\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2470 - accuracy: 0.9059\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.2193 - accuracy: 0.9014\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1876 - accuracy: 0.9321\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1882 - accuracy: 0.9337\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1621 - accuracy: 0.9390\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1716 - accuracy: 0.9352\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1595 - accuracy: 0.9334\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.1460 - accuracy: 0.9419\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1379 - accuracy: 0.9591\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1379 - accuracy: 0.9428\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1260 - accuracy: 0.9417\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1483 - accuracy: 0.9422\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.1196 - accuracy: 0.9506\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1035 - accuracy: 0.9545\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1064 - accuracy: 0.9513\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1048 - accuracy: 0.9588\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1165 - accuracy: 0.9549\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0930 - accuracy: 0.9647\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0793 - accuracy: 0.9746\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0776 - accuracy: 0.9630\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0622 - accuracy: 0.9772\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0807 - accuracy: 0.9670\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0645 - accuracy: 0.9715\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0580 - accuracy: 0.9739\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0759 - accuracy: 0.9669\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0666 - accuracy: 0.9686\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0664 - accuracy: 0.9787\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0604 - accuracy: 0.9737\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0935 - accuracy: 0.9753\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0660 - accuracy: 0.9725\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0650 - accuracy: 0.9737\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0611 - accuracy: 0.9752\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0547 - accuracy: 0.9736\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0564 - accuracy: 0.9807\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0513 - accuracy: 0.9857\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0511 - accuracy: 0.9788\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0388 - accuracy: 0.9903\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0552 - accuracy: 0.9748\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0412 - accuracy: 0.9796\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0414 - accuracy: 0.9818\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0698 - accuracy: 0.9708\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.1789 - accuracy: 0.9480\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 1.3638 - accuracy: 0.5539\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.4520 - accuracy: 0.8128\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.3331 - accuracy: 0.8714\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2497 - accuracy: 0.9056\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2190 - accuracy: 0.9145\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.1922 - accuracy: 0.9408\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.1870 - accuracy: 0.9346\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.1490 - accuracy: 0.9475\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1720 - accuracy: 0.9396\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.1467 - accuracy: 0.9460\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1298 - accuracy: 0.9534\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1138 - accuracy: 0.9610\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1142 - accuracy: 0.9605\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0983 - accuracy: 0.9638\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0876 - accuracy: 0.9728\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0884 - accuracy: 0.9677\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0743 - accuracy: 0.9736\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0638 - accuracy: 0.9757\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0630 - accuracy: 0.9733\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0523 - accuracy: 0.9800\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0512 - accuracy: 0.9839\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0550 - accuracy: 0.9818\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0597 - accuracy: 0.9818\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0400 - accuracy: 0.9842\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0349 - accuracy: 0.9904\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0424 - accuracy: 0.9818\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0326 - accuracy: 0.9896\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0443 - accuracy: 0.9841\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0450 - accuracy: 0.9788\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0345 - accuracy: 0.9891\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0396 - accuracy: 0.9860\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0265 - accuracy: 0.9912\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0248 - accuracy: 0.9920\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0205 - accuracy: 0.9935\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0270 - accuracy: 0.9936\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0344 - accuracy: 0.9855\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0270 - accuracy: 0.9926\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0163 - accuracy: 0.9979\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0248 - accuracy: 0.9877\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0346 - accuracy: 0.9824\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0250 - accuracy: 0.9955\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0240 - accuracy: 0.9892\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0286 - accuracy: 0.9820\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0164 - accuracy: 0.9954\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0147 - accuracy: 0.9950\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0296 - accuracy: 0.9882\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0176 - accuracy: 0.9933\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0162 - accuracy: 0.9937\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0197 - accuracy: 0.9902\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0158 - accuracy: 0.9935\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 3.3607 - accuracy: 0.6480\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 1.5411 - accuracy: 0.5358\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.5904 - accuracy: 0.6906\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.4768 - accuracy: 0.7748\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.4069 - accuracy: 0.8370\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.3545 - accuracy: 0.8356\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.3109 - accuracy: 0.8754\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.3242 - accuracy: 0.8699\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2776 - accuracy: 0.8836\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.2824 - accuracy: 0.8730\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2725 - accuracy: 0.8749\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.2533 - accuracy: 0.8947\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2366 - accuracy: 0.8967\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2453 - accuracy: 0.8993\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1943 - accuracy: 0.9192\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1845 - accuracy: 0.9249\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1960 - accuracy: 0.9082\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1870 - accuracy: 0.9175\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1668 - accuracy: 0.9244\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1499 - accuracy: 0.9335\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1338 - accuracy: 0.9413\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1420 - accuracy: 0.9374\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1332 - accuracy: 0.9408\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1423 - accuracy: 0.9369\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1381 - accuracy: 0.9372\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1345 - accuracy: 0.9368\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1201 - accuracy: 0.9427\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1199 - accuracy: 0.9426\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1227 - accuracy: 0.9443\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1038 - accuracy: 0.9522\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1190 - accuracy: 0.9518\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1323 - accuracy: 0.9401\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1297 - accuracy: 0.9452\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0926 - accuracy: 0.9519\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0947 - accuracy: 0.9645\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0743 - accuracy: 0.9660\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0945 - accuracy: 0.9515\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0976 - accuracy: 0.9518\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1036 - accuracy: 0.9590\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1252 - accuracy: 0.9492\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0787 - accuracy: 0.9615\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0829 - accuracy: 0.9538\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0748 - accuracy: 0.9696\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0892 - accuracy: 0.9645\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0935 - accuracy: 0.9597\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0750 - accuracy: 0.9662\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0841 - accuracy: 0.9668\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0788 - accuracy: 0.9656\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0708 - accuracy: 0.9642\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0586 - accuracy: 0.9813\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0522 - accuracy: 0.9777\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.3463 - accuracy: 0.8760\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 1.5316 - accuracy: 0.5588\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.5862 - accuracy: 0.7097\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.4129 - accuracy: 0.8496\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.3252 - accuracy: 0.8870\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.2695 - accuracy: 0.9076\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.2675 - accuracy: 0.9106\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1869 - accuracy: 0.9258\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1746 - accuracy: 0.9310\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2146 - accuracy: 0.9310\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1315 - accuracy: 0.9533\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1588 - accuracy: 0.9390\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0980 - accuracy: 0.9671\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1033 - accuracy: 0.9555\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1261 - accuracy: 0.9477\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0814 - accuracy: 0.9659\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0822 - accuracy: 0.9702\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0981 - accuracy: 0.9611\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0819 - accuracy: 0.9748\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0553 - accuracy: 0.9859\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0639 - accuracy: 0.9792\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0588 - accuracy: 0.9823\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0579 - accuracy: 0.9757\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0450 - accuracy: 0.9781\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0679 - accuracy: 0.9787\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0437 - accuracy: 0.9877\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0397 - accuracy: 0.9896\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0500 - accuracy: 0.9782\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0661 - accuracy: 0.9767\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0398 - accuracy: 0.9839\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0305 - accuracy: 0.9896\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0471 - accuracy: 0.9839\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0274 - accuracy: 0.9897\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0285 - accuracy: 0.9897\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0306 - accuracy: 0.9877\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0307 - accuracy: 0.9890\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0292 - accuracy: 0.9884\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0404 - accuracy: 0.9820\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0351 - accuracy: 0.9889\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0320 - accuracy: 0.9890\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0374 - accuracy: 0.9879\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0305 - accuracy: 0.9854\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0354 - accuracy: 0.9846\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0252 - accuracy: 0.9854\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0231 - accuracy: 0.9943\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0139 - accuracy: 0.9943\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0199 - accuracy: 0.9938\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0267 - accuracy: 0.9903\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0219 - accuracy: 0.9921\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0341 - accuracy: 0.9890\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0300 - accuracy: 0.9867\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0203 - accuracy: 0.9950\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0410 - accuracy: 0.9786\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0334 - accuracy: 0.9868\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0274 - accuracy: 0.9899\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0221 - accuracy: 0.9918\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0232 - accuracy: 0.9867\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0320 - accuracy: 0.9858\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0212 - accuracy: 0.9914\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0240 - accuracy: 0.9884\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0112 - accuracy: 0.9937\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0239 - accuracy: 0.9901\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0194 - accuracy: 0.9898\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0215 - accuracy: 0.9894\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0308 - accuracy: 0.9820\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0193 - accuracy: 0.9951\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0189 - accuracy: 0.9898\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0244 - accuracy: 0.9888\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0246 - accuracy: 0.9911\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0336 - accuracy: 0.9870\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0268 - accuracy: 0.9860\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0204 - accuracy: 0.9957\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0207 - accuracy: 0.9876\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0142 - accuracy: 0.9921\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0171 - accuracy: 0.9917\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0239 - accuracy: 0.9924\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0215 - accuracy: 0.9872\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0161 - accuracy: 0.9947\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0128 - accuracy: 0.9969\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0130 - accuracy: 0.9930\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0181 - accuracy: 0.9907\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.0210 - accuracy: 0.9895\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0150 - accuracy: 0.9944\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0113 - accuracy: 0.9962\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0113 - accuracy: 0.9957\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0098 - accuracy: 0.9957\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0107 - accuracy: 0.9957\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0106 - accuracy: 0.9951\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0134 - accuracy: 0.9918\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0091 - accuracy: 0.9959\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0146 - accuracy: 0.9916\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0128 - accuracy: 0.9962\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0138 - accuracy: 0.9938\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0225 - accuracy: 0.9949\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0151 - accuracy: 0.9957\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0141 - accuracy: 0.9936\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0146 - accuracy: 0.9888\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0154 - accuracy: 0.9915\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0188 - accuracy: 0.9920\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0194 - accuracy: 0.9931\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0144 - accuracy: 0.9946\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 9.2223 - accuracy: 0.3865\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 1.0549 - accuracy: 0.5998\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.5106 - accuracy: 0.7675\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.3400 - accuracy: 0.8740\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2830 - accuracy: 0.8982\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2781 - accuracy: 0.8998\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.2236 - accuracy: 0.9120\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2088 - accuracy: 0.9104\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2066 - accuracy: 0.9235\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1771 - accuracy: 0.9426\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.1697 - accuracy: 0.9383\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.1415 - accuracy: 0.9356\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1396 - accuracy: 0.9508\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1278 - accuracy: 0.9534\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1284 - accuracy: 0.9503\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1204 - accuracy: 0.9582\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1115 - accuracy: 0.9657\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0926 - accuracy: 0.9686\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0888 - accuracy: 0.9686\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0802 - accuracy: 0.9734\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0937 - accuracy: 0.9553\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0754 - accuracy: 0.9763\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0760 - accuracy: 0.9754\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0678 - accuracy: 0.9770\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0613 - accuracy: 0.9776\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0575 - accuracy: 0.9798\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0600 - accuracy: 0.9736\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0688 - accuracy: 0.9722\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0487 - accuracy: 0.9834\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0558 - accuracy: 0.9795\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0530 - accuracy: 0.9823\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0522 - accuracy: 0.9753\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0717 - accuracy: 0.9649\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0391 - accuracy: 0.9944\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0594 - accuracy: 0.9706\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0606 - accuracy: 0.9708\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0358 - accuracy: 0.9845\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0458 - accuracy: 0.9829\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0321 - accuracy: 0.9881\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0369 - accuracy: 0.9822\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0303 - accuracy: 0.9864\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0256 - accuracy: 0.9899\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0293 - accuracy: 0.9893\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0310 - accuracy: 0.9871\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0309 - accuracy: 0.9892\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0340 - accuracy: 0.9845\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0514 - accuracy: 0.9849\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0607 - accuracy: 0.9801\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0326 - accuracy: 0.9871\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0246 - accuracy: 0.9892\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0319 - accuracy: 0.9905\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0291 - accuracy: 0.9832\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0198 - accuracy: 0.9951\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0239 - accuracy: 0.9945\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0235 - accuracy: 0.9879\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0213 - accuracy: 0.9951\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0174 - accuracy: 0.9915\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0197 - accuracy: 0.9910\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0207 - accuracy: 0.9915\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0146 - accuracy: 0.9981\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0129 - accuracy: 0.9958\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0142 - accuracy: 0.9956\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0173 - accuracy: 0.9903\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0308 - accuracy: 0.9881\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0205 - accuracy: 0.9923\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0233 - accuracy: 0.9917\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0198 - accuracy: 0.9898\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0220 - accuracy: 0.9938\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0153 - accuracy: 0.9941\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0133 - accuracy: 0.9976\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0166 - accuracy: 0.9929\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0133 - accuracy: 0.9964\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0182 - accuracy: 0.9916\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0114 - accuracy: 0.9970\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0204 - accuracy: 0.9913\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0122 - accuracy: 0.9958\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0251 - accuracy: 0.9879\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0116 - accuracy: 0.9946\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0302 - accuracy: 0.9932\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0241 - accuracy: 0.9943\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0148 - accuracy: 0.9912\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0147 - accuracy: 0.9939\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0167 - accuracy: 0.9923\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0259 - accuracy: 0.9859\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0155 - accuracy: 0.9912\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0162 - accuracy: 0.9922\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0183 - accuracy: 0.9896\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0137 - accuracy: 0.9967\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0090 - accuracy: 0.9963\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0164 - accuracy: 0.9920\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0185 - accuracy: 0.9929\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0066 - accuracy: 0.9996\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0067 - accuracy: 0.9967\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0071 - accuracy: 0.9975\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0079 - accuracy: 0.9965\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0129 - accuracy: 0.9918\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0221 - accuracy: 0.9899\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0317 - accuracy: 0.9884\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0153 - accuracy: 0.9946\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0064 - accuracy: 0.9979\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0165 - accuracy: 0.9925\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.6454 - accuracy: 0.9200\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 1.0551 - accuracy: 0.5199\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.6222 - accuracy: 0.6836\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.4516 - accuracy: 0.7964\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.4145 - accuracy: 0.8487\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.3388 - accuracy: 0.8647\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.3099 - accuracy: 0.8797\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2498 - accuracy: 0.9037\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2379 - accuracy: 0.9114\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2048 - accuracy: 0.9180\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2135 - accuracy: 0.9017\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1889 - accuracy: 0.9227\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1464 - accuracy: 0.9573\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1556 - accuracy: 0.9430\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1694 - accuracy: 0.9380\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1612 - accuracy: 0.9351\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1514 - accuracy: 0.9337\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1426 - accuracy: 0.9455\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0973 - accuracy: 0.9664\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1391 - accuracy: 0.9387\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0995 - accuracy: 0.9676\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1066 - accuracy: 0.9602\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0884 - accuracy: 0.9651\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0988 - accuracy: 0.9546\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0898 - accuracy: 0.9632\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1007 - accuracy: 0.9604\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0826 - accuracy: 0.9637\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1004 - accuracy: 0.9596\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0735 - accuracy: 0.9745\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0745 - accuracy: 0.9700\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0629 - accuracy: 0.9787\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0584 - accuracy: 0.9735\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0538 - accuracy: 0.9774\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0499 - accuracy: 0.9769\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0646 - accuracy: 0.9713\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0720 - accuracy: 0.9749\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0564 - accuracy: 0.9795\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0737 - accuracy: 0.9749\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0571 - accuracy: 0.9721\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0492 - accuracy: 0.9830\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0319 - accuracy: 0.9868\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0540 - accuracy: 0.9754\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0431 - accuracy: 0.9829\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0467 - accuracy: 0.9819\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0510 - accuracy: 0.9849\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0619 - accuracy: 0.9743\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0651 - accuracy: 0.9705\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0569 - accuracy: 0.9767\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0435 - accuracy: 0.9783\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0405 - accuracy: 0.9860\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0496 - accuracy: 0.9828\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0686 - accuracy: 0.9815\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0720 - accuracy: 0.9721\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0481 - accuracy: 0.9788\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0266 - accuracy: 0.9931\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0308 - accuracy: 0.9881\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0481 - accuracy: 0.9764\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0254 - accuracy: 0.9870\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0435 - accuracy: 0.9828\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0474 - accuracy: 0.9817\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0367 - accuracy: 0.9839\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0374 - accuracy: 0.9874\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0345 - accuracy: 0.9846\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0339 - accuracy: 0.9863\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0251 - accuracy: 0.9909\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0239 - accuracy: 0.9907\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0412 - accuracy: 0.9787\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0226 - accuracy: 0.9915\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0293 - accuracy: 0.9895\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0364 - accuracy: 0.9781\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0237 - accuracy: 0.9902\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0388 - accuracy: 0.9837\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0233 - accuracy: 0.9884\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0250 - accuracy: 0.9892\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0220 - accuracy: 0.9909\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0298 - accuracy: 0.9889\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0245 - accuracy: 0.9860\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0190 - accuracy: 0.9927\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0210 - accuracy: 0.9897\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0242 - accuracy: 0.9887\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0201 - accuracy: 0.9933\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0237 - accuracy: 0.9932\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0253 - accuracy: 0.9873\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0173 - accuracy: 0.9968\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0170 - accuracy: 0.9919\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0248 - accuracy: 0.9934\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0334 - accuracy: 0.9864\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0252 - accuracy: 0.9909\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0209 - accuracy: 0.9945\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0266 - accuracy: 0.9935\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0204 - accuracy: 0.9924\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0164 - accuracy: 0.9927\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0235 - accuracy: 0.9933\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0231 - accuracy: 0.9914\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0150 - accuracy: 0.9960\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0377 - accuracy: 0.9790\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0341 - accuracy: 0.9822\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0326 - accuracy: 0.9877\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0252 - accuracy: 0.9970\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0128 - accuracy: 0.9973\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0243 - accuracy: 0.9909\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.1343 - accuracy: 0.9680\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 1.0563 - accuracy: 0.5565\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.4513 - accuracy: 0.8215\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.3562 - accuracy: 0.8576\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2401 - accuracy: 0.9191\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.2145 - accuracy: 0.9302\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.1956 - accuracy: 0.9197\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1745 - accuracy: 0.9321\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1543 - accuracy: 0.9434\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.1477 - accuracy: 0.9455\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1406 - accuracy: 0.9487\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0997 - accuracy: 0.9611\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0970 - accuracy: 0.9636\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0869 - accuracy: 0.9754\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0964 - accuracy: 0.9657\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0796 - accuracy: 0.9703\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0805 - accuracy: 0.9743\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0846 - accuracy: 0.9656\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0629 - accuracy: 0.9792\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0579 - accuracy: 0.9814\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0599 - accuracy: 0.9781\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0667 - accuracy: 0.9761\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0493 - accuracy: 0.9808\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0435 - accuracy: 0.9843\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0566 - accuracy: 0.9771\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0776 - accuracy: 0.9771\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0545 - accuracy: 0.9762\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0436 - accuracy: 0.9862\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0500 - accuracy: 0.9768\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.0357 - accuracy: 0.9858\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0308 - accuracy: 0.9921\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0381 - accuracy: 0.9885\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0306 - accuracy: 0.9900\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0321 - accuracy: 0.9889\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0341 - accuracy: 0.9870\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0389 - accuracy: 0.9835\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0282 - accuracy: 0.9914\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0270 - accuracy: 0.9884\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0192 - accuracy: 0.9948\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0280 - accuracy: 0.9894\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0320 - accuracy: 0.9864\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0328 - accuracy: 0.9867\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0277 - accuracy: 0.9873\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0279 - accuracy: 0.9920\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0153 - accuracy: 0.9947\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0290 - accuracy: 0.9882\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0147 - accuracy: 0.9943\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0324 - accuracy: 0.9897\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0178 - accuracy: 0.9930\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0168 - accuracy: 0.9963\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0271 - accuracy: 0.9919\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0304 - accuracy: 0.9891\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0225 - accuracy: 0.9931\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0210 - accuracy: 0.9910\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0498 - accuracy: 0.9920\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0148 - accuracy: 0.9946\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0278 - accuracy: 0.9923\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0278 - accuracy: 0.9883\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0162 - accuracy: 0.9957\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0229 - accuracy: 0.9882\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0193 - accuracy: 0.9920\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0195 - accuracy: 0.9925\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0198 - accuracy: 0.9946\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0167 - accuracy: 0.9930\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0217 - accuracy: 0.9891\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0116 - accuracy: 0.9953\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0171 - accuracy: 0.9884\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0135 - accuracy: 0.9914\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0063 - accuracy: 0.9999\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0129 - accuracy: 0.9923\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0209 - accuracy: 0.9913\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0247 - accuracy: 0.9906\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0145 - accuracy: 0.9935\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0252 - accuracy: 0.9863\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0134 - accuracy: 0.9955\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0133 - accuracy: 0.9939\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0061 - accuracy: 0.9994\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0126 - accuracy: 0.9964\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0145 - accuracy: 0.9911\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0243 - accuracy: 0.9914\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0179 - accuracy: 0.9974\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0237 - accuracy: 0.9891\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0089 - accuracy: 0.9982\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0157 - accuracy: 0.9945\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0228 - accuracy: 0.9932\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0349 - accuracy: 0.9931\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0209 - accuracy: 0.9951\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0241 - accuracy: 0.9910\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0134 - accuracy: 0.9933\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0081 - accuracy: 0.9979\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0194 - accuracy: 0.9939\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0040 - accuracy: 0.9996\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0094 - accuracy: 0.9990\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0292 - accuracy: 0.9927\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0091 - accuracy: 0.9973\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0123 - accuracy: 0.9980\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0236 - accuracy: 0.9925\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0186 - accuracy: 0.9916\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0086 - accuracy: 0.9960\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0080 - accuracy: 0.9982\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0036 - accuracy: 0.9980\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 3.6579 - accuracy: 0.7040\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 1.1684 - accuracy: 0.5432\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.5857 - accuracy: 0.6750\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.4969 - accuracy: 0.7702\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.4354 - accuracy: 0.7807\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.3880 - accuracy: 0.8198\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.3290 - accuracy: 0.8744\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.3190 - accuracy: 0.8564\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.2742 - accuracy: 0.8932\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2625 - accuracy: 0.8941\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2878 - accuracy: 0.8872\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.2524 - accuracy: 0.9113\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.2184 - accuracy: 0.9098\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2126 - accuracy: 0.9123\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1885 - accuracy: 0.9312\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1642 - accuracy: 0.9335\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1701 - accuracy: 0.9312\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1557 - accuracy: 0.9383\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1360 - accuracy: 0.9430\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1300 - accuracy: 0.9406\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1344 - accuracy: 0.9498\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1303 - accuracy: 0.9472\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1234 - accuracy: 0.9566\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1113 - accuracy: 0.9601\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1068 - accuracy: 0.9611\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.1230 - accuracy: 0.9567\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1066 - accuracy: 0.9614\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.1038 - accuracy: 0.9597\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1076 - accuracy: 0.9555\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0890 - accuracy: 0.9680\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0955 - accuracy: 0.9674\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0833 - accuracy: 0.9687\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0914 - accuracy: 0.9694\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0781 - accuracy: 0.9655\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0691 - accuracy: 0.9713\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0626 - accuracy: 0.9763\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0690 - accuracy: 0.9687\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0475 - accuracy: 0.9881\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0572 - accuracy: 0.9792\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0606 - accuracy: 0.9834\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0580 - accuracy: 0.9820\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0505 - accuracy: 0.9795\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0440 - accuracy: 0.9837\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0533 - accuracy: 0.9810\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0459 - accuracy: 0.9791\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0470 - accuracy: 0.9846\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0454 - accuracy: 0.9790\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0449 - accuracy: 0.9866\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0453 - accuracy: 0.9830\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0341 - accuracy: 0.9882\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0380 - accuracy: 0.9861\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0442 - accuracy: 0.9834\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0426 - accuracy: 0.9822\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0520 - accuracy: 0.9784\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0828 - accuracy: 0.9736\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0564 - accuracy: 0.9782\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0501 - accuracy: 0.9801\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0547 - accuracy: 0.9795\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0305 - accuracy: 0.9857\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0463 - accuracy: 0.9802\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0294 - accuracy: 0.9911\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0485 - accuracy: 0.9854\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0547 - accuracy: 0.9795\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0331 - accuracy: 0.9888\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0382 - accuracy: 0.9833\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0373 - accuracy: 0.9791\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0362 - accuracy: 0.9863\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0346 - accuracy: 0.9799\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0443 - accuracy: 0.9865\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0413 - accuracy: 0.9892\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0363 - accuracy: 0.9839\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0317 - accuracy: 0.9899\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.0387 - accuracy: 0.9754\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0311 - accuracy: 0.9867\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0347 - accuracy: 0.9846\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0259 - accuracy: 0.9862\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0238 - accuracy: 0.9933\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0326 - accuracy: 0.9851\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0231 - accuracy: 0.9927\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0382 - accuracy: 0.9863\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0513 - accuracy: 0.9821\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0706 - accuracy: 0.9751\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0556 - accuracy: 0.9779\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.1112 - accuracy: 0.9595\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0662 - accuracy: 0.9762\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0423 - accuracy: 0.9855\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0429 - accuracy: 0.9821\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0302 - accuracy: 0.9925\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0360 - accuracy: 0.9840\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0291 - accuracy: 0.9845\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0254 - accuracy: 0.9894\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0346 - accuracy: 0.9897\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0313 - accuracy: 0.9885\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0410 - accuracy: 0.9850\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0335 - accuracy: 0.9869\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.0322 - accuracy: 0.9921\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0455 - accuracy: 0.9807\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.0274 - accuracy: 0.9889\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.0305 - accuracy: 0.9888\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0239 - accuracy: 0.9855\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0206 - accuracy: 0.9894\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.4821 - accuracy: 0.9000\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.9117 - accuracy: 0.5436\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 2s 118ms/step - loss: 0.5350 - accuracy: 0.7512\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 2s 116ms/step - loss: 0.4002 - accuracy: 0.8442\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 2s 116ms/step - loss: 0.3490 - accuracy: 0.8582\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 2s 120ms/step - loss: 0.2661 - accuracy: 0.8950\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 2s 118ms/step - loss: 0.2651 - accuracy: 0.9029\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 2s 119ms/step - loss: 0.2045 - accuracy: 0.9244\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 2s 118ms/step - loss: 0.2322 - accuracy: 0.9064\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 2s 118ms/step - loss: 0.1973 - accuracy: 0.9125\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 2s 118ms/step - loss: 0.2059 - accuracy: 0.9235\n",
            "Best: 0.786747 using {'batch_size': 64, 'epochs': 10}\n",
            "0.760484 (0.198013) with: {'batch_size': 16, 'epochs': 10}\n",
            "0.726282 (0.301515) with: {'batch_size': 16, 'epochs': 30}\n",
            "0.731860 (0.294128) with: {'batch_size': 16, 'epochs': 50}\n",
            "0.747780 (0.254740) with: {'batch_size': 16, 'epochs': 100}\n",
            "0.772424 (0.179294) with: {'batch_size': 32, 'epochs': 10}\n",
            "0.731761 (0.246048) with: {'batch_size': 32, 'epochs': 30}\n",
            "0.706974 (0.236621) with: {'batch_size': 32, 'epochs': 50}\n",
            "0.738967 (0.252741) with: {'batch_size': 32, 'epochs': 100}\n",
            "0.786747 (0.165863) with: {'batch_size': 64, 'epochs': 10}\n",
            "0.750884 (0.205936) with: {'batch_size': 64, 'epochs': 30}\n",
            "0.728571 (0.243166) with: {'batch_size': 64, 'epochs': 50}\n",
            "0.775691 (0.214432) with: {'batch_size': 64, 'epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDaAXNfcRwGu",
        "outputId": "05de705e-f12d-4b31-ee01-fd9b1b505191"
      },
      "source": [
        "grid_result"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8a529e4b90>,\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'batch_size': [16, 32, 64],\n",
              "                         'epochs': [10, 30, 50, 100]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hMpCEBwStCJ"
      },
      "source": [
        "Con el keras clasifier no se obtiene un resultado muy bueno, se esperaba mejor resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4et_9J8TQWU"
      },
      "source": [
        "**Observación:**\n",
        "Los mejores resultados se han obtenido con las redes convolucionales, pero idenificamos que los modelos que hemos utilizado, les agregamos una función de activación llamada 'softmax' y compilamos con 'categorical_crossentropy', dado que nuestro problema es de solución binaria, tapabocas bien y mal puesto (0,1) hemos encontrado que podemos usar un modelo más óptimo a nuestras necesidades, utilizando una función de activación 'sigmoid' y compilando con 'binary_crossentropy'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK6mmpfuCC3U"
      },
      "source": [
        "def model_cnn_binary():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (5, 5), input_shape=(224, 224,3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.7)) ## desconectamos el 70% de los nodos\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2raTypteVXbI"
      },
      "source": [
        "Con el modelo anterior podremos usar las funciones descritas anteriormente, adicional mantenemos el dropout del 0.7 ya que mostró mejores resultados anteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFdaUDvCVkOY"
      },
      "source": [
        "**Posible inconventiente**\n",
        "Este modelo, a diferencia del anterior, solo tendrá un nodo de salida, así que nuestros labels deberán ser codificados solo a (0,1) y no a (1,0 0,1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nku_UPFOLxnh"
      },
      "source": [
        "## nuevas variables para hacer la nueva codificación\n",
        "y_test_binario = y_test_multi_channel\n",
        "y_train_binario =y_train_multi_channel\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train_binario)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train_binario)\n",
        "y_train_binario = encoder.transform(y_train_binario)\n",
        "y_test_binario = encoder.transform(y_test_binario)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vqhrcdOMzUH"
      },
      "source": [
        "y_test_binario, y_test_cn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyDPUwlQJ2T1",
        "outputId": "f00ca9a7-7390-48d6-9ac0-f08ebfca9fe1"
      },
      "source": [
        "## Construimos el modelo descrito anteriormente, usaremos los mismos datos para X pero para y los obtenidos en el código anterior\n",
        "model_binary = model_cnn_binary()\n",
        "# Entrenar\n",
        "model_binary.fit(X_train_cn, y_train_binario, validation_data=(X_test_cn, y_test_binario), epochs=50, batch_size=32)\n",
        "# Evaluación\n",
        "scores = model_binary.evaluate(X_test_cn, y_test_binario, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 5s 109ms/step - loss: 16.1198 - accuracy: 0.6318 - val_loss: 0.5333 - val_accuracy: 0.8112\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.4516 - accuracy: 0.8408 - val_loss: 0.4035 - val_accuracy: 0.8673\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.7940 - accuracy: 0.8200 - val_loss: 1.0100 - val_accuracy: 0.7375\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.4837 - accuracy: 0.8559 - val_loss: 0.2926 - val_accuracy: 0.8968\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.5490 - accuracy: 0.8764 - val_loss: 0.3042 - val_accuracy: 0.9027\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.2805 - accuracy: 0.8984 - val_loss: 0.3168 - val_accuracy: 0.8938\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2984 - accuracy: 0.8961 - val_loss: 3.0187 - val_accuracy: 0.7257\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.5908 - accuracy: 0.8795 - val_loss: 0.6615 - val_accuracy: 0.8260\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.4848 - accuracy: 0.8878 - val_loss: 0.3535 - val_accuracy: 0.8879\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3353 - accuracy: 0.8863 - val_loss: 0.3304 - val_accuracy: 0.8938\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2730 - accuracy: 0.9147 - val_loss: 0.3050 - val_accuracy: 0.9115\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3653 - accuracy: 0.9005 - val_loss: 0.3327 - val_accuracy: 0.9204\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.4918 - accuracy: 0.9063 - val_loss: 0.4165 - val_accuracy: 0.8997\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.7479 - accuracy: 0.8757 - val_loss: 0.3580 - val_accuracy: 0.9115\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2929 - accuracy: 0.9207 - val_loss: 0.3007 - val_accuracy: 0.9145\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2358 - accuracy: 0.9401 - val_loss: 0.6156 - val_accuracy: 0.8171\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2471 - accuracy: 0.9310 - val_loss: 0.2774 - val_accuracy: 0.9263\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1586 - accuracy: 0.9481 - val_loss: 0.3758 - val_accuracy: 0.9027\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.4085 - accuracy: 0.9389 - val_loss: 0.3656 - val_accuracy: 0.9145\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.3223 - accuracy: 0.9261 - val_loss: 0.4290 - val_accuracy: 0.9233\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1424 - accuracy: 0.9570 - val_loss: 0.3611 - val_accuracy: 0.9233\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.2354 - accuracy: 0.9368 - val_loss: 0.3698 - val_accuracy: 0.9174\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.3599 - accuracy: 0.9292 - val_loss: 1.0477 - val_accuracy: 0.8555\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3331 - accuracy: 0.9337 - val_loss: 0.4320 - val_accuracy: 0.8909\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2009 - accuracy: 0.9510 - val_loss: 0.3403 - val_accuracy: 0.9233\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1623 - accuracy: 0.9514 - val_loss: 0.3048 - val_accuracy: 0.9263\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1928 - accuracy: 0.9392 - val_loss: 0.7132 - val_accuracy: 0.8319\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1869 - accuracy: 0.9400 - val_loss: 0.4536 - val_accuracy: 0.9145\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.2058 - accuracy: 0.9592 - val_loss: 0.3845 - val_accuracy: 0.9145\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1929 - accuracy: 0.9529 - val_loss: 1.1514 - val_accuracy: 0.8850\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.6937 - accuracy: 0.9339 - val_loss: 0.3629 - val_accuracy: 0.9233\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.0861 - accuracy: 0.9746 - val_loss: 0.4400 - val_accuracy: 0.9292\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.1083 - accuracy: 0.9733 - val_loss: 0.4367 - val_accuracy: 0.9292\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.1093 - accuracy: 0.9732 - val_loss: 0.5346 - val_accuracy: 0.9174\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1341 - accuracy: 0.9576 - val_loss: 0.4653 - val_accuracy: 0.9086\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.1030 - accuracy: 0.9674 - val_loss: 0.6092 - val_accuracy: 0.9322\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.1170 - accuracy: 0.9749 - val_loss: 0.5500 - val_accuracy: 0.9263\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.2633 - accuracy: 0.9453 - val_loss: 0.5693 - val_accuracy: 0.9174\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.0775 - accuracy: 0.9742 - val_loss: 0.5582 - val_accuracy: 0.9115\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.1041 - accuracy: 0.9664 - val_loss: 0.3896 - val_accuracy: 0.9204\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.0927 - accuracy: 0.9799 - val_loss: 0.5309 - val_accuracy: 0.9351\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.0995 - accuracy: 0.9644 - val_loss: 0.8644 - val_accuracy: 0.9027\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.2318 - accuracy: 0.9421 - val_loss: 0.3950 - val_accuracy: 0.9233\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.0940 - accuracy: 0.9796 - val_loss: 0.4481 - val_accuracy: 0.9145\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.1059 - accuracy: 0.9675 - val_loss: 1.5284 - val_accuracy: 0.9086\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.3027 - accuracy: 0.9505 - val_loss: 0.8345 - val_accuracy: 0.9292\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.1105 - accuracy: 0.9726 - val_loss: 0.5083 - val_accuracy: 0.9233\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.1379 - accuracy: 0.9672 - val_loss: 0.4032 - val_accuracy: 0.9351\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.0963 - accuracy: 0.9728 - val_loss: 0.6499 - val_accuracy: 0.9351\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1307 - accuracy: 0.9781 - val_loss: 0.4253 - val_accuracy: 0.9204\n",
            "Baseline Error: 7.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfwETcvLcH-6"
      },
      "source": [
        "En nuestro primer intento tenemos un accuracy de 92.04% y un error: 7.96%, ahora vamos a intentar tunnear un poco el modelo, agregando varias capas de filtros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaZ_HeqVORuC"
      },
      "source": [
        "def model_cnn_binary_tunn(t_filtro: 5):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (t_filtro, t_filtro), input_shape=(224, 224,3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (t_filtro, t_filtro), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (t_filtro, t_filtro), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.7))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drG0Zg_cOhdI",
        "outputId": "003bc97a-7518-420d-b44a-a99b2e3a2d1a"
      },
      "source": [
        "resultados = \"resultado: \\n\"\n",
        "for indice in range(1,6):\n",
        "  model = model_cnn_binary_tunn(indice)\n",
        "\n",
        "  model.fit(X_train_cn, y_train_binario, validation_data=(X_test_cn, y_test_binario), epochs=50, batch_size=32)\n",
        "  \n",
        "  scores = model.evaluate(X_test_cn, y_test_binario, verbose=0)\n",
        "  r = (\"Error: %.2f%%, Acc: %.2f%% usando filtros de %r \" % ((100-scores[1]*100), scores[1]*100, str(indice)+\" X \"+str(indice)))+\"\\n\"\n",
        "  print(r)\n",
        "  resultados += r\n",
        "print(resultados)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 4s 79ms/step - loss: 2.3329 - accuracy: 0.6100 - val_loss: 0.5287 - val_accuracy: 0.7935\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.4235 - accuracy: 0.8235 - val_loss: 0.4651 - val_accuracy: 0.8289\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.3335 - accuracy: 0.8748 - val_loss: 0.3753 - val_accuracy: 0.8407\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 3s 71ms/step - loss: 0.3248 - accuracy: 0.8621 - val_loss: 0.3812 - val_accuracy: 0.8437\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.2565 - accuracy: 0.9040 - val_loss: 0.3528 - val_accuracy: 0.8525\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.2324 - accuracy: 0.9118 - val_loss: 0.2753 - val_accuracy: 0.8820\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 71ms/step - loss: 0.1777 - accuracy: 0.9295 - val_loss: 0.2674 - val_accuracy: 0.9056\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.1882 - accuracy: 0.9265 - val_loss: 0.3188 - val_accuracy: 0.8702\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1777 - accuracy: 0.9226 - val_loss: 0.3088 - val_accuracy: 0.8850\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1821 - accuracy: 0.9304 - val_loss: 0.2296 - val_accuracy: 0.9115\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1827 - accuracy: 0.9288 - val_loss: 0.2331 - val_accuracy: 0.9233\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.1557 - accuracy: 0.9395 - val_loss: 0.2361 - val_accuracy: 0.9086\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.1310 - accuracy: 0.9483 - val_loss: 0.2604 - val_accuracy: 0.9322\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1266 - accuracy: 0.9560 - val_loss: 0.3138 - val_accuracy: 0.9145\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1350 - accuracy: 0.9544 - val_loss: 0.2388 - val_accuracy: 0.9233\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.1090 - accuracy: 0.9621 - val_loss: 0.1965 - val_accuracy: 0.9381\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0964 - accuracy: 0.9635 - val_loss: 0.2641 - val_accuracy: 0.9027\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0850 - accuracy: 0.9714 - val_loss: 0.2690 - val_accuracy: 0.9145\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0966 - accuracy: 0.9589 - val_loss: 0.2753 - val_accuracy: 0.9322\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0884 - accuracy: 0.9660 - val_loss: 0.2863 - val_accuracy: 0.9086\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1027 - accuracy: 0.9628 - val_loss: 0.2339 - val_accuracy: 0.9322\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0754 - accuracy: 0.9727 - val_loss: 0.2646 - val_accuracy: 0.9263\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0614 - accuracy: 0.9751 - val_loss: 0.2851 - val_accuracy: 0.9233\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0709 - accuracy: 0.9719 - val_loss: 0.2885 - val_accuracy: 0.9410\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.3733 - val_accuracy: 0.9056\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0728 - accuracy: 0.9696 - val_loss: 0.3608 - val_accuracy: 0.9351\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0948 - accuracy: 0.9608 - val_loss: 0.2631 - val_accuracy: 0.9440\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0529 - accuracy: 0.9757 - val_loss: 0.2321 - val_accuracy: 0.9528\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0632 - accuracy: 0.9704 - val_loss: 0.2406 - val_accuracy: 0.9499\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0579 - accuracy: 0.9754 - val_loss: 0.2490 - val_accuracy: 0.9381\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0520 - accuracy: 0.9746 - val_loss: 0.3269 - val_accuracy: 0.9499\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0652 - accuracy: 0.9771 - val_loss: 0.3208 - val_accuracy: 0.9381\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0635 - accuracy: 0.9798 - val_loss: 0.2448 - val_accuracy: 0.9499\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0410 - accuracy: 0.9853 - val_loss: 0.4432 - val_accuracy: 0.9469\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0429 - accuracy: 0.9821 - val_loss: 0.2510 - val_accuracy: 0.9469\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 71ms/step - loss: 0.0565 - accuracy: 0.9753 - val_loss: 0.2657 - val_accuracy: 0.9528\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0449 - accuracy: 0.9788 - val_loss: 0.3062 - val_accuracy: 0.9469\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0623 - accuracy: 0.9765 - val_loss: 0.2923 - val_accuracy: 0.9351\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0517 - accuracy: 0.9806 - val_loss: 0.3635 - val_accuracy: 0.9233\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0457 - accuracy: 0.9799 - val_loss: 0.3576 - val_accuracy: 0.9469\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0546 - accuracy: 0.9826 - val_loss: 0.3334 - val_accuracy: 0.9233\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0432 - accuracy: 0.9843 - val_loss: 0.2945 - val_accuracy: 0.9499\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0604 - accuracy: 0.9843 - val_loss: 0.2748 - val_accuracy: 0.9469\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 0.3808 - val_accuracy: 0.9440\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0502 - accuracy: 0.9796 - val_loss: 0.3526 - val_accuracy: 0.9499\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0444 - accuracy: 0.9828 - val_loss: 0.5490 - val_accuracy: 0.9145\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0558 - accuracy: 0.9758 - val_loss: 0.3834 - val_accuracy: 0.9499\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0702 - accuracy: 0.9753 - val_loss: 0.3156 - val_accuracy: 0.9499\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.0425 - accuracy: 0.9818 - val_loss: 0.6106 - val_accuracy: 0.9115\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1163 - accuracy: 0.9820 - val_loss: 0.3201 - val_accuracy: 0.9440\n",
            "Error: 5.60%, Acc: 94.40% usando filtros de '1 X 1' \n",
            "\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 4s 72ms/step - loss: 1.4330 - accuracy: 0.5917 - val_loss: 0.4188 - val_accuracy: 0.8171\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.3692 - accuracy: 0.8531 - val_loss: 0.5346 - val_accuracy: 0.7404\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.3772 - accuracy: 0.8447 - val_loss: 0.4022 - val_accuracy: 0.8407\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.3037 - accuracy: 0.8862 - val_loss: 0.5019 - val_accuracy: 0.8289\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.2849 - accuracy: 0.8937 - val_loss: 0.2069 - val_accuracy: 0.9174\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1922 - accuracy: 0.9347 - val_loss: 0.2310 - val_accuracy: 0.9145\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2054 - accuracy: 0.9126 - val_loss: 0.2567 - val_accuracy: 0.8909\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1528 - accuracy: 0.9454 - val_loss: 0.2053 - val_accuracy: 0.9292\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1565 - accuracy: 0.9500 - val_loss: 0.2278 - val_accuracy: 0.9174\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1406 - accuracy: 0.9581 - val_loss: 0.2760 - val_accuracy: 0.9263\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1384 - accuracy: 0.9591 - val_loss: 0.2071 - val_accuracy: 0.9292\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.1248 - accuracy: 0.9625 - val_loss: 0.2263 - val_accuracy: 0.9204\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0898 - accuracy: 0.9623 - val_loss: 0.3901 - val_accuracy: 0.8673\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.1285 - accuracy: 0.9457 - val_loss: 0.2582 - val_accuracy: 0.9204\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1168 - accuracy: 0.9608 - val_loss: 0.2114 - val_accuracy: 0.9322\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0861 - accuracy: 0.9668 - val_loss: 0.2285 - val_accuracy: 0.9322\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1031 - accuracy: 0.9599 - val_loss: 0.2409 - val_accuracy: 0.9322\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0925 - accuracy: 0.9674 - val_loss: 0.2097 - val_accuracy: 0.9440\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0478 - accuracy: 0.9838 - val_loss: 0.1866 - val_accuracy: 0.9440\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0413 - accuracy: 0.9856 - val_loss: 0.2881 - val_accuracy: 0.9351\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0960 - accuracy: 0.9690 - val_loss: 0.2746 - val_accuracy: 0.9322\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0846 - accuracy: 0.9768 - val_loss: 0.2451 - val_accuracy: 0.9351\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0667 - accuracy: 0.9760 - val_loss: 0.2355 - val_accuracy: 0.9381\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.3806 - val_accuracy: 0.9204\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0699 - accuracy: 0.9791 - val_loss: 0.1965 - val_accuracy: 0.9469\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0517 - accuracy: 0.9861 - val_loss: 0.2840 - val_accuracy: 0.9381\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 3s 70ms/step - loss: 0.0443 - accuracy: 0.9859 - val_loss: 0.2172 - val_accuracy: 0.9440\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.3095 - val_accuracy: 0.9322\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0293 - accuracy: 0.9894 - val_loss: 0.3402 - val_accuracy: 0.9499\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0573 - accuracy: 0.9821 - val_loss: 0.2426 - val_accuracy: 0.9410\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0421 - accuracy: 0.9858 - val_loss: 0.2859 - val_accuracy: 0.9410\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0429 - accuracy: 0.9899 - val_loss: 0.2694 - val_accuracy: 0.9528\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 70ms/step - loss: 0.0832 - accuracy: 0.9755 - val_loss: 0.2916 - val_accuracy: 0.9351\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 70ms/step - loss: 0.0649 - accuracy: 0.9764 - val_loss: 0.2721 - val_accuracy: 0.9558\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0302 - accuracy: 0.9951 - val_loss: 0.1725 - val_accuracy: 0.9528\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0411 - accuracy: 0.9916 - val_loss: 0.2629 - val_accuracy: 0.9558\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.3472 - val_accuracy: 0.9499\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0668 - accuracy: 0.9793 - val_loss: 0.2270 - val_accuracy: 0.9587\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 70ms/step - loss: 0.0446 - accuracy: 0.9884 - val_loss: 0.2332 - val_accuracy: 0.9499\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.2752 - val_accuracy: 0.9440\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0253 - accuracy: 0.9888 - val_loss: 0.4500 - val_accuracy: 0.9528\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0652 - accuracy: 0.9869 - val_loss: 0.2041 - val_accuracy: 0.9558\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0207 - accuracy: 0.9924 - val_loss: 0.3004 - val_accuracy: 0.9440\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0156 - accuracy: 0.9903 - val_loss: 0.2842 - val_accuracy: 0.9499\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0344 - accuracy: 0.9863 - val_loss: 0.2765 - val_accuracy: 0.9528\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0199 - accuracy: 0.9935 - val_loss: 0.3021 - val_accuracy: 0.9499\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0242 - accuracy: 0.9899 - val_loss: 0.2633 - val_accuracy: 0.9617\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 0.3167 - val_accuracy: 0.9499\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.2887 - val_accuracy: 0.9587\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0178 - accuracy: 0.9919 - val_loss: 0.5010 - val_accuracy: 0.9469\n",
            "Error: 5.31%, Acc: 94.69% usando filtros de '2 X 2' \n",
            "\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 4s 73ms/step - loss: 1.1334 - accuracy: 0.5616 - val_loss: 0.8270 - val_accuracy: 0.4838\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.5243 - accuracy: 0.7583 - val_loss: 1.6782 - val_accuracy: 0.5900\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.4881 - accuracy: 0.8400 - val_loss: 0.2969 - val_accuracy: 0.8673\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.3131 - accuracy: 0.8856 - val_loss: 0.3583 - val_accuracy: 0.8466\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.3795 - accuracy: 0.8745 - val_loss: 0.2926 - val_accuracy: 0.8879\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2453 - accuracy: 0.9089 - val_loss: 0.2909 - val_accuracy: 0.9086\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.2318 - accuracy: 0.9165 - val_loss: 0.3188 - val_accuracy: 0.8820\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.2189 - accuracy: 0.9263 - val_loss: 0.2799 - val_accuracy: 0.9056\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.2099 - accuracy: 0.9284 - val_loss: 0.2573 - val_accuracy: 0.8850\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1624 - accuracy: 0.9540 - val_loss: 0.2097 - val_accuracy: 0.9233\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1770 - accuracy: 0.9408 - val_loss: 0.2253 - val_accuracy: 0.9233\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1474 - accuracy: 0.9557 - val_loss: 0.1809 - val_accuracy: 0.9351\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1199 - accuracy: 0.9570 - val_loss: 0.1947 - val_accuracy: 0.9263\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1224 - accuracy: 0.9603 - val_loss: 0.2267 - val_accuracy: 0.9292\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1002 - accuracy: 0.9701 - val_loss: 0.2049 - val_accuracy: 0.9145\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1556 - accuracy: 0.9665 - val_loss: 0.1651 - val_accuracy: 0.9410\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1564 - accuracy: 0.9596 - val_loss: 0.1824 - val_accuracy: 0.9469\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1016 - accuracy: 0.9650 - val_loss: 0.3571 - val_accuracy: 0.9204\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1463 - accuracy: 0.9572 - val_loss: 0.1592 - val_accuracy: 0.9440\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0946 - accuracy: 0.9675 - val_loss: 0.3705 - val_accuracy: 0.9381\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1345 - accuracy: 0.9599 - val_loss: 0.1868 - val_accuracy: 0.9469\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 3s 70ms/step - loss: 0.0628 - accuracy: 0.9778 - val_loss: 0.2757 - val_accuracy: 0.9322\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0829 - accuracy: 0.9657 - val_loss: 0.2992 - val_accuracy: 0.9204\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1074 - accuracy: 0.9652 - val_loss: 0.2192 - val_accuracy: 0.9499\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0578 - accuracy: 0.9802 - val_loss: 0.1792 - val_accuracy: 0.9381\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0497 - accuracy: 0.9860 - val_loss: 0.1478 - val_accuracy: 0.9499\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0650 - accuracy: 0.9743 - val_loss: 0.2944 - val_accuracy: 0.9410\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0566 - accuracy: 0.9847 - val_loss: 0.2003 - val_accuracy: 0.9174\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0683 - accuracy: 0.9823 - val_loss: 0.2316 - val_accuracy: 0.9528\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1006 - accuracy: 0.9788 - val_loss: 0.2749 - val_accuracy: 0.9410\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0706 - accuracy: 0.9805 - val_loss: 0.1677 - val_accuracy: 0.9410\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 70ms/step - loss: 0.0442 - accuracy: 0.9879 - val_loss: 0.1784 - val_accuracy: 0.9499\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0517 - accuracy: 0.9875 - val_loss: 0.1322 - val_accuracy: 0.9587\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0433 - accuracy: 0.9810 - val_loss: 0.2707 - val_accuracy: 0.9086\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0592 - accuracy: 0.9852 - val_loss: 0.2891 - val_accuracy: 0.9440\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0366 - accuracy: 0.9869 - val_loss: 0.2497 - val_accuracy: 0.9587\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0945 - accuracy: 0.9769 - val_loss: 0.2037 - val_accuracy: 0.9587\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0457 - accuracy: 0.9910 - val_loss: 0.2216 - val_accuracy: 0.9499\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0623 - accuracy: 0.9788 - val_loss: 0.2174 - val_accuracy: 0.9469\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0495 - accuracy: 0.9918 - val_loss: 0.3204 - val_accuracy: 0.9469\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0618 - accuracy: 0.9808 - val_loss: 0.3142 - val_accuracy: 0.9351\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0681 - accuracy: 0.9851 - val_loss: 0.2715 - val_accuracy: 0.9558\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0469 - accuracy: 0.9841 - val_loss: 0.2814 - val_accuracy: 0.9676\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 70ms/step - loss: 0.0701 - accuracy: 0.9872 - val_loss: 0.3072 - val_accuracy: 0.9646\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0837 - accuracy: 0.9734 - val_loss: 0.2657 - val_accuracy: 0.9646\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1231 - accuracy: 0.9836 - val_loss: 0.2179 - val_accuracy: 0.9646\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 70ms/step - loss: 0.0402 - accuracy: 0.9924 - val_loss: 0.3589 - val_accuracy: 0.9351\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0812 - accuracy: 0.9850 - val_loss: 0.5601 - val_accuracy: 0.8791\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0535 - accuracy: 0.9896 - val_loss: 0.3823 - val_accuracy: 0.9469\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0640 - accuracy: 0.9823 - val_loss: 0.1389 - val_accuracy: 0.9735\n",
            "Error: 2.65%, Acc: 97.35% usando filtros de '3 X 3' \n",
            "\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 1.2066 - accuracy: 0.5432 - val_loss: 0.4667 - val_accuracy: 0.7729\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.4956 - accuracy: 0.7847 - val_loss: 0.5611 - val_accuracy: 0.8289\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.5542 - accuracy: 0.8127 - val_loss: 0.3118 - val_accuracy: 0.8850\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.3933 - accuracy: 0.8640 - val_loss: 1.1570 - val_accuracy: 0.7345\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.4530 - accuracy: 0.8463 - val_loss: 0.3173 - val_accuracy: 0.8761\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.3164 - accuracy: 0.9004 - val_loss: 0.3778 - val_accuracy: 0.8525\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 87ms/step - loss: 0.2208 - accuracy: 0.9215 - val_loss: 0.3548 - val_accuracy: 0.8702\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.2309 - accuracy: 0.9153 - val_loss: 0.4611 - val_accuracy: 0.8702\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.2548 - accuracy: 0.9105 - val_loss: 0.8113 - val_accuracy: 0.6726\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.2424 - accuracy: 0.9231 - val_loss: 0.2579 - val_accuracy: 0.9145\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.1769 - accuracy: 0.9410 - val_loss: 0.2865 - val_accuracy: 0.9351\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.1649 - accuracy: 0.9521 - val_loss: 0.1733 - val_accuracy: 0.9322\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.1440 - accuracy: 0.9429 - val_loss: 1.8024 - val_accuracy: 0.7788\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.4231 - accuracy: 0.9189 - val_loss: 0.3660 - val_accuracy: 0.8732\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.1229 - accuracy: 0.9564 - val_loss: 0.3218 - val_accuracy: 0.9115\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.1265 - accuracy: 0.9595 - val_loss: 0.3036 - val_accuracy: 0.9263\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.1824 - accuracy: 0.9477 - val_loss: 0.3187 - val_accuracy: 0.9174\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.1028 - accuracy: 0.9690 - val_loss: 0.2033 - val_accuracy: 0.9410\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0739 - accuracy: 0.9782 - val_loss: 0.2431 - val_accuracy: 0.9322\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.0870 - accuracy: 0.9739 - val_loss: 0.2556 - val_accuracy: 0.9263\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.1244 - accuracy: 0.9593 - val_loss: 0.3864 - val_accuracy: 0.9233\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.1890 - accuracy: 0.9643 - val_loss: 0.2565 - val_accuracy: 0.9381\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0624 - accuracy: 0.9782 - val_loss: 0.3325 - val_accuracy: 0.9174\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0793 - accuracy: 0.9760 - val_loss: 0.2260 - val_accuracy: 0.9381\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0578 - accuracy: 0.9862 - val_loss: 0.4737 - val_accuracy: 0.9056\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0749 - accuracy: 0.9783 - val_loss: 0.4026 - val_accuracy: 0.9322\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0882 - accuracy: 0.9769 - val_loss: 0.4064 - val_accuracy: 0.9292\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0397 - accuracy: 0.9896 - val_loss: 0.3381 - val_accuracy: 0.9440\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 87ms/step - loss: 0.0529 - accuracy: 0.9819 - val_loss: 0.2867 - val_accuracy: 0.9440\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0991 - accuracy: 0.9820 - val_loss: 0.3737 - val_accuracy: 0.9292\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.1111 - accuracy: 0.9838 - val_loss: 0.5495 - val_accuracy: 0.9469\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.4791 - val_accuracy: 0.9410\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0957 - accuracy: 0.9837 - val_loss: 0.3235 - val_accuracy: 0.9410\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.1003 - accuracy: 0.9782 - val_loss: 0.2459 - val_accuracy: 0.9469\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0213 - accuracy: 0.9949 - val_loss: 0.3287 - val_accuracy: 0.9263\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 87ms/step - loss: 0.0548 - accuracy: 0.9882 - val_loss: 0.3724 - val_accuracy: 0.9381\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0466 - accuracy: 0.9857 - val_loss: 0.3776 - val_accuracy: 0.9469\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.3944 - val_accuracy: 0.9440\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0448 - accuracy: 0.9900 - val_loss: 0.5191 - val_accuracy: 0.8791\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.1417 - accuracy: 0.9612 - val_loss: 0.4318 - val_accuracy: 0.9174\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0391 - accuracy: 0.9862 - val_loss: 0.4093 - val_accuracy: 0.9499\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0448 - accuracy: 0.9849 - val_loss: 0.4664 - val_accuracy: 0.9322\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.1309 - accuracy: 0.9843 - val_loss: 0.7525 - val_accuracy: 0.9381\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 0.0641 - accuracy: 0.9881 - val_loss: 0.7099 - val_accuracy: 0.9322\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0652 - accuracy: 0.9891 - val_loss: 0.5812 - val_accuracy: 0.9322\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.0273 - accuracy: 0.9950 - val_loss: 0.4710 - val_accuracy: 0.9381\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 87ms/step - loss: 0.0781 - accuracy: 0.9820 - val_loss: 0.5463 - val_accuracy: 0.9469\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.3952 - val_accuracy: 0.9469\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 4s 89ms/step - loss: 0.0876 - accuracy: 0.9871 - val_loss: 0.4340 - val_accuracy: 0.9440\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 4s 88ms/step - loss: 0.0292 - accuracy: 0.9976 - val_loss: 0.6861 - val_accuracy: 0.9440\n",
            "Error: 5.60%, Acc: 94.40% usando filtros de '4 X 4' \n",
            "\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 5s 99ms/step - loss: 1.2857 - accuracy: 0.5299 - val_loss: 0.6391 - val_accuracy: 0.7463\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.6166 - accuracy: 0.7042 - val_loss: 0.5049 - val_accuracy: 0.8319\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.5562 - accuracy: 0.8134 - val_loss: 0.3406 - val_accuracy: 0.8378\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.4364 - accuracy: 0.8230 - val_loss: 0.3139 - val_accuracy: 0.8820\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.3950 - accuracy: 0.8407 - val_loss: 0.3971 - val_accuracy: 0.8761\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.4450 - accuracy: 0.8477 - val_loss: 0.4118 - val_accuracy: 0.8171\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.6361 - accuracy: 0.8475 - val_loss: 0.3459 - val_accuracy: 0.8614\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.4241 - accuracy: 0.8788 - val_loss: 0.8517 - val_accuracy: 0.8584\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.3990 - accuracy: 0.8770 - val_loss: 0.3474 - val_accuracy: 0.8732\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.3781 - accuracy: 0.8825 - val_loss: 0.2862 - val_accuracy: 0.8909\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2336 - accuracy: 0.8972 - val_loss: 0.3360 - val_accuracy: 0.8348\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2708 - accuracy: 0.8941 - val_loss: 0.3669 - val_accuracy: 0.8673\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.3584 - accuracy: 0.8891 - val_loss: 0.3746 - val_accuracy: 0.8702\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.3448 - accuracy: 0.9143 - val_loss: 0.2436 - val_accuracy: 0.9115\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2467 - accuracy: 0.9291 - val_loss: 0.2678 - val_accuracy: 0.9145\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2319 - accuracy: 0.9190 - val_loss: 0.8034 - val_accuracy: 0.8643\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2648 - accuracy: 0.9311 - val_loss: 0.3406 - val_accuracy: 0.9204\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.3019 - accuracy: 0.9210 - val_loss: 0.2226 - val_accuracy: 0.9410\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1518 - accuracy: 0.9551 - val_loss: 0.4084 - val_accuracy: 0.8673\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2304 - accuracy: 0.9333 - val_loss: 0.2819 - val_accuracy: 0.9410\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1679 - accuracy: 0.9610 - val_loss: 0.3011 - val_accuracy: 0.9351\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1577 - accuracy: 0.9537 - val_loss: 0.3715 - val_accuracy: 0.9056\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2481 - accuracy: 0.9517 - val_loss: 0.5045 - val_accuracy: 0.8673\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2099 - accuracy: 0.9601 - val_loss: 0.4394 - val_accuracy: 0.9204\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1179 - accuracy: 0.9705 - val_loss: 0.3299 - val_accuracy: 0.9322\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.4306 - accuracy: 0.9420 - val_loss: 0.4783 - val_accuracy: 0.9145\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1238 - accuracy: 0.9633 - val_loss: 0.4013 - val_accuracy: 0.9381\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1440 - accuracy: 0.9680 - val_loss: 0.2196 - val_accuracy: 0.9469\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0917 - accuracy: 0.9749 - val_loss: 0.6785 - val_accuracy: 0.8732\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2185 - accuracy: 0.9466 - val_loss: 0.6817 - val_accuracy: 0.9056\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0710 - accuracy: 0.9720 - val_loss: 0.3268 - val_accuracy: 0.9351\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1098 - accuracy: 0.9665 - val_loss: 0.2702 - val_accuracy: 0.9410\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.1255 - accuracy: 0.9683 - val_loss: 0.3700 - val_accuracy: 0.9292\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1097 - accuracy: 0.9654 - val_loss: 1.4829 - val_accuracy: 0.8879\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1318 - accuracy: 0.9618 - val_loss: 2.8156 - val_accuracy: 0.8230\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2283 - accuracy: 0.9470 - val_loss: 0.4679 - val_accuracy: 0.9469\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1209 - accuracy: 0.9729 - val_loss: 0.6119 - val_accuracy: 0.9263\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0621 - accuracy: 0.9784 - val_loss: 0.3793 - val_accuracy: 0.9322\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2995 - accuracy: 0.9579 - val_loss: 0.8152 - val_accuracy: 0.9292\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0896 - accuracy: 0.9787 - val_loss: 0.5767 - val_accuracy: 0.9469\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0784 - accuracy: 0.9826 - val_loss: 0.5090 - val_accuracy: 0.9233\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1917 - accuracy: 0.9671 - val_loss: 0.7002 - val_accuracy: 0.9174\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0733 - accuracy: 0.9844 - val_loss: 0.7341 - val_accuracy: 0.9528\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1974 - accuracy: 0.9668 - val_loss: 0.5771 - val_accuracy: 0.9263\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1069 - accuracy: 0.9811 - val_loss: 0.6527 - val_accuracy: 0.8938\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1495 - accuracy: 0.9672 - val_loss: 0.6355 - val_accuracy: 0.9233\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1676 - accuracy: 0.9665 - val_loss: 0.4994 - val_accuracy: 0.9292\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0801 - accuracy: 0.9801 - val_loss: 0.7504 - val_accuracy: 0.9233\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0903 - accuracy: 0.9814 - val_loss: 0.6031 - val_accuracy: 0.9410\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0626 - accuracy: 0.9864 - val_loss: 1.1241 - val_accuracy: 0.9381\n",
            "Error: 6.19%, Acc: 93.81% usando filtros de '5 X 5' \n",
            "\n",
            "resultado: \n",
            "Error: 5.60%, Acc: 94.40% usando filtros de '1 X 1' \n",
            "Error: 5.31%, Acc: 94.69% usando filtros de '2 X 2' \n",
            "Error: 2.65%, Acc: 97.35% usando filtros de '3 X 3' \n",
            "Error: 5.60%, Acc: 94.40% usando filtros de '4 X 4' \n",
            "Error: 6.19%, Acc: 93.81% usando filtros de '5 X 5' \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcbwuApUkdBo"
      },
      "source": [
        "Se ha logrado un 97.35% de accuracy utilizando fitlros de 3X3, es la mayor precisión obtenida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riq2k64fmtSx",
        "outputId": "e981751e-fd83-4ee8-8d66-3cf3164676ff"
      },
      "source": [
        "model_best = model_cnn_binary_tunn(3)\n",
        "\n",
        "model_best.fit(X_train_cn, y_train_binario, validation_data=(X_test_cn, y_test_binario), epochs=50, batch_size=32)\n",
        "\n",
        "scores = model_best.evaluate(X_test_cn, y_test_binario, verbose=0)\n",
        "r = (\"Error: %.2f%%, Acc: %.2f%% usando filtros de %r \" % ((100-scores[1]*100), scores[1]*100, str(3)+\" X \"+str(3)))+\"\\n\"\n",
        "print(r)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 4s 74ms/step - loss: 1.1572 - accuracy: 0.5477 - val_loss: 0.6569 - val_accuracy: 0.6136\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.6257 - accuracy: 0.6827 - val_loss: 0.4217 - val_accuracy: 0.8171\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.3577 - accuracy: 0.8599 - val_loss: 0.4374 - val_accuracy: 0.8319\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.3776 - accuracy: 0.8369 - val_loss: 0.5418 - val_accuracy: 0.7817\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2917 - accuracy: 0.9009 - val_loss: 0.2784 - val_accuracy: 0.9115\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.2331 - accuracy: 0.9120 - val_loss: 0.2689 - val_accuracy: 0.8968\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.2060 - accuracy: 0.9314 - val_loss: 0.2185 - val_accuracy: 0.9263\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.2333 - accuracy: 0.9296 - val_loss: 0.2558 - val_accuracy: 0.9233\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2082 - accuracy: 0.9331 - val_loss: 0.3281 - val_accuracy: 0.9027\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1646 - accuracy: 0.9508 - val_loss: 0.2400 - val_accuracy: 0.9233\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1403 - accuracy: 0.9641 - val_loss: 0.2712 - val_accuracy: 0.9056\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.1474 - accuracy: 0.9577 - val_loss: 0.2979 - val_accuracy: 0.9086\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1058 - accuracy: 0.9752 - val_loss: 0.2287 - val_accuracy: 0.9233\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1196 - accuracy: 0.9664 - val_loss: 0.3694 - val_accuracy: 0.9145\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1626 - accuracy: 0.9451 - val_loss: 0.2216 - val_accuracy: 0.9263\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0767 - accuracy: 0.9743 - val_loss: 0.7148 - val_accuracy: 0.8879\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1696 - accuracy: 0.9603 - val_loss: 0.1608 - val_accuracy: 0.9410\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0713 - accuracy: 0.9760 - val_loss: 0.2253 - val_accuracy: 0.9410\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0692 - accuracy: 0.9816 - val_loss: 0.1959 - val_accuracy: 0.9440\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0562 - accuracy: 0.9854 - val_loss: 0.4433 - val_accuracy: 0.9086\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0921 - accuracy: 0.9764 - val_loss: 0.2623 - val_accuracy: 0.9469\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0938 - accuracy: 0.9696 - val_loss: 0.2237 - val_accuracy: 0.9440\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0377 - accuracy: 0.9866 - val_loss: 0.1670 - val_accuracy: 0.9587\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0769 - accuracy: 0.9795 - val_loss: 0.1868 - val_accuracy: 0.9499\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0730 - accuracy: 0.9787 - val_loss: 0.1761 - val_accuracy: 0.9646\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0392 - accuracy: 0.9825 - val_loss: 0.3069 - val_accuracy: 0.9351\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0472 - accuracy: 0.9825 - val_loss: 1.0860 - val_accuracy: 0.8909\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0495 - accuracy: 0.9863 - val_loss: 0.1903 - val_accuracy: 0.9558\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0571 - accuracy: 0.9832 - val_loss: 0.2243 - val_accuracy: 0.9617\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0563 - accuracy: 0.9842 - val_loss: 0.2960 - val_accuracy: 0.9410\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0531 - accuracy: 0.9889 - val_loss: 0.1810 - val_accuracy: 0.9617\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0381 - accuracy: 0.9887 - val_loss: 0.4141 - val_accuracy: 0.9056\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0622 - accuracy: 0.9810 - val_loss: 0.2665 - val_accuracy: 0.9558\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1685 - accuracy: 0.9811 - val_loss: 0.2783 - val_accuracy: 0.9410\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0757 - accuracy: 0.9762 - val_loss: 0.2463 - val_accuracy: 0.9469\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0693 - accuracy: 0.9880 - val_loss: 0.2263 - val_accuracy: 0.9499\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0553 - accuracy: 0.9872 - val_loss: 0.4134 - val_accuracy: 0.9351\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0419 - accuracy: 0.9855 - val_loss: 0.3786 - val_accuracy: 0.9440\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1135 - accuracy: 0.9787 - val_loss: 0.3666 - val_accuracy: 0.9292\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0266 - accuracy: 0.9954 - val_loss: 0.3661 - val_accuracy: 0.9322\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1872 - accuracy: 0.9722 - val_loss: 0.3929 - val_accuracy: 0.9322\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0466 - accuracy: 0.9883 - val_loss: 0.2530 - val_accuracy: 0.9410\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0338 - accuracy: 0.9933 - val_loss: 0.2195 - val_accuracy: 0.9587\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0544 - accuracy: 0.9846 - val_loss: 0.2748 - val_accuracy: 0.9528\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0522 - accuracy: 0.9918 - val_loss: 0.3673 - val_accuracy: 0.9469\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0533 - accuracy: 0.9886 - val_loss: 0.3430 - val_accuracy: 0.9440\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0528 - accuracy: 0.9917 - val_loss: 0.2419 - val_accuracy: 0.9528\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0291 - accuracy: 0.9864 - val_loss: 0.4856 - val_accuracy: 0.9174\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0363 - accuracy: 0.9914 - val_loss: 0.3114 - val_accuracy: 0.9292\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 0.1766 - val_accuracy: 0.9410\n",
            "Error: 5.90%, Acc: 94.10% usando filtros de '3 X 3' \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "idNS-2IHnuMN",
        "outputId": "22ed1333-0f41-4604-cb2a-d23b783ad132"
      },
      "source": [
        "plot_model(model_best, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHjqEj1Xk7jp"
      },
      "source": [
        "Se intentará obtener un mejor valor usando un GridSearch que muestre el mejor valor para las épocas y el batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3RGEwunliBz",
        "outputId": "e31b4cad-c6e5-4795-ec31-f49cb9bc5b6c"
      },
      "source": [
        "model_keras = KerasClassifier(build_fn=model_cnn_binary_tunn, t_filtro=3, verbose=1)\n",
        "batch_size = [16, 32, 64]\n",
        "epochs = [10,30, 50,100]\n",
        "\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model_keras, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train_cn, y_train_binario)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 4s 39ms/step - loss: 0.8766 - accuracy: 0.6407\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3471 - accuracy: 0.8606\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2666 - accuracy: 0.9013\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.2706 - accuracy: 0.8947\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.2348 - accuracy: 0.9116\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2293 - accuracy: 0.9179\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.2270 - accuracy: 0.9277\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2220 - accuracy: 0.9457\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0976 - accuracy: 0.9677\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1281 - accuracy: 0.9728\n",
            "16/16 [==============================] - 1s 26ms/step - loss: 3.3220 - accuracy: 0.2231\n",
            "Epoch 1/10\n",
            "63/63 [==============================] - 3s 40ms/step - loss: 0.7893 - accuracy: 0.6462\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3653 - accuracy: 0.8753\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3235 - accuracy: 0.8970\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2842 - accuracy: 0.9077\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2944 - accuracy: 0.8918\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2439 - accuracy: 0.9148\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2110 - accuracy: 0.9278\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1540 - accuracy: 0.9439\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1976 - accuracy: 0.9206\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1791 - accuracy: 0.9548\n",
            "16/16 [==============================] - 1s 26ms/step - loss: 1.5080 - accuracy: 0.7520\n",
            "Epoch 1/10\n",
            "63/63 [==============================] - 3s 33ms/step - loss: 1.0307 - accuracy: 0.5745\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.4621 - accuracy: 0.8117\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.3571 - accuracy: 0.8670\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3284 - accuracy: 0.8819\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2686 - accuracy: 0.9131\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3065 - accuracy: 0.8968\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2073 - accuracy: 0.9176\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2248 - accuracy: 0.9241\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2043 - accuracy: 0.9453\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1749 - accuracy: 0.9347\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3704 - accuracy: 0.9000\n",
            "Epoch 1/10\n",
            "63/63 [==============================] - 3s 33ms/step - loss: 1.1612 - accuracy: 0.5878\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3083 - accuracy: 0.8798\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2814 - accuracy: 0.9091\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2461 - accuracy: 0.9243\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2099 - accuracy: 0.9318\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2056 - accuracy: 0.9313\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1791 - accuracy: 0.9548\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1788 - accuracy: 0.9458\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1642 - accuracy: 0.9489\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1112 - accuracy: 0.9672\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 3.1702 - accuracy: 0.6920\n",
            "Epoch 1/10\n",
            "63/63 [==============================] - 3s 33ms/step - loss: 0.8700 - accuracy: 0.5646\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.4627 - accuracy: 0.8108\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3689 - accuracy: 0.8691\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3513 - accuracy: 0.8617\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2528 - accuracy: 0.8980\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2260 - accuracy: 0.9110\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1413 - accuracy: 0.9369\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1670 - accuracy: 0.9426\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1481 - accuracy: 0.9551\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1300 - accuracy: 0.9626\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.6388 - accuracy: 0.8920\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 0.7886 - accuracy: 0.6496\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 0.4045 - accuracy: 0.8268\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 0.3274 - accuracy: 0.8883\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 0.3396 - accuracy: 0.8576\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 0.2666 - accuracy: 0.9204\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 0.4325 - accuracy: 0.9089\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 0.2363 - accuracy: 0.9191\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 0.1897 - accuracy: 0.9471\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 0.1995 - accuracy: 0.9339\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 0.2249 - accuracy: 0.9467\n",
            "Best: 0.691822 using {'batch_size': 16, 'epochs': 10}\n",
            "0.691822 (0.247679) with: {'batch_size': 16, 'epochs': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5slRlazroYDB",
        "outputId": "e8fcbde4-90dd-4f1b-e7ad-48d4dd4ff873"
      },
      "source": [
        "grid_result.best_score_"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6918215036392212"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}